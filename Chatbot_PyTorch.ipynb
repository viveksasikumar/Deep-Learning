{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the text files with lines and conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_filepath = os.path.join(\"cornell movie-dialogs corpus\", \"movie_lines.txt\")\n",
    "conv_filepath = os.path.join(\"cornell movie-dialogs corpus\", \"movie_conversations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_name = \"cornell movie-dialogs corpus\"\n",
    "corpus = os.path.join(\"data\", corpus_name)\n",
    "\n",
    "def printLines(file, n=10):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(\"data\", \"save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
      "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
      "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n"
     ]
    }
   ],
   "source": [
    "with open(lines_filepath,'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines[:8]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_fields = ['lineID', 'characterID', 'movieID', 'character', 'text']\n",
    "\n",
    "lines = {}\n",
    "\n",
    "with open(lines_filepath, 'r', encoding = 'iso-8859-1') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' +++$+++ ')\n",
    "        lineObj = {}\n",
    "        for i, field in enumerate(line_fields):\n",
    "            lineObj[field] = values[i]\n",
    "        lines[lineObj['lineID']] = lineObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lineID': 'L984',\n",
       " 'characterID': 'u2',\n",
       " 'movieID': 'm0',\n",
       " 'character': 'CAMERON',\n",
       " 'text': 'She okay?\\n'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['L984']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the conversation to a dictionary with fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_fields = ['character1ID', 'character2ID', 'movieID', 'utteranceIDs']\n",
    "conversations = []\n",
    "\n",
    "with open(conv_filepath, 'r', encoding = 'iso-8859-1') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' +++$+++ ')\n",
    "        convObj = {}\n",
    "        for i, field in enumerate(conv_fields):\n",
    "            convObj[field] = values[i]\n",
    "        lineIds = eval(convObj['utteranceIDs'])\n",
    "        convObj['lines'] = []\n",
    "        for lineId in lineIds:\n",
    "            convObj['lines'].append(lines[lineId])\n",
    "        conversations.append(convObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
      " \n",
      " Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conversations[0]['lines'][0]['text'],'\\n',conversations[0]['lines'][1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = []\n",
    "for conversation in conversations:\n",
    "    for i in range(len(conversation['lines'])-1):\n",
    "        inputLine = conversation['lines'][i]['text'].strip()\n",
    "        targetLine = conversation['lines'][i+1]['text'].strip()\n",
    "        if inputLine and targetLine:\n",
    "            qa_pairs.append([inputLine, targetLine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.',\n",
       " \"Well, I thought we'd start with pronunciation, if that's okay with you.\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pairs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the file with conversation pairs in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing newly formatted file...\n",
      "Done writing to file\n"
     ]
    }
   ],
   "source": [
    "datafile = os.path.join('cornell movie-dialogs corpus','formatted_movie_lines.txt')\n",
    "delimiter = '\\t'\n",
    "delimiter = str(codecs.decode(delimiter, 'unicode_escape'))\n",
    "\n",
    "print('\\nWriting newly formatted file...')\n",
    "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter)\n",
    "    for pair in qa_pairs:\n",
    "        writer.writerow(pair)\n",
    "print('Done writing to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open the text file with conversation pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"I don't want to know how to say that though.  I want to know useful things. Like where the good stores are.  How much does champagne cost?  Stuff like Chat.  I have never in my life had to point out my head to someone.\\tThat's because it's such a nice one.\\r\\r\\n\"\n",
      "b\"That's because it's such a nice one.\\tForget French.\\r\\r\\n\"\n",
      "b\"How is our little Find the Wench A Date plan progressing?\\tWell, there's someone I think might be --\\r\\r\\n\"\n",
      "b'There.\\tWhere?\\r\\r\\n'\n",
      "b\"You got something on your mind?\\tI counted on you to help my cause. You and that thug are obviously failing. Aren't we ever going on our date?\\r\\r\\n\"\n",
      "b\"You have my word.  As a gentleman\\tYou're sweet.\\r\\r\\n\"\n",
      "b\"How do you get your hair to look like that?\\tEber's Deep Conditioner every two days. And I never, ever use a blowdryer without the diffuser attachment.\\r\\r\\n\"\n",
      "b\"Sure have.\\tI really, really, really wanna go, but I can't.  Not unless my sister goes.\\r\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "datafile = os.path.join('cornell movie-dialogs corpus','formatted_movie_lines.txt')\n",
    "\n",
    "with open(datafile, 'rb') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines[12:20]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a vocabulary class \n",
    "### To create a clas which creates word count, indexes the word. Also a function to delete rare which do not repeat  more than a minimum threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0  # Use padding for short sentences\n",
    "SOS_token = 1  # Start of sentence\n",
    "EOS_token = 2  # End of sentence\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: 'PAD', SOS_token: 'SOS', EOS_token: 'EOS'}\n",
    "        self.num_words = 3  #count PAD, SOS, EOS\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words+=1\n",
    "        else:\n",
    "            self.word2count[word] = self.word2count[word] + 1\n",
    " \n",
    "    def trim(self, min_count):\n",
    "        keep_words = []\n",
    "        for k,v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "                \n",
    "        print('keep_words {} / {} = {:.4f}'.format(len(keep_words), len(self.word2index),\n",
    "                                                   len(keep_words)/len(self.word2index)))\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: 'PAD', SOS_token: 'SOS', EOS_token: 'EOS'}\n",
    "        self.num_words = 3\n",
    "        \n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to remove annotations from alphabets\n",
    "### Normal Form Decompose - decompose to normal form - comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c)!='Mn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function - Regular expression\n",
    "### 1. To lower the case of string, (r is added to escape backslash)\n",
    "### 2. To remove any character that is not a sequqnce of lower or upper case letters \n",
    "### 3. To remove a sequence of white space characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\",r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\",r\" \",s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa aa !s s dd ?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizeString(\"aa123aa!s's dd?\\n \\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening the text file\n",
    "### Each line of file contains conversation separated by \\t\n",
    "### Open it as lines\n",
    "### Split it into pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and processing file .. Please wait\n"
     ]
    }
   ],
   "source": [
    "datafile = os.path.join('cornell movie-dialogs corpus','formatted_movie_lines.txt')\n",
    "\n",
    "print(\"Reading and processing file .. Please wait\")\n",
    "\n",
    "lines = open(datafile, encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "pairs = [[normalizeString(s) for s in pair.split('\\t')] for pair in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['you re asking me out . that s so cute . what s your name again ?',\n",
       "  'forget it .'],\n",
       " 'you re asking me out . that s so cute . what s your name again ?',\n",
       " 'forget it .')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[6], pairs[6][0],pairs[6][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter pair to a set maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split()) < MAX_LENGTH and len(p[1].split()) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 221282 conversations\n",
      "There are 64271 conversations after filtering\n"
     ]
    }
   ],
   "source": [
    "pairs = [pair for pair in pairs if len(pair) > 1]\n",
    "\n",
    "print(\"There are {} conversations\".format(len(pairs)))\n",
    "\n",
    "pairs = filterPairs(pairs)\n",
    "\n",
    "print(\"There are {} conversations after filtering\".format(len(pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call the class vocabulary with the pairs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = Vocabulary(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.word2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted words: 18008\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['you know chastity ?', 'i believe we share an art instructor']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n"
     ]
    }
   ],
   "source": [
    "for pair in pairs:\n",
    "    voc.addSentence(pair[0])\n",
    "    voc.addSentence(pair[1])\n",
    "\n",
    "print('Counted words:', voc.num_words)\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'there': 2013,\n",
       " '.': 104124,\n",
       " 'where': 2475,\n",
       " '?': 43942,\n",
       " 'you': 29248,\n",
       " 'have': 3023,\n",
       " 'my': 3148,\n",
       " 'word': 125,\n",
       " 'as': 558,\n",
       " 'a': 8579,\n",
       " 'gentleman': 22,\n",
       " 're': 3658,\n",
       " 'sweet': 78,\n",
       " 'hi': 659,\n",
       " 'looks': 199,\n",
       " 'like': 2173,\n",
       " 'things': 249,\n",
       " 'worked': 59,\n",
       " 'out': 1521,\n",
       " 'tonight': 278,\n",
       " 'huh': 815,\n",
       " 'know': 3608,\n",
       " 'chastity': 2,\n",
       " 'i': 22076,\n",
       " 'believe': 399,\n",
       " 'we': 3946,\n",
       " 'share': 25,\n",
       " 'an': 809,\n",
       " 'art': 26,\n",
       " 'instructor': 1,\n",
       " 'fun': 94,\n",
       " 'tons': 7,\n",
       " 'well': 1898,\n",
       " 'no': 5693,\n",
       " 'then': 1140,\n",
       " 'that': 7220,\n",
       " 's': 12452,\n",
       " 'all': 1774,\n",
       " 'had': 489,\n",
       " 'to': 8082,\n",
       " 'say': 1272,\n",
       " 'but': 1478,\n",
       " 'always': 330,\n",
       " 'been': 760,\n",
       " 'this': 3362,\n",
       " 'selfish': 3,\n",
       " 'do': 5416,\n",
       " 'listen': 204,\n",
       " 'crap': 19,\n",
       " 'what': 12633,\n",
       " 'good': 1756,\n",
       " 'stuff': 146,\n",
       " 'the': 10739,\n",
       " 'real': 252,\n",
       " 'fear': 31,\n",
       " 'of': 3309,\n",
       " 'wearing': 41,\n",
       " 'pastels': 1,\n",
       " 'wow': 86,\n",
       " 'let': 1022,\n",
       " 'go': 2057,\n",
       " 'she': 2057,\n",
       " 'okay': 1453,\n",
       " 'hope': 154,\n",
       " 'so': 2259,\n",
       " 'they': 2079,\n",
       " '!': 11227,\n",
       " 'not': 3814,\n",
       " 'did': 2600,\n",
       " 'change': 85,\n",
       " 'your': 3509,\n",
       " 'hair': 89,\n",
       " 'might': 179,\n",
       " 'wanna': 184,\n",
       " 'think': 1713,\n",
       " 'about': 2357,\n",
       " 'it': 11523,\n",
       " 'who': 2049,\n",
       " 'joey': 25,\n",
       " 'great': 428,\n",
       " 'would': 864,\n",
       " 'mind': 244,\n",
       " 'getting': 228,\n",
       " 'me': 5559,\n",
       " 'drink': 225,\n",
       " 'cameron': 15,\n",
       " 'more': 482,\n",
       " 'expensive': 13,\n",
       " 'hey': 786,\n",
       " 'cheeks': 1,\n",
       " 've': 1105,\n",
       " 'nowhere': 15,\n",
       " 'daddy': 159,\n",
       " 'are': 4216,\n",
       " 'completely': 40,\n",
       " 'unbalanced': 1,\n",
       " 'can': 2626,\n",
       " 'now': 1434,\n",
       " 'in': 3439,\n",
       " 'th': 32,\n",
       " 'for': 2812,\n",
       " 'month': 51,\n",
       " 'why': 2379,\n",
       " 'he': 4123,\n",
       " 'was': 2655,\n",
       " 'total': 17,\n",
       " 'babe': 23,\n",
       " 'hate': 128,\n",
       " 'looked': 51,\n",
       " 'beautiful': 212,\n",
       " 'last': 302,\n",
       " 'night': 483,\n",
       " 'set': 89,\n",
       " 'up': 1582,\n",
       " 'just': 2164,\n",
       " 'wanted': 178,\n",
       " 'patrick': 35,\n",
       " 'is': 5514,\n",
       " 'perm': 1,\n",
       " 'doesn': 308,\n",
       " 't': 8426,\n",
       " 'want': 1847,\n",
       " 'date': 64,\n",
       " 'exactly': 204,\n",
       " 'point': 125,\n",
       " 'and': 2964,\n",
       " 'going': 1385,\n",
       " 'oh': 2459,\n",
       " 'god': 550,\n",
       " 'starting': 29,\n",
       " 'party': 106,\n",
       " 'wear': 42,\n",
       " 'belly': 2,\n",
       " 'before': 326,\n",
       " 'minute': 189,\n",
       " 'because': 373,\n",
       " 'll': 2023,\n",
       " 'scare': 22,\n",
       " 'them': 762,\n",
       " 'away': 349,\n",
       " 'prom': 17,\n",
       " 'kat': 9,\n",
       " 'has': 360,\n",
       " 'new': 292,\n",
       " 'guy': 301,\n",
       " 'tell': 1005,\n",
       " 'which': 227,\n",
       " 'dakota': 10,\n",
       " 'from': 759,\n",
       " 'north': 32,\n",
       " 'actually': 124,\n",
       " 'how': 3146,\n",
       " 'd': 1141,\n",
       " 'kidding': 124,\n",
       " 'people': 330,\n",
       " 'live': 195,\n",
       " 'many': 237,\n",
       " 'were': 909,\n",
       " 'old': 321,\n",
       " 'school': 143,\n",
       " 'thirty': 139,\n",
       " 'two': 581,\n",
       " 'get': 1952,\n",
       " 'here': 2402,\n",
       " 'couple': 78,\n",
       " 'thousand': 122,\n",
       " 'most': 81,\n",
       " 'evil': 34,\n",
       " 'girl': 306,\n",
       " 'burn': 22,\n",
       " 'pine': 2,\n",
       " 'perish': 3,\n",
       " 'yeah': 3098,\n",
       " 'minor': 4,\n",
       " 'encounter': 2,\n",
       " 'with': 1846,\n",
       " 'shrew': 1,\n",
       " 'her': 1269,\n",
       " 'bianca': 5,\n",
       " 'sister': 118,\n",
       " 'mewling': 1,\n",
       " 'rampalian': 1,\n",
       " 'wretch': 1,\n",
       " 'herself': 27,\n",
       " 'him': 1845,\n",
       " 'makes': 136,\n",
       " 'seems': 57,\n",
       " 'thrives': 1,\n",
       " 'on': 2394,\n",
       " 'danger': 14,\n",
       " 'number': 120,\n",
       " 'one': 1369,\n",
       " 'hates': 23,\n",
       " 'smokers': 1,\n",
       " 'lung': 4,\n",
       " 'cancer': 19,\n",
       " 'issue': 9,\n",
       " 'favorite': 38,\n",
       " 'uncle': 52,\n",
       " 'dead': 379,\n",
       " 'at': 1191,\n",
       " 'forty': 59,\n",
       " 'pretty': 242,\n",
       " 'wasn': 246,\n",
       " 'sure': 1188,\n",
       " 'assail': 1,\n",
       " 'ears': 21,\n",
       " 'band': 16,\n",
       " 'gigglepuss': 1,\n",
       " 'playing': 64,\n",
       " 'tomorrow': 238,\n",
       " 'don': 4022,\n",
       " 'make': 493,\n",
       " 'man': 771,\n",
       " 'm': 3968,\n",
       " 'little': 514,\n",
       " 'busy': 104,\n",
       " 'off': 467,\n",
       " 'whole': 80,\n",
       " 'thing': 339,\n",
       " 'talking': 354,\n",
       " 'partial': 2,\n",
       " 'makin': 11,\n",
       " 'any': 568,\n",
       " 'headway': 1,\n",
       " 'kissed': 17,\n",
       " 'worst': 17,\n",
       " 'ya': 362,\n",
       " 'goin': 103,\n",
       " 'leave': 356,\n",
       " 'alone': 181,\n",
       " 'said': 718,\n",
       " 'need': 578,\n",
       " 'money': 355,\n",
       " 'take': 833,\n",
       " 'when': 708,\n",
       " 'shell': 7,\n",
       " 'fifty': 99,\n",
       " 'expect': 48,\n",
       " 'results': 1,\n",
       " 'upped': 1,\n",
       " 'price': 44,\n",
       " 'hundred': 167,\n",
       " 'bucks': 50,\n",
       " 'forget': 171,\n",
       " 'time': 816,\n",
       " 'deal': 126,\n",
       " 'act': 48,\n",
       " 'human': 36,\n",
       " 'lost': 151,\n",
       " 'nope': 99,\n",
       " 'came': 190,\n",
       " 'by': 365,\n",
       " 'chat': 7,\n",
       " 'hear': 370,\n",
       " 'helpin': 3,\n",
       " 'verona': 3,\n",
       " 'uh': 626,\n",
       " 'friend': 288,\n",
       " 'random': 3,\n",
       " 'skid': 2,\n",
       " 'look': 953,\n",
       " 'block': 12,\n",
       " 'e': 26,\n",
       " 'attempted': 2,\n",
       " 'slit': 4,\n",
       " 'william': 27,\n",
       " 'didn': 961,\n",
       " 'even': 230,\n",
       " 'high': 73,\n",
       " 'never': 763,\n",
       " 'proven': 5,\n",
       " 'neither': 59,\n",
       " 'his': 704,\n",
       " 'heterosexuality': 1,\n",
       " 'work': 420,\n",
       " 'cares': 15,\n",
       " 'favor': 50,\n",
       " 'backfired': 1,\n",
       " 'seen': 229,\n",
       " 'asked': 128,\n",
       " 'meet': 170,\n",
       " 'mean': 987,\n",
       " 'wo': 1,\n",
       " 'doin': 118,\n",
       " 'sweating': 2,\n",
       " 'pig': 31,\n",
       " 'yourself': 228,\n",
       " 'pick': 81,\n",
       " 'friday': 17,\n",
       " 'right': 2035,\n",
       " 'covered': 13,\n",
       " 'vomit': 3,\n",
       " 'seven': 114,\n",
       " 'excuse': 205,\n",
       " 'isn': 361,\n",
       " 'raincoats': 1,\n",
       " 'funny': 152,\n",
       " 'only': 390,\n",
       " 'fine': 607,\n",
       " 'lie': 76,\n",
       " 'down': 640,\n",
       " 'awhile': 15,\n",
       " 'doing': 855,\n",
       " 'told': 434,\n",
       " 'care': 228,\n",
       " 'if': 745,\n",
       " 'die': 139,\n",
       " 'dorsey': 2,\n",
       " 'thought': 474,\n",
       " 'above': 13,\n",
       " 'wake': 56,\n",
       " 'jail': 33,\n",
       " 'maybe': 647,\n",
       " 'weren': 65,\n",
       " 'ask': 323,\n",
       " 'should': 618,\n",
       " 'start': 132,\n",
       " 'father': 308,\n",
       " 'wouldn': 193,\n",
       " 'approve': 8,\n",
       " 'gettin': 23,\n",
       " 'heard': 306,\n",
       " 'poetry': 13,\n",
       " 'reading': 47,\n",
       " 'pleasant': 13,\n",
       " 'wholesome': 1,\n",
       " 'unwelcome': 1,\n",
       " 'effect': 9,\n",
       " 'other': 316,\n",
       " 'than': 226,\n",
       " 'upchuck': 1,\n",
       " 'reflex': 1,\n",
       " 'nothing': 745,\n",
       " 'c': 168,\n",
       " 'mon': 118,\n",
       " 'bad': 358,\n",
       " 'try': 266,\n",
       " 'lookin': 31,\n",
       " 'angle': 10,\n",
       " 'put': 237,\n",
       " 'foot': 20,\n",
       " 'stayin': 7,\n",
       " 'soft': 21,\n",
       " 'side': 71,\n",
       " 'knew': 172,\n",
       " 'acting': 29,\n",
       " 'way': 613,\n",
       " 'yes': 3889,\n",
       " 'something': 885,\n",
       " 'screwed': 13,\n",
       " 'disappointed': 11,\n",
       " 'state': 28,\n",
       " 'trooper': 1,\n",
       " 'fallacy': 2,\n",
       " 'duck': 10,\n",
       " 'hearsay': 2,\n",
       " 'porn': 1,\n",
       " 'career': 3,\n",
       " 'true': 136,\n",
       " 'peas': 1,\n",
       " 'else': 328,\n",
       " 'knows': 151,\n",
       " 'request': 10,\n",
       " 'or': 612,\n",
       " 'command': 16,\n",
       " 'won': 378,\n",
       " 'grandmother': 10,\n",
       " 'insurance': 34,\n",
       " 'does': 616,\n",
       " 'cover': 27,\n",
       " 'pms': 4,\n",
       " 'seizure': 1,\n",
       " 'punishing': 4,\n",
       " 'agree': 30,\n",
       " 'making': 85,\n",
       " 'decisions': 4,\n",
       " 'parent': 2,\n",
       " 'matter': 207,\n",
       " 'parts': 10,\n",
       " 'tired': 89,\n",
       " 'breathing': 15,\n",
       " 'cool': 126,\n",
       " 'pictures': 41,\n",
       " 'fan': 17,\n",
       " 'guess': 442,\n",
       " 'macbeth': 1,\n",
       " 'too': 960,\n",
       " 'enough': 254,\n",
       " 'ever': 403,\n",
       " 'club': 35,\n",
       " 'skunk': 4,\n",
       " 'still': 497,\n",
       " 'pissed': 13,\n",
       " 'love': 619,\n",
       " 'renew': 2,\n",
       " 'thy': 15,\n",
       " 'force': 13,\n",
       " 'demented': 2,\n",
       " 'see': 1426,\n",
       " 'next': 139,\n",
       " 'week': 119,\n",
       " 'microwave': 3,\n",
       " 'anyone': 155,\n",
       " 'cry': 24,\n",
       " 'today': 218,\n",
       " 'tumescent': 1,\n",
       " 'helping': 16,\n",
       " 'honey': 207,\n",
       " 'happened': 445,\n",
       " 'daughters': 8,\n",
       " 'went': 172,\n",
       " 'anything': 575,\n",
       " 'absolutely': 103,\n",
       " 'devil': 15,\n",
       " 'child': 62,\n",
       " 'crazy': 162,\n",
       " 'life': 218,\n",
       " 'others': 47,\n",
       " 'follow': 100,\n",
       " 'could': 655,\n",
       " 'be': 2255,\n",
       " 'gone': 181,\n",
       " 'years': 242,\n",
       " 'thank': 734,\n",
       " 'beatrix': 1,\n",
       " 'usually': 35,\n",
       " 'stay': 288,\n",
       " 'us': 645,\n",
       " 'am': 860,\n",
       " 'inside': 107,\n",
       " 'may': 243,\n",
       " 'whom': 23,\n",
       " 'bartolome': 1,\n",
       " 'giacomo': 1,\n",
       " 'colon': 4,\n",
       " 'alonso': 1,\n",
       " 'de': 42,\n",
       " 'bobadilla': 1,\n",
       " 'remember': 313,\n",
       " 'letters': 22,\n",
       " 'appointment': 11,\n",
       " 'viceroy': 1,\n",
       " 'west': 27,\n",
       " 'indies': 1,\n",
       " 'explore': 3,\n",
       " 'mainland': 1,\n",
       " 'feeling': 95,\n",
       " 'fernando': 2,\n",
       " 'bargaining': 1,\n",
       " 'ambitious': 3,\n",
       " 'defend': 7,\n",
       " 'admirably': 1,\n",
       " 'commoner': 1,\n",
       " 'come': 1347,\n",
       " 'speak': 115,\n",
       " 'first': 345,\n",
       " 'chief': 62,\n",
       " 'says': 158,\n",
       " 'thousands': 6,\n",
       " 'bring': 129,\n",
       " 'also': 52,\n",
       " 'medicine': 16,\n",
       " 'understands': 2,\n",
       " 'will': 969,\n",
       " 'help': 408,\n",
       " 'manage': 13,\n",
       " 'esdras': 1,\n",
       " 'jew': 14,\n",
       " 'christ': 129,\n",
       " 'marchena': 1,\n",
       " 'passion': 6,\n",
       " 'cannot': 52,\n",
       " 'control': 56,\n",
       " 'lies': 9,\n",
       " 'nomine': 3,\n",
       " 'patris': 1,\n",
       " 'et': 5,\n",
       " 'filius': 1,\n",
       " 'spiritus': 1,\n",
       " 'sancti': 1,\n",
       " 'forgive': 33,\n",
       " 'sinned': 4,\n",
       " 'believed': 9,\n",
       " 'give': 469,\n",
       " 'absolution': 1,\n",
       " 'suppose': 109,\n",
       " 'both': 123,\n",
       " 'men': 102,\n",
       " 'older': 32,\n",
       " 'disagree': 1,\n",
       " 'worlds': 10,\n",
       " 'create': 3,\n",
       " 'ocean': 14,\n",
       " 'uncrossable': 1,\n",
       " 'granada': 3,\n",
       " 'impregnable': 1,\n",
       " 'ignore': 7,\n",
       " 'verdict': 3,\n",
       " 'council': 2,\n",
       " 'surely': 26,\n",
       " 'freely': 3,\n",
       " 'show': 165,\n",
       " 'inclination': 1,\n",
       " 'otherwise': 23,\n",
       " 'raise': 30,\n",
       " 'wheel': 13,\n",
       " 'without': 111,\n",
       " 'horse': 30,\n",
       " 'read': 158,\n",
       " 'twenty': 176,\n",
       " 'eight': 145,\n",
       " 'immediately': 12,\n",
       " 'six': 161,\n",
       " 'days': 114,\n",
       " 'ago': 140,\n",
       " 'must': 391,\n",
       " 'mad': 46,\n",
       " 'land': 30,\n",
       " 'decide': 23,\n",
       " 'treasurer': 2,\n",
       " 'sanchez': 6,\n",
       " 'majesty': 24,\n",
       " 'suggest': 11,\n",
       " 'replaced': 5,\n",
       " 'tolerate': 4,\n",
       " 'impertinence': 1,\n",
       " 'afraid': 194,\n",
       " 'coming': 301,\n",
       " 'cigarettes': 28,\n",
       " '.delusions': 1,\n",
       " 'paranoia': 4,\n",
       " 'these': 243,\n",
       " 'alright': 264,\n",
       " 'justifiable': 1,\n",
       " 'homicide': 9,\n",
       " 'cop': 56,\n",
       " 'married': 187,\n",
       " 'divorced': 20,\n",
       " 'place': 243,\n",
       " 'somewhere': 72,\n",
       " '.the': 21,\n",
       " 'station': 31,\n",
       " 'empty': 18,\n",
       " 'considered': 6,\n",
       " 'becoming': 5,\n",
       " 'prostitute': 10,\n",
       " 'turn': 130,\n",
       " 'tricks': 10,\n",
       " 'back': 902,\n",
       " 'home': 409,\n",
       " 'asking': 70,\n",
       " 'eddie': 71,\n",
       " 'sorry': 761,\n",
       " 'boyfriend': 57,\n",
       " 'ludwig': 4,\n",
       " 'gay': 26,\n",
       " 'jealous': 32,\n",
       " 'better': 539,\n",
       " 'packed': 6,\n",
       " 'coffee': 101,\n",
       " 'kitchen': 24,\n",
       " 'some': 747,\n",
       " 'clothes': 61,\n",
       " 'pouring': 2,\n",
       " 'decision': 23,\n",
       " 'cause': 75,\n",
       " 'origin': 5,\n",
       " 'cleaned': 10,\n",
       " 'shower': 23,\n",
       " 'water': 103,\n",
       " 'sports': 6,\n",
       " 'korfin': 1,\n",
       " '.a': 42,\n",
       " 'videotape': 3,\n",
       " 'deposition': 3,\n",
       " 'finished': 61,\n",
       " 'gotta': 295,\n",
       " 'slow': 50,\n",
       " 'vodka': 19,\n",
       " 'tonic': 4,\n",
       " 'gonna': 465,\n",
       " 'propose': 2,\n",
       " 'lunch': 53,\n",
       " 'ready': 230,\n",
       " 'looking': 274,\n",
       " 'timer': 2,\n",
       " 'takin': 20,\n",
       " 'bath': 10,\n",
       " '.d': 23,\n",
       " '.pd': 1,\n",
       " 'guys': 174,\n",
       " 'checked': 26,\n",
       " 'hit': 113,\n",
       " 'boy': 265,\n",
       " 'popular': 6,\n",
       " 'sudden': 12,\n",
       " 'saying': 134,\n",
       " 'watch': 190,\n",
       " 'news': 72,\n",
       " 'nah': 63,\n",
       " 'musta': 8,\n",
       " 'missed': 78,\n",
       " 'tv': 46,\n",
       " 'commendable': 1,\n",
       " 'hmmmm': 8,\n",
       " 'polish': 11,\n",
       " 'folks': 27,\n",
       " 'escort': 3,\n",
       " 'service': 41,\n",
       " 'got': 1710,\n",
       " 'ideas': 21,\n",
       " 'ride': 79,\n",
       " 'along': 51,\n",
       " 'fire': 89,\n",
       " 'heads': 15,\n",
       " 'thirsty': 12,\n",
       " 'duty': 18,\n",
       " 'talk': 598,\n",
       " 'girlfriend': 74,\n",
       " 'serious': 128,\n",
       " '.who': 17,\n",
       " 'nicky': 17,\n",
       " 'accomplishment': 2,\n",
       " 'kill': 297,\n",
       " 'someone': 235,\n",
       " 'famous': 15,\n",
       " 'asshole': 77,\n",
       " 'victims': 8,\n",
       " 'bodies': 20,\n",
       " 'found': 173,\n",
       " 'crime': 12,\n",
       " 'scene': 20,\n",
       " 'patronize': 2,\n",
       " 'ruthless': 1,\n",
       " 'til': 14,\n",
       " 'promise': 147,\n",
       " 'later': 184,\n",
       " 'luck': 123,\n",
       " 'late': 215,\n",
       " 'unique': 2,\n",
       " 'keep': 317,\n",
       " 'jesus': 259,\n",
       " 'sausage': 3,\n",
       " 'bones': 16,\n",
       " 'dog': 89,\n",
       " 'food': 60,\n",
       " 'proposing': 3,\n",
       " 'gun': 142,\n",
       " 'czech': 6,\n",
       " 'documents': 5,\n",
       " 'please': 686,\n",
       " 'sir': 1029,\n",
       " 'weeks': 73,\n",
       " 'holiday': 11,\n",
       " 'much': 608,\n",
       " 'carrying': 22,\n",
       " 'five': 308,\n",
       " 'dollars': 111,\n",
       " 'join': 43,\n",
       " 'forward': 23,\n",
       " 'problem': 208,\n",
       " 'prague': 1,\n",
       " 'long': 501,\n",
       " 'planning': 22,\n",
       " 'himself': 47,\n",
       " 'english': 50,\n",
       " 'fool': 42,\n",
       " 'around': 295,\n",
       " 'document': 4,\n",
       " 'trip': 43,\n",
       " 'america': 30,\n",
       " 'smell': 57,\n",
       " 'chemicals': 5,\n",
       " '.for': 9,\n",
       " 'smoking': 33,\n",
       " 'drugs': 23,\n",
       " 'erase': 2,\n",
       " 'bathroom': 59,\n",
       " 'whatever': 123,\n",
       " 'fuck': 504,\n",
       " 'shut': 275,\n",
       " 'hurt': 155,\n",
       " 'shit': 498,\n",
       " 'film': 20,\n",
       " 'camera': 32,\n",
       " 'oleg': 1,\n",
       " 'shot': 113,\n",
       " 'sit': 140,\n",
       " 'emil': 2,\n",
       " 'surprise': 64,\n",
       " 'spent': 6,\n",
       " 'ha': 56,\n",
       " 'job': 196,\n",
       " 'plumber': 5,\n",
       " 'easy': 132,\n",
       " 'learn': 66,\n",
       " 'robert': 39,\n",
       " 'call': 586,\n",
       " 'viewer': 5,\n",
       " 'discretion': 2,\n",
       " 'advised': 1,\n",
       " 'tape': 43,\n",
       " 'paulie': 5,\n",
       " 'kids': 103,\n",
       " 'everything': 321,\n",
       " 'trying': 155,\n",
       " 'ahead': 131,\n",
       " 'cheap': 23,\n",
       " 'hotel': 62,\n",
       " 'movies': 42,\n",
       " 'thanks': 623,\n",
       " 'appreciate': 27,\n",
       " 'evidence': 17,\n",
       " 'mine': 156,\n",
       " 'argue': 13,\n",
       " 'collar': 6,\n",
       " 'killed': 207,\n",
       " 'partner': 30,\n",
       " 'department': 21,\n",
       " 'firemen': 4,\n",
       " 'carry': 32,\n",
       " 'guns': 33,\n",
       " 'again': 465,\n",
       " 'used': 118,\n",
       " 'accelerant': 2,\n",
       " 'kind': 293,\n",
       " 'woulda': 4,\n",
       " 'locked': 49,\n",
       " 'mouth': 68,\n",
       " 'clean': 55,\n",
       " 'blow': 33,\n",
       " 'nose': 28,\n",
       " 'stand': 94,\n",
       " 'livin': 4,\n",
       " 'question': 154,\n",
       " 'garcia': 2,\n",
       " 'bobby': 45,\n",
       " 'hurts': 18,\n",
       " 'aw': 41,\n",
       " 'lay': 24,\n",
       " 'outta': 52,\n",
       " 'hell': 434,\n",
       " 'continued': 17,\n",
       " 'wonderful': 78,\n",
       " 'sec': 5,\n",
       " 'salary': 5,\n",
       " 'cheques': 2,\n",
       " 'really': 890,\n",
       " 'very': 626,\n",
       " 'unlikely': 7,\n",
       " 'almost': 98,\n",
       " 'inconceivable': 4,\n",
       " 'logically': 2,\n",
       " 'impossible': 36,\n",
       " 'morning': 297,\n",
       " 'reasonably': 2,\n",
       " 'awake': 22,\n",
       " 'hal': 14,\n",
       " 'misunderstanding': 5,\n",
       " 'worry': 109,\n",
       " 'confidence': 10,\n",
       " 'fully': 6,\n",
       " 'restored': 3,\n",
       " 'frank': 131,\n",
       " 'antenna': 2,\n",
       " 'repairing': 1,\n",
       " 'dangerous': 50,\n",
       " 'operation': 9,\n",
       " 'explanation': 10,\n",
       " 'having': 82,\n",
       " 'sweetheart': 44,\n",
       " 'three': 333,\n",
       " 'darling': 88,\n",
       " 'mommy': 48,\n",
       " 'dresser': 2,\n",
       " 'mrs': 182,\n",
       " 'brown': 31,\n",
       " 'bye': 169,\n",
       " 'goodbye': 154,\n",
       " 'such': 100,\n",
       " 'delightful': 6,\n",
       " 'age': 23,\n",
       " 'gregor': 3,\n",
       " 'shall': 108,\n",
       " 'through': 184,\n",
       " 'documentation': 2,\n",
       " 'quite': 115,\n",
       " 'fortunately': 1,\n",
       " 'glad': 79,\n",
       " 'pod': 1,\n",
       " 'arms': 11,\n",
       " 'secure': 10,\n",
       " 'component': 1,\n",
       " 'roger': 38,\n",
       " 'understand': 250,\n",
       " 'maintain': 6,\n",
       " 'normal': 34,\n",
       " '.v': 11,\n",
       " 'condition': 25,\n",
       " 'check': 164,\n",
       " 'airlock': 3,\n",
       " 'doors': 19,\n",
       " 'car': 340,\n",
       " 'name': 687,\n",
       " 'hammond': 5,\n",
       " 'wash': 15,\n",
       " 'em': 212,\n",
       " 'chargin': 1,\n",
       " 'battery': 4,\n",
       " 'black': 104,\n",
       " 'russian': 21,\n",
       " 'shoulda': 9,\n",
       " 'stole': 37,\n",
       " 'truck': 55,\n",
       " 'tonto': 1,\n",
       " 'big': 249,\n",
       " 'convict': 5,\n",
       " 'drive': 117,\n",
       " 'ain': 265,\n",
       " 'yet': 295,\n",
       " 'whaddya': 8,\n",
       " 'buy': 93,\n",
       " 'pros': 2,\n",
       " 'pay': 98,\n",
       " 'dummy': 8,\n",
       " 'paid': 43,\n",
       " 'hurry': 100,\n",
       " 'waiting': 110,\n",
       " 'quit': 70,\n",
       " 'bein': 4,\n",
       " 'priest': 14,\n",
       " 'somethin': 51,\n",
       " 'visitors': 9,\n",
       " 'chance': 73,\n",
       " 'ganz': 2,\n",
       " 'corridor': 7,\n",
       " 'lot': 179,\n",
       " 'protect': 25,\n",
       " 'bullshit': 87,\n",
       " 'luther': 4,\n",
       " 'part': 62,\n",
       " 'gang': 8,\n",
       " 'talkin': 24,\n",
       " 'jack': 213,\n",
       " 'works': 69,\n",
       " 'mission': 20,\n",
       " 'district': 9,\n",
       " 'find': 348,\n",
       " 'indian': 11,\n",
       " 'details': 13,\n",
       " 'nights': 19,\n",
       " 'billy': 45,\n",
       " 'half': 130,\n",
       " 'million': 65,\n",
       " 'split': 19,\n",
       " 'likely': 7,\n",
       " 'primo': 1,\n",
       " 'bondsman': 2,\n",
       " 'move': 168,\n",
       " 'notice': 32,\n",
       " 'bus': 44,\n",
       " 'four': 215,\n",
       " 'stops': 3,\n",
       " 'closing': 16,\n",
       " 'play': 167,\n",
       " 'maker': 4,\n",
       " 'anthing': 1,\n",
       " 'botherin': 3,\n",
       " 'besides': 27,\n",
       " 'losin': 3,\n",
       " 'bell': 11,\n",
       " 'pulled': 22,\n",
       " 'trigger': 3,\n",
       " 'yards': 16,\n",
       " 'couldn': 121,\n",
       " 'cates': 1,\n",
       " 'same': 178,\n",
       " 'dick': 53,\n",
       " 'tracy': 9,\n",
       " 'wrong': 478,\n",
       " 'red': 73,\n",
       " 'heading': 19,\n",
       " 'hopeless': 7,\n",
       " 'wet': 21,\n",
       " 'dyin': 2,\n",
       " 'fairly': 2,\n",
       " 'crummy': 1,\n",
       " 'day': 299,\n",
       " 'nice': 382,\n",
       " 'favorites': 5,\n",
       " 'made': 227,\n",
       " 'front': 47,\n",
       " 'page': 27,\n",
       " 'wait': 412,\n",
       " 'second': 128,\n",
       " 'hello': 616,\n",
       " 'hiya': 15,\n",
       " 'kid': 132,\n",
       " 'hours': 77,\n",
       " 'hard': 123,\n",
       " 'bull': 13,\n",
       " 'stall': 5,\n",
       " 'stallin': 1,\n",
       " '.hold': 1,\n",
       " 'complain': 8,\n",
       " 'times': 112,\n",
       " 'partners': 17,\n",
       " 'break': 72,\n",
       " 'outside': 73,\n",
       " 'naw': 36,\n",
       " 'mess': 28,\n",
       " 'bills': 4,\n",
       " 'credit': 18,\n",
       " 'business': 200,\n",
       " 'appipulai': 1,\n",
       " 'leeloo': 3,\n",
       " 'minai': 2,\n",
       " 'corn': 3,\n",
       " 'lius': 2,\n",
       " 'laughing': 13,\n",
       " 'napoleon': 2,\n",
       " 'small': 60,\n",
       " 'san': 20,\n",
       " 'agamat': 1,\n",
       " 'chay': 1,\n",
       " 'bet': 154,\n",
       " 'envolet': 1,\n",
       " 'case': 93,\n",
       " 'stolen': 15,\n",
       " 'ikset': 1,\n",
       " 'kiba': 1,\n",
       " 'imanetaba': 1,\n",
       " 'oum': 1,\n",
       " 'dalat': 1,\n",
       " '.we': 9,\n",
       " 'saved': 42,\n",
       " 'fucked': 55,\n",
       " '.would': 2,\n",
       " 'monster': 21,\n",
       " 'zorg': 1,\n",
       " 'weddings': 4,\n",
       " 'floor': 43,\n",
       " 'congratulations': 49,\n",
       " 'brought': 70,\n",
       " 'noticed': 16,\n",
       " 'family': 84,\n",
       " 'exception': 8,\n",
       " 'means': 82,\n",
       " 'permission': 23,\n",
       " 'save': 57,\n",
       " 'world': 74,\n",
       " 'course': 456,\n",
       " 'trouble': 136,\n",
       " 'stop': 360,\n",
       " '.thank': 2,\n",
       " 'miracle': 16,\n",
       " 'perfect': 74,\n",
       " 'bud': 34,\n",
       " 'finger': 13,\n",
       " 'picture': 57,\n",
       " 'least': 73,\n",
       " 'dreams': 23,\n",
       " 'akina': 1,\n",
       " 'delutan': 1,\n",
       " 'nou': 1,\n",
       " 'shan': 3,\n",
       " 'scuse': 1,\n",
       " '.what': 62,\n",
       " 'lekarariba': 1,\n",
       " 'laminai': 1,\n",
       " 'tchai': 1,\n",
       " 'ekbat': 1,\n",
       " 'sebat': 1,\n",
       " 'returns': 5,\n",
       " 'lord': 68,\n",
       " 'listening': 42,\n",
       " 'ingrate': 1,\n",
       " 'ma': 164,\n",
       " 'together': 116,\n",
       " '.not': 9,\n",
       " 'sleaze': 2,\n",
       " 'bag': 54,\n",
       " '.ma': 2,\n",
       " 'fuel': 9,\n",
       " 'level': 20,\n",
       " '.propulsion': 1,\n",
       " 'x': 11,\n",
       " 'goddamn': 76,\n",
       " 'nightmare': 15,\n",
       " 'police': 105,\n",
       " 'action': 11,\n",
       " '.hi': 7,\n",
       " 'fly': 24,\n",
       " 'cab': 22,\n",
       " 'song': 38,\n",
       " 'open': 171,\n",
       " 'messages': 10,\n",
       " 'best': 151,\n",
       " 'eh': 106,\n",
       " ...}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.word2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function to remove words which does not repeat more than 3 times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_COUNT = 3\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    voc.trim(MIN_COUNT)\n",
    "    keep_pairs = []\n",
    "    \n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        \n",
    "        keep_input= True\n",
    "        keep_output = True\n",
    "        \n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        \n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "        \n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "            \n",
    "    print('Trimmed from {} pairs to {}, {:.4f}% of Total'.format(len(pairs), len(keep_pairs),\n",
    "                                                                 len(pairs)/len(keep_pairs)))\n",
    "    return keep_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 7823 / 18005 = 0.4345\n",
      "Trimmed from 64271 pairs to 53165, 1.2089% of Total\n"
     ]
    }
   ],
   "source": [
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an index from the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')]+[EOS_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there .', 'you have my word . as a gentleman', 'hi .', 'have fun tonight ?', 'well no . . .', 'then that s all you had to say .', 'but', 'do you listen to this crap ?', 'what good stuff ?', 'wow']\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3, 4, 2],\n",
       " [7, 8, 9, 10, 4, 11, 12, 13, 2],\n",
       " [16, 4, 2],\n",
       " [8, 31, 22, 6, 2],\n",
       " [33, 34, 4, 4, 4, 2],\n",
       " [35, 36, 37, 38, 7, 39, 40, 41, 4, 2],\n",
       " [42, 2],\n",
       " [47, 7, 48, 40, 45, 49, 6, 2],\n",
       " [50, 51, 52, 6, 2],\n",
       " [58, 2]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = []\n",
    "out = []\n",
    "\n",
    "for pair in pairs[:10]:  #create a test pair for indexing\n",
    "    inp.append(pair[0])\n",
    "    out.append(pair[1])\n",
    "    \n",
    "print(inp)\n",
    "print(len(inp))\n",
    "\n",
    "indexes = [indexesFromSentence(voc, sentence) for sentence in inp]\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[3, 4, 2],\n",
    " [7, 8, 9, 10, 4, 11, 12, 13, 2],\n",
    " [16, 4, 2],\n",
    " [8, 31, 22, 6, 2],\n",
    " [33, 34, 4, 4, 4, 2],\n",
    " [35, 36, 37, 38, 7, 39, 40, 41, 4, 2],\n",
    " [42, 2],\n",
    " [47, 7, 48, 40, 45, 49, 6, 2],\n",
    " [50, 51, 52, 6, 2],\n",
    " [58, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip_longest used to zip the indexes together and fill missing values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 7, 16, 8, 33, 35, 42, 47, 50, 58),\n",
       " (4, 8, 4, 31, 34, 36, 2, 7, 51, 2),\n",
       " (2, 9, 2, 22, 4, 37, 0, 48, 52, 0),\n",
       " (0, 10, 0, 6, 4, 38, 0, 40, 6, 0),\n",
       " (0, 4, 0, 2, 4, 7, 0, 45, 2, 0),\n",
       " (0, 11, 0, 0, 2, 39, 0, 49, 0, 0),\n",
       " (0, 12, 0, 0, 0, 40, 0, 6, 0, 0),\n",
       " (0, 13, 0, 0, 0, 41, 0, 2, 0, 0),\n",
       " (0, 2, 0, 0, 0, 4, 0, 0, 0, 0),\n",
       " (0, 0, 0, 0, 0, 2, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.zip_longest(*a, fillvalue=0)) #how we zip the indexes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroPadding(l, fillvalue=0):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 7, 16, 8, 33, 35, 42, 47, 50, 58),\n",
       " (4, 8, 4, 31, 34, 36, 2, 7, 51, 2),\n",
       " (2, 9, 2, 22, 4, 37, 0, 48, 52, 0),\n",
       " (0, 10, 0, 6, 4, 38, 0, 40, 6, 0),\n",
       " (0, 4, 0, 2, 4, 7, 0, 45, 2, 0),\n",
       " (0, 11, 0, 0, 2, 39, 0, 49, 0, 0),\n",
       " (0, 12, 0, 0, 0, 40, 0, 6, 0, 0),\n",
       " (0, 13, 0, 0, 0, 41, 0, 2, 0, 0),\n",
       " (0, 2, 0, 0, 0, 4, 0, 0, 0, 0),\n",
       " (0, 0, 0, 0, 0, 2, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = zeroPadding(indexes, fillvalue=0)\n",
    "\n",
    "print(len(test_result))\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to convert to binary matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryMatrix(l, value = 0):\n",
    "    m = []\n",
    "    for i,seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],\n",
       " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
       " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
       " [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_result = binaryMatrix(test_result)\n",
    "\n",
    "binary_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for converting pairs into input and output tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x:len(x[0].split(' ')), reverse=True)  #sort the 1st chat of pair in descending order number of words\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"small_batch_size = 5\\nbatches = batch2TrainData(voc,[random.choice(pairs) for _ in range(small_batch_size)])\\ninput_variable, lengths, target_variable, mask, max_target_len = batches\\n\\nprint('input variable:', input_variable)\\nprint('lengths', lengths)\\nprint('target variable', target_variable)\\nprint('mask', mask)\\nprint('max_target_len:', max_target_len)\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''small_batch_size = 5\n",
    "batches = batch2TrainData(voc,[random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print('input variable:', input_variable)\n",
    "print('lengths', lengths)\n",
    "print('target variable', target_variable)\n",
    "print('mask', mask)\n",
    "print('max_target_len:', max_target_len)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model\n",
    "\n",
    "### 1. We are using bi-directional GRU enocder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN,self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout = (0 if n_layers == 1 else dropout), \n",
    "                          bidirectional = True)\n",
    "    \n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        embedded =  self.embedding(input_seq)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        outputs = outputs[:,:,:self.hidden_size] + outputs[:,:,self.hidden_size:]\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def dot_score(self, hidden, encoder_outputs):\n",
    "        return torch.sum(hidden * encoder_outputs, dim =2)\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "        attn_energies = attn_energies.t()\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        #Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, \n",
    "                          dropout=(0 if n_layers ==1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "    \n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0,1))\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context),1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        return output, hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(decoder_out, target, mask):\n",
    "    nTotal = mask.sum()  #() added to sum\n",
    "    target = target.view(-1,1)\n",
    "    gathered_tensor = torch.gather(decoder_out, 1, target)\n",
    "    crossEntropy = -torch.log(gathered_tensor)\n",
    "    loss = crossEntropy.masked_select(mask)\n",
    "    loss = loss.mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by step visulaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'small_batch_size = 5\\nbatches = batch2TrainData(voc,[random.choice(pairs) for _ in range(small_batch_size)])\\ninput_variable, lengths, target_variable, mask, max_target_len = batches\\n\\nprint(\\'input variable:\\', input_variable)\\nprint(\\'lengths\\', lengths)\\nprint(\\'target variable\\', target_variable)\\nprint(\\'mask\\', mask)\\nprint(\\'max_target_len:\\', max_target_len)\\n\\n#Define parameters\\nhidden_size= 500\\nencoder_n_layers = 2\\ndecoder_n_layers = 2\\ndropout = 0.1\\nattn_model = \\'dot\\'\\nembedding = nn.Embedding(voc.num_words, hidden_size)\\n\\n#Define the enocder & decoder\\nencoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\\ndecoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\\nencoder = encoder.to(device)\\ndecoder = decoder.to(device)\\n\\nencoder.train()\\ndecoder.train()\\n\\nencoder_optimizer = optim.Adam(encoder.parameters(), lr = 0.0001)\\ndecoder_optimizer = optim.Adam(decoder.parameters(), lr = 0.0001)\\nencoder_optimizer.zero_grad()\\ndecoder_optimizer.zero_grad()\\n\\ninput_variable = input_variable.to(device)\\nlengths = lengths.to(device)\\ntarget_variable = target_variable.to(device)\\nmask = mask.to(device)\\n\\nloss = 0\\nprint_losses = []\\nn_totals = 0\\n\\nencoder_outputs, encoder_hidden = encoder(input_variable, lengths)\\nprint(\"Encoder Outputs Shape:\", encoder_outputs.shape)\\nprint(\"Last Encoder Hidden Shape\", encoder_hidden.shape)\\n\\ndecoder_input = torch.LongTensor([[SOS_token for _ in range(small_batch_size)]])\\ndecoder_input = decoder_input.to(device)\\nprint(\"Initial Decoder Input Shape:\", decoder_input.shape)\\nprint(decoder_input)\\n\\ndecoder_hidden = encoder_hidden[:decoder.n_layers]\\nprint(\"Initial Decoder hidden state shape:\", decoder_hidden.shape)\\nprint(\"\\n\")\\nprint(\"------------------------------------------------------------------------------\")\\nprint(\"Now let us look at what is happening in every timestep of the GRU!\")\\nprint(\"------------------------------------------------------------------------------\")\\n\\n\\nfor t in range(max_target_len):\\n    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\\n    print(\"Decoder Output Shape:\", decoder_output.shape)\\n    print(\"Decoder Hidden Shape:\", decoder_hidden.shape)\\n    \\n    decoder_input = target_variable[t].view(1,-1)\\n    print(\"The target variable at the currrent timestep before reshaping:\", target_variable[t])\\n    print(\"The target variable at the curent timestep shape before reshaping:\", target_variable[t].shape)\\n    print(\"The Decoder input shape(reshape the target variable): \", decoder_input.shape)\\n    \\n    print(\"The mask at the current timestep:\", mask[t])\\n    print(\"The mask at the current timestep shape:\", mask[t].shape)\\n    mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\\n    print(\"Mask Loss:\", mask_loss)\\n    print(\"Total:\", nTotal)\\n    loss+=mask_loss\\n    print_losses.append(mask_loss.item() * nTotal)\\n    print(print_losses)\\n    n_totals+=nTotal\\n    print(n_totals)\\n    encoder_optimizer.step()\\n    decoder_optimizer.step()\\n    returned_loss = sum(print_losses) / n_totals\\n    print(\"Returned Loss:\", returned_loss)\\n    print(\"\\n\")\\n    print(\"-------------------------------DONE ONE TIMESTEP---------------------------------\")\\n    print(\"\\n\")'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''small_batch_size = 5\n",
    "batches = batch2TrainData(voc,[random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print('input variable:', input_variable)\n",
    "print('lengths', lengths)\n",
    "print('target variable', target_variable)\n",
    "print('mask', mask)\n",
    "print('max_target_len:', max_target_len)\n",
    "\n",
    "#Define parameters\n",
    "hidden_size= 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "attn_model = 'dot'\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "\n",
    "#Define the enocder & decoder\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr = 0.0001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr = 0.0001)\n",
    "encoder_optimizer.zero_grad()\n",
    "decoder_optimizer.zero_grad()\n",
    "\n",
    "input_variable = input_variable.to(device)\n",
    "lengths = lengths.to(device)\n",
    "target_variable = target_variable.to(device)\n",
    "mask = mask.to(device)\n",
    "\n",
    "loss = 0\n",
    "print_losses = []\n",
    "n_totals = 0\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "print(\"Encoder Outputs Shape:\", encoder_outputs.shape)\n",
    "print(\"Last Encoder Hidden Shape\", encoder_hidden.shape)\n",
    "\n",
    "decoder_input = torch.LongTensor([[SOS_token for _ in range(small_batch_size)]])\n",
    "decoder_input = decoder_input.to(device)\n",
    "print(\"Initial Decoder Input Shape:\", decoder_input.shape)\n",
    "print(decoder_input)\n",
    "\n",
    "decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "print(\"Initial Decoder hidden state shape:\", decoder_hidden.shape)\n",
    "print(\"\\n\")\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"Now let us look at what is happening in every timestep of the GRU!\")\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "for t in range(max_target_len):\n",
    "    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    print(\"Decoder Output Shape:\", decoder_output.shape)\n",
    "    print(\"Decoder Hidden Shape:\", decoder_hidden.shape)\n",
    "    \n",
    "    decoder_input = target_variable[t].view(1,-1)\n",
    "    print(\"The target variable at the currrent timestep before reshaping:\", target_variable[t])\n",
    "    print(\"The target variable at the curent timestep shape before reshaping:\", target_variable[t].shape)\n",
    "    print(\"The Decoder input shape(reshape the target variable): \", decoder_input.shape)\n",
    "    \n",
    "    print(\"The mask at the current timestep:\", mask[t])\n",
    "    print(\"The mask at the current timestep shape:\", mask[t].shape)\n",
    "    mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "    print(\"Mask Loss:\", mask_loss)\n",
    "    print(\"Total:\", nTotal)\n",
    "    loss+=mask_loss\n",
    "    print_losses.append(mask_loss.item() * nTotal)\n",
    "    print(print_losses)\n",
    "    n_totals+=nTotal\n",
    "    print(n_totals)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    returned_loss = sum(print_losses) / n_totals\n",
    "    print(\"Returned Loss:\", returned_loss)\n",
    "    print(\"\\n\")\n",
    "    print(\"-------------------------------DONE ONE TIMESTEP---------------------------------\")\n",
    "    print(\"\\n\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, \n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length = MAX_LENGTH):\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "    \n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "    \n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "    \n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_input = target_variable[t].view(1,-1)\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss+=mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals+=nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            _,topi = decoder_optput.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss+=mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals+=nTotal\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return sum(print_losses)/ n_totals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, \n",
    "               embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, \n",
    "               print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None\n",
    "checkpoint_iter = 4000\n",
    "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n",
      "Iteration: 1; Percent complete: 0.0%; Average loss: 8.9682\n",
      "Iteration: 2; Percent complete: 0.1%; Average loss: 8.7466\n",
      "Iteration: 3; Percent complete: 0.1%; Average loss: 8.5202\n",
      "Iteration: 4; Percent complete: 0.1%; Average loss: 7.9875\n",
      "Iteration: 5; Percent complete: 0.1%; Average loss: 7.6512\n",
      "Iteration: 6; Percent complete: 0.1%; Average loss: 6.8905\n",
      "Iteration: 7; Percent complete: 0.2%; Average loss: 6.5037\n",
      "Iteration: 8; Percent complete: 0.2%; Average loss: 6.7799\n",
      "Iteration: 9; Percent complete: 0.2%; Average loss: 6.4198\n",
      "Iteration: 10; Percent complete: 0.2%; Average loss: 6.2929\n",
      "Iteration: 11; Percent complete: 0.3%; Average loss: 5.4661\n",
      "Iteration: 12; Percent complete: 0.3%; Average loss: 5.9222\n",
      "Iteration: 13; Percent complete: 0.3%; Average loss: 5.1892\n",
      "Iteration: 14; Percent complete: 0.4%; Average loss: 4.8910\n",
      "Iteration: 15; Percent complete: 0.4%; Average loss: 4.8181\n",
      "Iteration: 16; Percent complete: 0.4%; Average loss: 4.9370\n",
      "Iteration: 17; Percent complete: 0.4%; Average loss: 4.6601\n",
      "Iteration: 18; Percent complete: 0.4%; Average loss: 4.5252\n",
      "Iteration: 19; Percent complete: 0.5%; Average loss: 4.6361\n",
      "Iteration: 20; Percent complete: 0.5%; Average loss: 4.6734\n",
      "Iteration: 21; Percent complete: 0.5%; Average loss: 4.6090\n",
      "Iteration: 22; Percent complete: 0.5%; Average loss: 4.2844\n",
      "Iteration: 23; Percent complete: 0.6%; Average loss: 4.3974\n",
      "Iteration: 24; Percent complete: 0.6%; Average loss: 4.2635\n",
      "Iteration: 25; Percent complete: 0.6%; Average loss: 4.2972\n",
      "Iteration: 26; Percent complete: 0.7%; Average loss: 3.9490\n",
      "Iteration: 27; Percent complete: 0.7%; Average loss: 4.3305\n",
      "Iteration: 28; Percent complete: 0.7%; Average loss: 4.2341\n",
      "Iteration: 29; Percent complete: 0.7%; Average loss: 4.3085\n",
      "Iteration: 30; Percent complete: 0.8%; Average loss: 3.9436\n",
      "Iteration: 31; Percent complete: 0.8%; Average loss: 4.1233\n",
      "Iteration: 32; Percent complete: 0.8%; Average loss: 3.9559\n",
      "Iteration: 33; Percent complete: 0.8%; Average loss: 4.1783\n",
      "Iteration: 34; Percent complete: 0.9%; Average loss: 4.2923\n",
      "Iteration: 35; Percent complete: 0.9%; Average loss: 4.2142\n",
      "Iteration: 36; Percent complete: 0.9%; Average loss: 4.1576\n",
      "Iteration: 37; Percent complete: 0.9%; Average loss: 4.0278\n",
      "Iteration: 38; Percent complete: 0.9%; Average loss: 3.8451\n",
      "Iteration: 39; Percent complete: 1.0%; Average loss: 4.1299\n",
      "Iteration: 40; Percent complete: 1.0%; Average loss: 3.9425\n",
      "Iteration: 41; Percent complete: 1.0%; Average loss: 3.9464\n",
      "Iteration: 42; Percent complete: 1.1%; Average loss: 4.1229\n",
      "Iteration: 43; Percent complete: 1.1%; Average loss: 4.0473\n",
      "Iteration: 44; Percent complete: 1.1%; Average loss: 4.3407\n",
      "Iteration: 45; Percent complete: 1.1%; Average loss: 4.0182\n",
      "Iteration: 46; Percent complete: 1.1%; Average loss: 4.0029\n",
      "Iteration: 47; Percent complete: 1.2%; Average loss: 4.0375\n",
      "Iteration: 48; Percent complete: 1.2%; Average loss: 3.9466\n",
      "Iteration: 49; Percent complete: 1.2%; Average loss: 3.8249\n",
      "Iteration: 50; Percent complete: 1.2%; Average loss: 3.9195\n",
      "Iteration: 51; Percent complete: 1.3%; Average loss: 4.0714\n",
      "Iteration: 52; Percent complete: 1.3%; Average loss: 3.9977\n",
      "Iteration: 53; Percent complete: 1.3%; Average loss: 4.0015\n",
      "Iteration: 54; Percent complete: 1.4%; Average loss: 3.6296\n",
      "Iteration: 55; Percent complete: 1.4%; Average loss: 4.1983\n",
      "Iteration: 56; Percent complete: 1.4%; Average loss: 4.0541\n",
      "Iteration: 57; Percent complete: 1.4%; Average loss: 3.9737\n",
      "Iteration: 58; Percent complete: 1.5%; Average loss: 4.0284\n",
      "Iteration: 59; Percent complete: 1.5%; Average loss: 3.9303\n",
      "Iteration: 60; Percent complete: 1.5%; Average loss: 4.2754\n",
      "Iteration: 61; Percent complete: 1.5%; Average loss: 3.8851\n",
      "Iteration: 62; Percent complete: 1.6%; Average loss: 3.9418\n",
      "Iteration: 63; Percent complete: 1.6%; Average loss: 4.0348\n",
      "Iteration: 64; Percent complete: 1.6%; Average loss: 3.7876\n",
      "Iteration: 65; Percent complete: 1.6%; Average loss: 4.0497\n",
      "Iteration: 66; Percent complete: 1.7%; Average loss: 3.8628\n",
      "Iteration: 67; Percent complete: 1.7%; Average loss: 3.9892\n",
      "Iteration: 68; Percent complete: 1.7%; Average loss: 3.7576\n",
      "Iteration: 69; Percent complete: 1.7%; Average loss: 3.9751\n",
      "Iteration: 70; Percent complete: 1.8%; Average loss: 3.9673\n",
      "Iteration: 71; Percent complete: 1.8%; Average loss: 3.9749\n",
      "Iteration: 72; Percent complete: 1.8%; Average loss: 3.7609\n",
      "Iteration: 73; Percent complete: 1.8%; Average loss: 3.6564\n",
      "Iteration: 74; Percent complete: 1.8%; Average loss: 3.9894\n",
      "Iteration: 75; Percent complete: 1.9%; Average loss: 4.1470\n",
      "Iteration: 76; Percent complete: 1.9%; Average loss: 3.8305\n",
      "Iteration: 77; Percent complete: 1.9%; Average loss: 3.5601\n",
      "Iteration: 78; Percent complete: 1.9%; Average loss: 3.5954\n",
      "Iteration: 79; Percent complete: 2.0%; Average loss: 3.8900\n",
      "Iteration: 80; Percent complete: 2.0%; Average loss: 3.9406\n",
      "Iteration: 81; Percent complete: 2.0%; Average loss: 3.8451\n",
      "Iteration: 82; Percent complete: 2.1%; Average loss: 3.5745\n",
      "Iteration: 83; Percent complete: 2.1%; Average loss: 3.9780\n",
      "Iteration: 84; Percent complete: 2.1%; Average loss: 3.5837\n",
      "Iteration: 85; Percent complete: 2.1%; Average loss: 3.6625\n",
      "Iteration: 86; Percent complete: 2.1%; Average loss: 3.9426\n",
      "Iteration: 87; Percent complete: 2.2%; Average loss: 3.8696\n",
      "Iteration: 88; Percent complete: 2.2%; Average loss: 4.0507\n",
      "Iteration: 89; Percent complete: 2.2%; Average loss: 4.1594\n",
      "Iteration: 90; Percent complete: 2.2%; Average loss: 3.9020\n",
      "Iteration: 91; Percent complete: 2.3%; Average loss: 3.9113\n",
      "Iteration: 92; Percent complete: 2.3%; Average loss: 3.9118\n",
      "Iteration: 93; Percent complete: 2.3%; Average loss: 3.8602\n",
      "Iteration: 94; Percent complete: 2.4%; Average loss: 3.7149\n",
      "Iteration: 95; Percent complete: 2.4%; Average loss: 3.6559\n",
      "Iteration: 96; Percent complete: 2.4%; Average loss: 3.7013\n",
      "Iteration: 97; Percent complete: 2.4%; Average loss: 3.8495\n",
      "Iteration: 98; Percent complete: 2.5%; Average loss: 3.6277\n",
      "Iteration: 99; Percent complete: 2.5%; Average loss: 3.9990\n",
      "Iteration: 100; Percent complete: 2.5%; Average loss: 3.9171\n",
      "Iteration: 101; Percent complete: 2.5%; Average loss: 3.8722\n",
      "Iteration: 102; Percent complete: 2.5%; Average loss: 3.9540\n",
      "Iteration: 103; Percent complete: 2.6%; Average loss: 3.9502\n",
      "Iteration: 104; Percent complete: 2.6%; Average loss: 3.9108\n",
      "Iteration: 105; Percent complete: 2.6%; Average loss: 3.9023\n",
      "Iteration: 106; Percent complete: 2.6%; Average loss: 3.5388\n",
      "Iteration: 107; Percent complete: 2.7%; Average loss: 3.9874\n",
      "Iteration: 108; Percent complete: 2.7%; Average loss: 3.7323\n",
      "Iteration: 109; Percent complete: 2.7%; Average loss: 3.6066\n",
      "Iteration: 110; Percent complete: 2.8%; Average loss: 3.7193\n",
      "Iteration: 111; Percent complete: 2.8%; Average loss: 3.7693\n",
      "Iteration: 112; Percent complete: 2.8%; Average loss: 3.5920\n",
      "Iteration: 113; Percent complete: 2.8%; Average loss: 3.9716\n",
      "Iteration: 114; Percent complete: 2.9%; Average loss: 3.9179\n",
      "Iteration: 115; Percent complete: 2.9%; Average loss: 3.6670\n",
      "Iteration: 116; Percent complete: 2.9%; Average loss: 3.7252\n",
      "Iteration: 117; Percent complete: 2.9%; Average loss: 3.7215\n",
      "Iteration: 118; Percent complete: 2.9%; Average loss: 3.7123\n",
      "Iteration: 119; Percent complete: 3.0%; Average loss: 3.9457\n",
      "Iteration: 120; Percent complete: 3.0%; Average loss: 3.7615\n",
      "Iteration: 121; Percent complete: 3.0%; Average loss: 3.6677\n",
      "Iteration: 122; Percent complete: 3.0%; Average loss: 3.7973\n",
      "Iteration: 123; Percent complete: 3.1%; Average loss: 3.4189\n",
      "Iteration: 124; Percent complete: 3.1%; Average loss: 3.8131\n",
      "Iteration: 125; Percent complete: 3.1%; Average loss: 3.9990\n",
      "Iteration: 126; Percent complete: 3.1%; Average loss: 3.4964\n",
      "Iteration: 127; Percent complete: 3.2%; Average loss: 3.5485\n",
      "Iteration: 128; Percent complete: 3.2%; Average loss: 3.8069\n",
      "Iteration: 129; Percent complete: 3.2%; Average loss: 3.4514\n",
      "Iteration: 130; Percent complete: 3.2%; Average loss: 3.6385\n",
      "Iteration: 131; Percent complete: 3.3%; Average loss: 3.4696\n",
      "Iteration: 132; Percent complete: 3.3%; Average loss: 3.6087\n",
      "Iteration: 133; Percent complete: 3.3%; Average loss: 3.4511\n",
      "Iteration: 134; Percent complete: 3.4%; Average loss: 3.5206\n",
      "Iteration: 135; Percent complete: 3.4%; Average loss: 3.8648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 136; Percent complete: 3.4%; Average loss: 3.7693\n",
      "Iteration: 137; Percent complete: 3.4%; Average loss: 3.7230\n",
      "Iteration: 138; Percent complete: 3.5%; Average loss: 3.7412\n",
      "Iteration: 139; Percent complete: 3.5%; Average loss: 3.6472\n",
      "Iteration: 140; Percent complete: 3.5%; Average loss: 3.6630\n",
      "Iteration: 141; Percent complete: 3.5%; Average loss: 3.4587\n",
      "Iteration: 142; Percent complete: 3.5%; Average loss: 3.6421\n",
      "Iteration: 143; Percent complete: 3.6%; Average loss: 3.5282\n",
      "Iteration: 144; Percent complete: 3.6%; Average loss: 3.6722\n",
      "Iteration: 145; Percent complete: 3.6%; Average loss: 3.7428\n",
      "Iteration: 146; Percent complete: 3.6%; Average loss: 3.5540\n",
      "Iteration: 147; Percent complete: 3.7%; Average loss: 3.6635\n",
      "Iteration: 148; Percent complete: 3.7%; Average loss: 3.9120\n",
      "Iteration: 149; Percent complete: 3.7%; Average loss: 3.5492\n",
      "Iteration: 150; Percent complete: 3.8%; Average loss: 3.7582\n",
      "Iteration: 151; Percent complete: 3.8%; Average loss: 3.6253\n",
      "Iteration: 152; Percent complete: 3.8%; Average loss: 3.6869\n",
      "Iteration: 153; Percent complete: 3.8%; Average loss: 3.8913\n",
      "Iteration: 154; Percent complete: 3.9%; Average loss: 3.8186\n",
      "Iteration: 155; Percent complete: 3.9%; Average loss: 3.8723\n",
      "Iteration: 156; Percent complete: 3.9%; Average loss: 3.5872\n",
      "Iteration: 157; Percent complete: 3.9%; Average loss: 3.5906\n",
      "Iteration: 158; Percent complete: 4.0%; Average loss: 3.5609\n",
      "Iteration: 159; Percent complete: 4.0%; Average loss: 3.5742\n",
      "Iteration: 160; Percent complete: 4.0%; Average loss: 3.4384\n",
      "Iteration: 161; Percent complete: 4.0%; Average loss: 3.6444\n",
      "Iteration: 162; Percent complete: 4.0%; Average loss: 3.7869\n",
      "Iteration: 163; Percent complete: 4.1%; Average loss: 3.5589\n",
      "Iteration: 164; Percent complete: 4.1%; Average loss: 3.4128\n",
      "Iteration: 165; Percent complete: 4.1%; Average loss: 3.4326\n",
      "Iteration: 166; Percent complete: 4.2%; Average loss: 3.6631\n",
      "Iteration: 167; Percent complete: 4.2%; Average loss: 3.5802\n",
      "Iteration: 168; Percent complete: 4.2%; Average loss: 3.6451\n",
      "Iteration: 169; Percent complete: 4.2%; Average loss: 3.5858\n",
      "Iteration: 170; Percent complete: 4.2%; Average loss: 3.4964\n",
      "Iteration: 171; Percent complete: 4.3%; Average loss: 3.3598\n",
      "Iteration: 172; Percent complete: 4.3%; Average loss: 3.8147\n",
      "Iteration: 173; Percent complete: 4.3%; Average loss: 3.6960\n",
      "Iteration: 174; Percent complete: 4.3%; Average loss: 3.4824\n",
      "Iteration: 175; Percent complete: 4.4%; Average loss: 3.4466\n",
      "Iteration: 176; Percent complete: 4.4%; Average loss: 3.8282\n",
      "Iteration: 177; Percent complete: 4.4%; Average loss: 3.9132\n",
      "Iteration: 178; Percent complete: 4.5%; Average loss: 3.5583\n",
      "Iteration: 179; Percent complete: 4.5%; Average loss: 3.6010\n",
      "Iteration: 180; Percent complete: 4.5%; Average loss: 3.5229\n",
      "Iteration: 181; Percent complete: 4.5%; Average loss: 3.5006\n",
      "Iteration: 182; Percent complete: 4.5%; Average loss: 3.5322\n",
      "Iteration: 183; Percent complete: 4.6%; Average loss: 3.4058\n",
      "Iteration: 184; Percent complete: 4.6%; Average loss: 3.4159\n",
      "Iteration: 185; Percent complete: 4.6%; Average loss: 3.4404\n",
      "Iteration: 186; Percent complete: 4.7%; Average loss: 3.8604\n",
      "Iteration: 187; Percent complete: 4.7%; Average loss: 3.5856\n",
      "Iteration: 188; Percent complete: 4.7%; Average loss: 3.5552\n",
      "Iteration: 189; Percent complete: 4.7%; Average loss: 3.3535\n",
      "Iteration: 190; Percent complete: 4.8%; Average loss: 3.2575\n",
      "Iteration: 191; Percent complete: 4.8%; Average loss: 3.3560\n",
      "Iteration: 192; Percent complete: 4.8%; Average loss: 3.4219\n",
      "Iteration: 193; Percent complete: 4.8%; Average loss: 3.8789\n",
      "Iteration: 194; Percent complete: 4.9%; Average loss: 3.7665\n",
      "Iteration: 195; Percent complete: 4.9%; Average loss: 3.4482\n",
      "Iteration: 196; Percent complete: 4.9%; Average loss: 3.4601\n",
      "Iteration: 197; Percent complete: 4.9%; Average loss: 3.2537\n",
      "Iteration: 198; Percent complete: 5.0%; Average loss: 3.3967\n",
      "Iteration: 199; Percent complete: 5.0%; Average loss: 3.4724\n",
      "Iteration: 200; Percent complete: 5.0%; Average loss: 3.3280\n",
      "Iteration: 201; Percent complete: 5.0%; Average loss: 3.4963\n",
      "Iteration: 202; Percent complete: 5.1%; Average loss: 3.5949\n",
      "Iteration: 203; Percent complete: 5.1%; Average loss: 3.3802\n",
      "Iteration: 204; Percent complete: 5.1%; Average loss: 3.2502\n",
      "Iteration: 205; Percent complete: 5.1%; Average loss: 3.5241\n",
      "Iteration: 206; Percent complete: 5.1%; Average loss: 3.2188\n",
      "Iteration: 207; Percent complete: 5.2%; Average loss: 3.3356\n",
      "Iteration: 208; Percent complete: 5.2%; Average loss: 3.6336\n",
      "Iteration: 209; Percent complete: 5.2%; Average loss: 3.4310\n",
      "Iteration: 210; Percent complete: 5.2%; Average loss: 3.4328\n",
      "Iteration: 211; Percent complete: 5.3%; Average loss: 3.6127\n",
      "Iteration: 212; Percent complete: 5.3%; Average loss: 3.3538\n",
      "Iteration: 213; Percent complete: 5.3%; Average loss: 3.2556\n",
      "Iteration: 214; Percent complete: 5.3%; Average loss: 3.4026\n",
      "Iteration: 215; Percent complete: 5.4%; Average loss: 3.4422\n",
      "Iteration: 216; Percent complete: 5.4%; Average loss: 3.1842\n",
      "Iteration: 217; Percent complete: 5.4%; Average loss: 3.6124\n",
      "Iteration: 218; Percent complete: 5.5%; Average loss: 3.9127\n",
      "Iteration: 219; Percent complete: 5.5%; Average loss: 3.2732\n",
      "Iteration: 220; Percent complete: 5.5%; Average loss: 3.6047\n",
      "Iteration: 221; Percent complete: 5.5%; Average loss: 3.4440\n",
      "Iteration: 222; Percent complete: 5.5%; Average loss: 3.3796\n",
      "Iteration: 223; Percent complete: 5.6%; Average loss: 3.6140\n",
      "Iteration: 224; Percent complete: 5.6%; Average loss: 3.1111\n",
      "Iteration: 225; Percent complete: 5.6%; Average loss: 3.3426\n",
      "Iteration: 226; Percent complete: 5.7%; Average loss: 3.1843\n",
      "Iteration: 227; Percent complete: 5.7%; Average loss: 3.6103\n",
      "Iteration: 228; Percent complete: 5.7%; Average loss: 3.4107\n",
      "Iteration: 229; Percent complete: 5.7%; Average loss: 3.6887\n",
      "Iteration: 230; Percent complete: 5.8%; Average loss: 3.3602\n",
      "Iteration: 231; Percent complete: 5.8%; Average loss: 3.3372\n",
      "Iteration: 232; Percent complete: 5.8%; Average loss: 3.2661\n",
      "Iteration: 233; Percent complete: 5.8%; Average loss: 3.1098\n",
      "Iteration: 234; Percent complete: 5.9%; Average loss: 3.4494\n",
      "Iteration: 235; Percent complete: 5.9%; Average loss: 3.2689\n",
      "Iteration: 236; Percent complete: 5.9%; Average loss: 3.4536\n",
      "Iteration: 237; Percent complete: 5.9%; Average loss: 3.0927\n",
      "Iteration: 238; Percent complete: 5.9%; Average loss: 3.6323\n",
      "Iteration: 239; Percent complete: 6.0%; Average loss: 3.1954\n",
      "Iteration: 240; Percent complete: 6.0%; Average loss: 3.3220\n",
      "Iteration: 241; Percent complete: 6.0%; Average loss: 3.1801\n",
      "Iteration: 242; Percent complete: 6.0%; Average loss: 3.4756\n",
      "Iteration: 243; Percent complete: 6.1%; Average loss: 3.7224\n",
      "Iteration: 244; Percent complete: 6.1%; Average loss: 3.1963\n",
      "Iteration: 245; Percent complete: 6.1%; Average loss: 3.4481\n",
      "Iteration: 246; Percent complete: 6.2%; Average loss: 3.3980\n",
      "Iteration: 247; Percent complete: 6.2%; Average loss: 3.5880\n",
      "Iteration: 248; Percent complete: 6.2%; Average loss: 3.6724\n",
      "Iteration: 249; Percent complete: 6.2%; Average loss: 3.2142\n",
      "Iteration: 250; Percent complete: 6.2%; Average loss: 2.8551\n",
      "Iteration: 251; Percent complete: 6.3%; Average loss: 3.5300\n",
      "Iteration: 252; Percent complete: 6.3%; Average loss: 3.7570\n",
      "Iteration: 253; Percent complete: 6.3%; Average loss: 3.3529\n",
      "Iteration: 254; Percent complete: 6.3%; Average loss: 3.3669\n",
      "Iteration: 255; Percent complete: 6.4%; Average loss: 3.3432\n",
      "Iteration: 256; Percent complete: 6.4%; Average loss: 3.3697\n",
      "Iteration: 257; Percent complete: 6.4%; Average loss: 3.5498\n",
      "Iteration: 258; Percent complete: 6.5%; Average loss: 3.2404\n",
      "Iteration: 259; Percent complete: 6.5%; Average loss: 3.3639\n",
      "Iteration: 260; Percent complete: 6.5%; Average loss: 3.5518\n",
      "Iteration: 261; Percent complete: 6.5%; Average loss: 3.5847\n",
      "Iteration: 262; Percent complete: 6.6%; Average loss: 3.3036\n",
      "Iteration: 263; Percent complete: 6.6%; Average loss: 3.6546\n",
      "Iteration: 264; Percent complete: 6.6%; Average loss: 3.2881\n",
      "Iteration: 265; Percent complete: 6.6%; Average loss: 3.1827\n",
      "Iteration: 266; Percent complete: 6.7%; Average loss: 3.2345\n",
      "Iteration: 267; Percent complete: 6.7%; Average loss: 3.3031\n",
      "Iteration: 268; Percent complete: 6.7%; Average loss: 3.2162\n",
      "Iteration: 269; Percent complete: 6.7%; Average loss: 3.3344\n",
      "Iteration: 270; Percent complete: 6.8%; Average loss: 3.3737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 271; Percent complete: 6.8%; Average loss: 3.2718\n",
      "Iteration: 272; Percent complete: 6.8%; Average loss: 3.3204\n",
      "Iteration: 273; Percent complete: 6.8%; Average loss: 3.3793\n",
      "Iteration: 274; Percent complete: 6.9%; Average loss: 3.4504\n",
      "Iteration: 275; Percent complete: 6.9%; Average loss: 3.4354\n",
      "Iteration: 276; Percent complete: 6.9%; Average loss: 3.2260\n",
      "Iteration: 277; Percent complete: 6.9%; Average loss: 3.3650\n",
      "Iteration: 278; Percent complete: 7.0%; Average loss: 3.2623\n",
      "Iteration: 279; Percent complete: 7.0%; Average loss: 3.4532\n",
      "Iteration: 280; Percent complete: 7.0%; Average loss: 3.5294\n",
      "Iteration: 281; Percent complete: 7.0%; Average loss: 3.4725\n",
      "Iteration: 282; Percent complete: 7.0%; Average loss: 3.2585\n",
      "Iteration: 283; Percent complete: 7.1%; Average loss: 3.1777\n",
      "Iteration: 284; Percent complete: 7.1%; Average loss: 3.1949\n",
      "Iteration: 285; Percent complete: 7.1%; Average loss: 3.3492\n",
      "Iteration: 286; Percent complete: 7.1%; Average loss: 3.3218\n",
      "Iteration: 287; Percent complete: 7.2%; Average loss: 3.5138\n",
      "Iteration: 288; Percent complete: 7.2%; Average loss: 3.3115\n",
      "Iteration: 289; Percent complete: 7.2%; Average loss: 3.6503\n",
      "Iteration: 290; Percent complete: 7.2%; Average loss: 3.3494\n",
      "Iteration: 291; Percent complete: 7.3%; Average loss: 3.1687\n",
      "Iteration: 292; Percent complete: 7.3%; Average loss: 3.2581\n",
      "Iteration: 293; Percent complete: 7.3%; Average loss: 3.3604\n",
      "Iteration: 294; Percent complete: 7.3%; Average loss: 3.3955\n",
      "Iteration: 295; Percent complete: 7.4%; Average loss: 3.3349\n",
      "Iteration: 296; Percent complete: 7.4%; Average loss: 3.3749\n",
      "Iteration: 297; Percent complete: 7.4%; Average loss: 3.2676\n",
      "Iteration: 298; Percent complete: 7.4%; Average loss: 3.4686\n",
      "Iteration: 299; Percent complete: 7.5%; Average loss: 3.7876\n",
      "Iteration: 300; Percent complete: 7.5%; Average loss: 3.3261\n",
      "Iteration: 301; Percent complete: 7.5%; Average loss: 3.6066\n",
      "Iteration: 302; Percent complete: 7.5%; Average loss: 3.3948\n",
      "Iteration: 303; Percent complete: 7.6%; Average loss: 3.4496\n",
      "Iteration: 304; Percent complete: 7.6%; Average loss: 3.3206\n",
      "Iteration: 305; Percent complete: 7.6%; Average loss: 2.8545\n",
      "Iteration: 306; Percent complete: 7.6%; Average loss: 3.0285\n",
      "Iteration: 307; Percent complete: 7.7%; Average loss: 3.3045\n",
      "Iteration: 308; Percent complete: 7.7%; Average loss: 3.3691\n",
      "Iteration: 309; Percent complete: 7.7%; Average loss: 3.5633\n",
      "Iteration: 310; Percent complete: 7.8%; Average loss: 3.4486\n",
      "Iteration: 311; Percent complete: 7.8%; Average loss: 3.1818\n",
      "Iteration: 312; Percent complete: 7.8%; Average loss: 3.4726\n",
      "Iteration: 313; Percent complete: 7.8%; Average loss: 3.5131\n",
      "Iteration: 314; Percent complete: 7.8%; Average loss: 3.3913\n",
      "Iteration: 315; Percent complete: 7.9%; Average loss: 3.5964\n",
      "Iteration: 316; Percent complete: 7.9%; Average loss: 3.4296\n",
      "Iteration: 317; Percent complete: 7.9%; Average loss: 3.3324\n",
      "Iteration: 318; Percent complete: 8.0%; Average loss: 3.4015\n",
      "Iteration: 319; Percent complete: 8.0%; Average loss: 3.3389\n",
      "Iteration: 320; Percent complete: 8.0%; Average loss: 3.4512\n",
      "Iteration: 321; Percent complete: 8.0%; Average loss: 3.5270\n",
      "Iteration: 322; Percent complete: 8.1%; Average loss: 3.5888\n",
      "Iteration: 323; Percent complete: 8.1%; Average loss: 3.4480\n",
      "Iteration: 324; Percent complete: 8.1%; Average loss: 3.1979\n",
      "Iteration: 325; Percent complete: 8.1%; Average loss: 3.3662\n",
      "Iteration: 326; Percent complete: 8.2%; Average loss: 3.4413\n",
      "Iteration: 327; Percent complete: 8.2%; Average loss: 3.5007\n",
      "Iteration: 328; Percent complete: 8.2%; Average loss: 3.2881\n",
      "Iteration: 329; Percent complete: 8.2%; Average loss: 3.4282\n",
      "Iteration: 330; Percent complete: 8.2%; Average loss: 3.0879\n",
      "Iteration: 331; Percent complete: 8.3%; Average loss: 3.0801\n",
      "Iteration: 332; Percent complete: 8.3%; Average loss: 3.4328\n",
      "Iteration: 333; Percent complete: 8.3%; Average loss: 3.2673\n",
      "Iteration: 334; Percent complete: 8.3%; Average loss: 3.4952\n",
      "Iteration: 335; Percent complete: 8.4%; Average loss: 3.2977\n",
      "Iteration: 336; Percent complete: 8.4%; Average loss: 3.3996\n",
      "Iteration: 337; Percent complete: 8.4%; Average loss: 3.4621\n",
      "Iteration: 338; Percent complete: 8.5%; Average loss: 3.1961\n",
      "Iteration: 339; Percent complete: 8.5%; Average loss: 3.2644\n",
      "Iteration: 340; Percent complete: 8.5%; Average loss: 3.4377\n",
      "Iteration: 341; Percent complete: 8.5%; Average loss: 3.2897\n",
      "Iteration: 342; Percent complete: 8.6%; Average loss: 3.4489\n",
      "Iteration: 343; Percent complete: 8.6%; Average loss: 3.7342\n",
      "Iteration: 344; Percent complete: 8.6%; Average loss: 2.9718\n",
      "Iteration: 345; Percent complete: 8.6%; Average loss: 3.4202\n",
      "Iteration: 346; Percent complete: 8.6%; Average loss: 3.4855\n",
      "Iteration: 347; Percent complete: 8.7%; Average loss: 3.5635\n",
      "Iteration: 348; Percent complete: 8.7%; Average loss: 3.3620\n",
      "Iteration: 349; Percent complete: 8.7%; Average loss: 3.4240\n",
      "Iteration: 350; Percent complete: 8.8%; Average loss: 3.2148\n",
      "Iteration: 351; Percent complete: 8.8%; Average loss: 3.2651\n",
      "Iteration: 352; Percent complete: 8.8%; Average loss: 3.3083\n",
      "Iteration: 353; Percent complete: 8.8%; Average loss: 3.3790\n",
      "Iteration: 354; Percent complete: 8.8%; Average loss: 3.3010\n",
      "Iteration: 355; Percent complete: 8.9%; Average loss: 3.1004\n",
      "Iteration: 356; Percent complete: 8.9%; Average loss: 3.3594\n",
      "Iteration: 357; Percent complete: 8.9%; Average loss: 3.3982\n",
      "Iteration: 358; Percent complete: 8.9%; Average loss: 3.0399\n",
      "Iteration: 359; Percent complete: 9.0%; Average loss: 3.2249\n",
      "Iteration: 360; Percent complete: 9.0%; Average loss: 3.2678\n",
      "Iteration: 361; Percent complete: 9.0%; Average loss: 3.2644\n",
      "Iteration: 362; Percent complete: 9.0%; Average loss: 3.2984\n",
      "Iteration: 363; Percent complete: 9.1%; Average loss: 3.4320\n",
      "Iteration: 364; Percent complete: 9.1%; Average loss: 3.2910\n",
      "Iteration: 365; Percent complete: 9.1%; Average loss: 3.2623\n",
      "Iteration: 366; Percent complete: 9.2%; Average loss: 3.2071\n",
      "Iteration: 367; Percent complete: 9.2%; Average loss: 2.9416\n",
      "Iteration: 368; Percent complete: 9.2%; Average loss: 3.3095\n",
      "Iteration: 369; Percent complete: 9.2%; Average loss: 3.2536\n",
      "Iteration: 370; Percent complete: 9.2%; Average loss: 3.2901\n",
      "Iteration: 371; Percent complete: 9.3%; Average loss: 3.3244\n",
      "Iteration: 372; Percent complete: 9.3%; Average loss: 3.2753\n",
      "Iteration: 373; Percent complete: 9.3%; Average loss: 3.3226\n",
      "Iteration: 374; Percent complete: 9.3%; Average loss: 3.2100\n",
      "Iteration: 375; Percent complete: 9.4%; Average loss: 3.1078\n",
      "Iteration: 376; Percent complete: 9.4%; Average loss: 3.2242\n",
      "Iteration: 377; Percent complete: 9.4%; Average loss: 3.0837\n",
      "Iteration: 378; Percent complete: 9.4%; Average loss: 3.5215\n",
      "Iteration: 379; Percent complete: 9.5%; Average loss: 3.5684\n",
      "Iteration: 380; Percent complete: 9.5%; Average loss: 3.3254\n",
      "Iteration: 381; Percent complete: 9.5%; Average loss: 3.3400\n",
      "Iteration: 382; Percent complete: 9.6%; Average loss: 3.2739\n",
      "Iteration: 383; Percent complete: 9.6%; Average loss: 3.1385\n",
      "Iteration: 384; Percent complete: 9.6%; Average loss: 3.4757\n",
      "Iteration: 385; Percent complete: 9.6%; Average loss: 3.1786\n",
      "Iteration: 386; Percent complete: 9.7%; Average loss: 3.1676\n",
      "Iteration: 387; Percent complete: 9.7%; Average loss: 3.1611\n",
      "Iteration: 388; Percent complete: 9.7%; Average loss: 3.0528\n",
      "Iteration: 389; Percent complete: 9.7%; Average loss: 3.0070\n",
      "Iteration: 390; Percent complete: 9.8%; Average loss: 3.5857\n",
      "Iteration: 391; Percent complete: 9.8%; Average loss: 3.1553\n",
      "Iteration: 392; Percent complete: 9.8%; Average loss: 3.0855\n",
      "Iteration: 393; Percent complete: 9.8%; Average loss: 3.1900\n",
      "Iteration: 394; Percent complete: 9.8%; Average loss: 3.3600\n",
      "Iteration: 395; Percent complete: 9.9%; Average loss: 3.3223\n",
      "Iteration: 396; Percent complete: 9.9%; Average loss: 3.1757\n",
      "Iteration: 397; Percent complete: 9.9%; Average loss: 3.3290\n",
      "Iteration: 398; Percent complete: 10.0%; Average loss: 3.1040\n",
      "Iteration: 399; Percent complete: 10.0%; Average loss: 3.5825\n",
      "Iteration: 400; Percent complete: 10.0%; Average loss: 3.0512\n",
      "Iteration: 401; Percent complete: 10.0%; Average loss: 3.2745\n",
      "Iteration: 402; Percent complete: 10.1%; Average loss: 3.1879\n",
      "Iteration: 403; Percent complete: 10.1%; Average loss: 3.3028\n",
      "Iteration: 404; Percent complete: 10.1%; Average loss: 3.2655\n",
      "Iteration: 405; Percent complete: 10.1%; Average loss: 3.3975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 406; Percent complete: 10.2%; Average loss: 3.2737\n",
      "Iteration: 407; Percent complete: 10.2%; Average loss: 3.2325\n",
      "Iteration: 408; Percent complete: 10.2%; Average loss: 3.3328\n",
      "Iteration: 409; Percent complete: 10.2%; Average loss: 3.0878\n",
      "Iteration: 410; Percent complete: 10.2%; Average loss: 3.2570\n",
      "Iteration: 411; Percent complete: 10.3%; Average loss: 3.1672\n",
      "Iteration: 412; Percent complete: 10.3%; Average loss: 3.3389\n",
      "Iteration: 413; Percent complete: 10.3%; Average loss: 3.2364\n",
      "Iteration: 414; Percent complete: 10.3%; Average loss: 3.1642\n",
      "Iteration: 415; Percent complete: 10.4%; Average loss: 3.1594\n",
      "Iteration: 416; Percent complete: 10.4%; Average loss: 3.2046\n",
      "Iteration: 417; Percent complete: 10.4%; Average loss: 3.1673\n",
      "Iteration: 418; Percent complete: 10.4%; Average loss: 3.3764\n",
      "Iteration: 419; Percent complete: 10.5%; Average loss: 3.2919\n",
      "Iteration: 420; Percent complete: 10.5%; Average loss: 3.0755\n",
      "Iteration: 421; Percent complete: 10.5%; Average loss: 2.9852\n",
      "Iteration: 422; Percent complete: 10.5%; Average loss: 3.2975\n",
      "Iteration: 423; Percent complete: 10.6%; Average loss: 3.1572\n",
      "Iteration: 424; Percent complete: 10.6%; Average loss: 3.2250\n",
      "Iteration: 425; Percent complete: 10.6%; Average loss: 3.0571\n",
      "Iteration: 426; Percent complete: 10.7%; Average loss: 3.1881\n",
      "Iteration: 427; Percent complete: 10.7%; Average loss: 3.1144\n",
      "Iteration: 428; Percent complete: 10.7%; Average loss: 3.2572\n",
      "Iteration: 429; Percent complete: 10.7%; Average loss: 3.2943\n",
      "Iteration: 430; Percent complete: 10.8%; Average loss: 3.2270\n",
      "Iteration: 431; Percent complete: 10.8%; Average loss: 3.3037\n",
      "Iteration: 432; Percent complete: 10.8%; Average loss: 3.1426\n",
      "Iteration: 433; Percent complete: 10.8%; Average loss: 3.0029\n",
      "Iteration: 434; Percent complete: 10.8%; Average loss: 3.0222\n",
      "Iteration: 435; Percent complete: 10.9%; Average loss: 3.3291\n",
      "Iteration: 436; Percent complete: 10.9%; Average loss: 3.1081\n",
      "Iteration: 437; Percent complete: 10.9%; Average loss: 3.3290\n",
      "Iteration: 438; Percent complete: 10.9%; Average loss: 3.4245\n",
      "Iteration: 439; Percent complete: 11.0%; Average loss: 3.1072\n",
      "Iteration: 440; Percent complete: 11.0%; Average loss: 3.2157\n",
      "Iteration: 441; Percent complete: 11.0%; Average loss: 3.1872\n",
      "Iteration: 442; Percent complete: 11.1%; Average loss: 3.1885\n",
      "Iteration: 443; Percent complete: 11.1%; Average loss: 3.3541\n",
      "Iteration: 444; Percent complete: 11.1%; Average loss: 3.1980\n",
      "Iteration: 445; Percent complete: 11.1%; Average loss: 3.1478\n",
      "Iteration: 446; Percent complete: 11.2%; Average loss: 3.0278\n",
      "Iteration: 447; Percent complete: 11.2%; Average loss: 3.1418\n",
      "Iteration: 448; Percent complete: 11.2%; Average loss: 3.1144\n",
      "Iteration: 449; Percent complete: 11.2%; Average loss: 3.0393\n",
      "Iteration: 450; Percent complete: 11.2%; Average loss: 3.2479\n",
      "Iteration: 451; Percent complete: 11.3%; Average loss: 3.0099\n",
      "Iteration: 452; Percent complete: 11.3%; Average loss: 3.1659\n",
      "Iteration: 453; Percent complete: 11.3%; Average loss: 3.2560\n",
      "Iteration: 454; Percent complete: 11.3%; Average loss: 3.2308\n",
      "Iteration: 455; Percent complete: 11.4%; Average loss: 3.1397\n",
      "Iteration: 456; Percent complete: 11.4%; Average loss: 3.2972\n",
      "Iteration: 457; Percent complete: 11.4%; Average loss: 3.2655\n",
      "Iteration: 458; Percent complete: 11.5%; Average loss: 3.3465\n",
      "Iteration: 459; Percent complete: 11.5%; Average loss: 3.2760\n",
      "Iteration: 460; Percent complete: 11.5%; Average loss: 3.3931\n",
      "Iteration: 461; Percent complete: 11.5%; Average loss: 3.2620\n",
      "Iteration: 462; Percent complete: 11.6%; Average loss: 3.0900\n",
      "Iteration: 463; Percent complete: 11.6%; Average loss: 3.3611\n",
      "Iteration: 464; Percent complete: 11.6%; Average loss: 3.1049\n",
      "Iteration: 465; Percent complete: 11.6%; Average loss: 3.1319\n",
      "Iteration: 466; Percent complete: 11.7%; Average loss: 2.9804\n",
      "Iteration: 467; Percent complete: 11.7%; Average loss: 3.1395\n",
      "Iteration: 468; Percent complete: 11.7%; Average loss: 3.1283\n",
      "Iteration: 469; Percent complete: 11.7%; Average loss: 3.2664\n",
      "Iteration: 470; Percent complete: 11.8%; Average loss: 3.1116\n",
      "Iteration: 471; Percent complete: 11.8%; Average loss: 3.1810\n",
      "Iteration: 472; Percent complete: 11.8%; Average loss: 2.8750\n",
      "Iteration: 473; Percent complete: 11.8%; Average loss: 3.2828\n",
      "Iteration: 474; Percent complete: 11.8%; Average loss: 3.3377\n",
      "Iteration: 475; Percent complete: 11.9%; Average loss: 3.0567\n",
      "Iteration: 476; Percent complete: 11.9%; Average loss: 3.1464\n",
      "Iteration: 477; Percent complete: 11.9%; Average loss: 3.1575\n",
      "Iteration: 478; Percent complete: 11.9%; Average loss: 3.2932\n",
      "Iteration: 479; Percent complete: 12.0%; Average loss: 3.2538\n",
      "Iteration: 480; Percent complete: 12.0%; Average loss: 3.1364\n",
      "Iteration: 481; Percent complete: 12.0%; Average loss: 3.3235\n",
      "Iteration: 482; Percent complete: 12.0%; Average loss: 3.3230\n",
      "Iteration: 483; Percent complete: 12.1%; Average loss: 2.9584\n",
      "Iteration: 484; Percent complete: 12.1%; Average loss: 3.0575\n",
      "Iteration: 485; Percent complete: 12.1%; Average loss: 3.1883\n",
      "Iteration: 486; Percent complete: 12.2%; Average loss: 3.1502\n",
      "Iteration: 487; Percent complete: 12.2%; Average loss: 3.0021\n",
      "Iteration: 488; Percent complete: 12.2%; Average loss: 2.9341\n",
      "Iteration: 489; Percent complete: 12.2%; Average loss: 3.2192\n",
      "Iteration: 490; Percent complete: 12.2%; Average loss: 3.2075\n",
      "Iteration: 491; Percent complete: 12.3%; Average loss: 3.1943\n",
      "Iteration: 492; Percent complete: 12.3%; Average loss: 3.0438\n",
      "Iteration: 493; Percent complete: 12.3%; Average loss: 3.1526\n",
      "Iteration: 494; Percent complete: 12.3%; Average loss: 2.7642\n",
      "Iteration: 495; Percent complete: 12.4%; Average loss: 3.2746\n",
      "Iteration: 496; Percent complete: 12.4%; Average loss: 3.0841\n",
      "Iteration: 497; Percent complete: 12.4%; Average loss: 3.0874\n",
      "Iteration: 498; Percent complete: 12.4%; Average loss: 2.9982\n",
      "Iteration: 499; Percent complete: 12.5%; Average loss: 3.0997\n",
      "Iteration: 500; Percent complete: 12.5%; Average loss: 3.2269\n",
      "Iteration: 501; Percent complete: 12.5%; Average loss: 3.2944\n",
      "Iteration: 502; Percent complete: 12.6%; Average loss: 3.0921\n",
      "Iteration: 503; Percent complete: 12.6%; Average loss: 3.2173\n",
      "Iteration: 504; Percent complete: 12.6%; Average loss: 3.1918\n",
      "Iteration: 505; Percent complete: 12.6%; Average loss: 3.2482\n",
      "Iteration: 506; Percent complete: 12.7%; Average loss: 3.2889\n",
      "Iteration: 507; Percent complete: 12.7%; Average loss: 2.9361\n",
      "Iteration: 508; Percent complete: 12.7%; Average loss: 3.4188\n",
      "Iteration: 509; Percent complete: 12.7%; Average loss: 3.1256\n",
      "Iteration: 510; Percent complete: 12.8%; Average loss: 2.9074\n",
      "Iteration: 511; Percent complete: 12.8%; Average loss: 2.9775\n",
      "Iteration: 512; Percent complete: 12.8%; Average loss: 3.0800\n",
      "Iteration: 513; Percent complete: 12.8%; Average loss: 3.1428\n",
      "Iteration: 514; Percent complete: 12.8%; Average loss: 2.9749\n",
      "Iteration: 515; Percent complete: 12.9%; Average loss: 3.2391\n",
      "Iteration: 516; Percent complete: 12.9%; Average loss: 2.9838\n",
      "Iteration: 517; Percent complete: 12.9%; Average loss: 3.3455\n",
      "Iteration: 518; Percent complete: 13.0%; Average loss: 2.9700\n",
      "Iteration: 519; Percent complete: 13.0%; Average loss: 3.0996\n",
      "Iteration: 520; Percent complete: 13.0%; Average loss: 3.1663\n",
      "Iteration: 521; Percent complete: 13.0%; Average loss: 3.1855\n",
      "Iteration: 522; Percent complete: 13.1%; Average loss: 3.2957\n",
      "Iteration: 523; Percent complete: 13.1%; Average loss: 3.4503\n",
      "Iteration: 524; Percent complete: 13.1%; Average loss: 2.9958\n",
      "Iteration: 525; Percent complete: 13.1%; Average loss: 3.2430\n",
      "Iteration: 526; Percent complete: 13.2%; Average loss: 3.2002\n",
      "Iteration: 527; Percent complete: 13.2%; Average loss: 2.8290\n",
      "Iteration: 528; Percent complete: 13.2%; Average loss: 3.0500\n",
      "Iteration: 529; Percent complete: 13.2%; Average loss: 3.2329\n",
      "Iteration: 530; Percent complete: 13.2%; Average loss: 3.4239\n",
      "Iteration: 531; Percent complete: 13.3%; Average loss: 3.2869\n",
      "Iteration: 532; Percent complete: 13.3%; Average loss: 3.2341\n",
      "Iteration: 533; Percent complete: 13.3%; Average loss: 3.0641\n",
      "Iteration: 534; Percent complete: 13.4%; Average loss: 3.1139\n",
      "Iteration: 535; Percent complete: 13.4%; Average loss: 3.1903\n",
      "Iteration: 536; Percent complete: 13.4%; Average loss: 3.2711\n",
      "Iteration: 537; Percent complete: 13.4%; Average loss: 3.3188\n",
      "Iteration: 538; Percent complete: 13.5%; Average loss: 2.8742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 539; Percent complete: 13.5%; Average loss: 3.0969\n",
      "Iteration: 540; Percent complete: 13.5%; Average loss: 3.1722\n",
      "Iteration: 541; Percent complete: 13.5%; Average loss: 3.2220\n",
      "Iteration: 542; Percent complete: 13.6%; Average loss: 3.1824\n",
      "Iteration: 543; Percent complete: 13.6%; Average loss: 2.8848\n",
      "Iteration: 544; Percent complete: 13.6%; Average loss: 3.1483\n",
      "Iteration: 545; Percent complete: 13.6%; Average loss: 2.9908\n",
      "Iteration: 546; Percent complete: 13.7%; Average loss: 2.9932\n",
      "Iteration: 547; Percent complete: 13.7%; Average loss: 3.2727\n",
      "Iteration: 548; Percent complete: 13.7%; Average loss: 2.8729\n",
      "Iteration: 549; Percent complete: 13.7%; Average loss: 3.2337\n",
      "Iteration: 550; Percent complete: 13.8%; Average loss: 2.9562\n",
      "Iteration: 551; Percent complete: 13.8%; Average loss: 3.3129\n",
      "Iteration: 552; Percent complete: 13.8%; Average loss: 3.0802\n",
      "Iteration: 553; Percent complete: 13.8%; Average loss: 3.1233\n",
      "Iteration: 554; Percent complete: 13.9%; Average loss: 3.1109\n",
      "Iteration: 555; Percent complete: 13.9%; Average loss: 3.0195\n",
      "Iteration: 556; Percent complete: 13.9%; Average loss: 3.1092\n",
      "Iteration: 557; Percent complete: 13.9%; Average loss: 3.2357\n",
      "Iteration: 558; Percent complete: 14.0%; Average loss: 2.9907\n",
      "Iteration: 559; Percent complete: 14.0%; Average loss: 3.2730\n",
      "Iteration: 560; Percent complete: 14.0%; Average loss: 3.4100\n",
      "Iteration: 561; Percent complete: 14.0%; Average loss: 3.1602\n",
      "Iteration: 562; Percent complete: 14.1%; Average loss: 3.0204\n",
      "Iteration: 563; Percent complete: 14.1%; Average loss: 3.1462\n",
      "Iteration: 564; Percent complete: 14.1%; Average loss: 3.1845\n",
      "Iteration: 565; Percent complete: 14.1%; Average loss: 2.8892\n",
      "Iteration: 566; Percent complete: 14.1%; Average loss: 3.3938\n",
      "Iteration: 567; Percent complete: 14.2%; Average loss: 2.9932\n",
      "Iteration: 568; Percent complete: 14.2%; Average loss: 3.3385\n",
      "Iteration: 569; Percent complete: 14.2%; Average loss: 3.3856\n",
      "Iteration: 570; Percent complete: 14.2%; Average loss: 3.0541\n",
      "Iteration: 571; Percent complete: 14.3%; Average loss: 2.8946\n",
      "Iteration: 572; Percent complete: 14.3%; Average loss: 3.2349\n",
      "Iteration: 573; Percent complete: 14.3%; Average loss: 3.0512\n",
      "Iteration: 574; Percent complete: 14.3%; Average loss: 2.6661\n",
      "Iteration: 575; Percent complete: 14.4%; Average loss: 2.9543\n",
      "Iteration: 576; Percent complete: 14.4%; Average loss: 2.9952\n",
      "Iteration: 577; Percent complete: 14.4%; Average loss: 2.8647\n",
      "Iteration: 578; Percent complete: 14.4%; Average loss: 3.0433\n",
      "Iteration: 579; Percent complete: 14.5%; Average loss: 3.1285\n",
      "Iteration: 580; Percent complete: 14.5%; Average loss: 3.0342\n",
      "Iteration: 581; Percent complete: 14.5%; Average loss: 3.3054\n",
      "Iteration: 582; Percent complete: 14.5%; Average loss: 2.9742\n",
      "Iteration: 583; Percent complete: 14.6%; Average loss: 3.3548\n",
      "Iteration: 584; Percent complete: 14.6%; Average loss: 3.4463\n",
      "Iteration: 585; Percent complete: 14.6%; Average loss: 3.3402\n",
      "Iteration: 586; Percent complete: 14.6%; Average loss: 2.9406\n",
      "Iteration: 587; Percent complete: 14.7%; Average loss: 3.2978\n",
      "Iteration: 588; Percent complete: 14.7%; Average loss: 2.8573\n",
      "Iteration: 589; Percent complete: 14.7%; Average loss: 3.3227\n",
      "Iteration: 590; Percent complete: 14.8%; Average loss: 3.2409\n",
      "Iteration: 591; Percent complete: 14.8%; Average loss: 3.1098\n",
      "Iteration: 592; Percent complete: 14.8%; Average loss: 3.0482\n",
      "Iteration: 593; Percent complete: 14.8%; Average loss: 3.0424\n",
      "Iteration: 594; Percent complete: 14.8%; Average loss: 3.0377\n",
      "Iteration: 595; Percent complete: 14.9%; Average loss: 3.1993\n",
      "Iteration: 596; Percent complete: 14.9%; Average loss: 2.7590\n",
      "Iteration: 597; Percent complete: 14.9%; Average loss: 3.1633\n",
      "Iteration: 598; Percent complete: 14.9%; Average loss: 3.1833\n",
      "Iteration: 599; Percent complete: 15.0%; Average loss: 2.7307\n",
      "Iteration: 600; Percent complete: 15.0%; Average loss: 3.0334\n",
      "Iteration: 601; Percent complete: 15.0%; Average loss: 3.0242\n",
      "Iteration: 602; Percent complete: 15.0%; Average loss: 3.1230\n",
      "Iteration: 603; Percent complete: 15.1%; Average loss: 2.9702\n",
      "Iteration: 604; Percent complete: 15.1%; Average loss: 3.0475\n",
      "Iteration: 605; Percent complete: 15.1%; Average loss: 3.2309\n",
      "Iteration: 606; Percent complete: 15.2%; Average loss: 3.0198\n",
      "Iteration: 607; Percent complete: 15.2%; Average loss: 3.0393\n",
      "Iteration: 608; Percent complete: 15.2%; Average loss: 2.9518\n",
      "Iteration: 609; Percent complete: 15.2%; Average loss: 2.8781\n",
      "Iteration: 610; Percent complete: 15.2%; Average loss: 3.4623\n",
      "Iteration: 611; Percent complete: 15.3%; Average loss: 2.9246\n",
      "Iteration: 612; Percent complete: 15.3%; Average loss: 3.0295\n",
      "Iteration: 613; Percent complete: 15.3%; Average loss: 2.8157\n",
      "Iteration: 614; Percent complete: 15.3%; Average loss: 2.9542\n",
      "Iteration: 615; Percent complete: 15.4%; Average loss: 2.9296\n",
      "Iteration: 616; Percent complete: 15.4%; Average loss: 3.1424\n",
      "Iteration: 617; Percent complete: 15.4%; Average loss: 3.0914\n",
      "Iteration: 618; Percent complete: 15.4%; Average loss: 2.9565\n",
      "Iteration: 619; Percent complete: 15.5%; Average loss: 3.2585\n",
      "Iteration: 620; Percent complete: 15.5%; Average loss: 3.0275\n",
      "Iteration: 621; Percent complete: 15.5%; Average loss: 3.1922\n",
      "Iteration: 622; Percent complete: 15.6%; Average loss: 2.9846\n",
      "Iteration: 623; Percent complete: 15.6%; Average loss: 3.0538\n",
      "Iteration: 624; Percent complete: 15.6%; Average loss: 3.0497\n",
      "Iteration: 625; Percent complete: 15.6%; Average loss: 3.0363\n",
      "Iteration: 626; Percent complete: 15.7%; Average loss: 3.0997\n",
      "Iteration: 627; Percent complete: 15.7%; Average loss: 3.2234\n",
      "Iteration: 628; Percent complete: 15.7%; Average loss: 3.4658\n",
      "Iteration: 629; Percent complete: 15.7%; Average loss: 3.2295\n",
      "Iteration: 630; Percent complete: 15.8%; Average loss: 3.0483\n",
      "Iteration: 631; Percent complete: 15.8%; Average loss: 3.1628\n",
      "Iteration: 632; Percent complete: 15.8%; Average loss: 3.2568\n",
      "Iteration: 633; Percent complete: 15.8%; Average loss: 3.1939\n",
      "Iteration: 634; Percent complete: 15.8%; Average loss: 2.9107\n",
      "Iteration: 635; Percent complete: 15.9%; Average loss: 3.0428\n",
      "Iteration: 636; Percent complete: 15.9%; Average loss: 3.1351\n",
      "Iteration: 637; Percent complete: 15.9%; Average loss: 3.1195\n",
      "Iteration: 638; Percent complete: 16.0%; Average loss: 3.0596\n",
      "Iteration: 639; Percent complete: 16.0%; Average loss: 2.9201\n",
      "Iteration: 640; Percent complete: 16.0%; Average loss: 2.8300\n",
      "Iteration: 641; Percent complete: 16.0%; Average loss: 2.8385\n",
      "Iteration: 642; Percent complete: 16.1%; Average loss: 3.2357\n",
      "Iteration: 643; Percent complete: 16.1%; Average loss: 3.1766\n",
      "Iteration: 644; Percent complete: 16.1%; Average loss: 2.9621\n",
      "Iteration: 645; Percent complete: 16.1%; Average loss: 3.1044\n",
      "Iteration: 646; Percent complete: 16.2%; Average loss: 2.8999\n",
      "Iteration: 647; Percent complete: 16.2%; Average loss: 3.1625\n",
      "Iteration: 648; Percent complete: 16.2%; Average loss: 3.0669\n",
      "Iteration: 649; Percent complete: 16.2%; Average loss: 3.2355\n",
      "Iteration: 650; Percent complete: 16.2%; Average loss: 2.9999\n",
      "Iteration: 651; Percent complete: 16.3%; Average loss: 3.4435\n",
      "Iteration: 652; Percent complete: 16.3%; Average loss: 2.7969\n",
      "Iteration: 653; Percent complete: 16.3%; Average loss: 3.1358\n",
      "Iteration: 654; Percent complete: 16.4%; Average loss: 2.9627\n",
      "Iteration: 655; Percent complete: 16.4%; Average loss: 3.3005\n",
      "Iteration: 656; Percent complete: 16.4%; Average loss: 3.0685\n",
      "Iteration: 657; Percent complete: 16.4%; Average loss: 3.0221\n",
      "Iteration: 658; Percent complete: 16.4%; Average loss: 3.1152\n",
      "Iteration: 659; Percent complete: 16.5%; Average loss: 2.9579\n",
      "Iteration: 660; Percent complete: 16.5%; Average loss: 3.2702\n",
      "Iteration: 661; Percent complete: 16.5%; Average loss: 3.3942\n",
      "Iteration: 662; Percent complete: 16.6%; Average loss: 3.0513\n",
      "Iteration: 663; Percent complete: 16.6%; Average loss: 2.9949\n",
      "Iteration: 664; Percent complete: 16.6%; Average loss: 3.2058\n",
      "Iteration: 665; Percent complete: 16.6%; Average loss: 3.2006\n",
      "Iteration: 666; Percent complete: 16.7%; Average loss: 3.1631\n",
      "Iteration: 667; Percent complete: 16.7%; Average loss: 3.0827\n",
      "Iteration: 668; Percent complete: 16.7%; Average loss: 2.8329\n",
      "Iteration: 669; Percent complete: 16.7%; Average loss: 3.3564\n",
      "Iteration: 670; Percent complete: 16.8%; Average loss: 3.1880\n",
      "Iteration: 671; Percent complete: 16.8%; Average loss: 3.2034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 672; Percent complete: 16.8%; Average loss: 2.8675\n",
      "Iteration: 673; Percent complete: 16.8%; Average loss: 2.9664\n",
      "Iteration: 674; Percent complete: 16.9%; Average loss: 3.1381\n",
      "Iteration: 675; Percent complete: 16.9%; Average loss: 3.1193\n",
      "Iteration: 676; Percent complete: 16.9%; Average loss: 2.9081\n",
      "Iteration: 677; Percent complete: 16.9%; Average loss: 3.2408\n",
      "Iteration: 678; Percent complete: 17.0%; Average loss: 3.0908\n",
      "Iteration: 679; Percent complete: 17.0%; Average loss: 3.0628\n",
      "Iteration: 680; Percent complete: 17.0%; Average loss: 3.0761\n",
      "Iteration: 681; Percent complete: 17.0%; Average loss: 3.0741\n",
      "Iteration: 682; Percent complete: 17.1%; Average loss: 3.0895\n",
      "Iteration: 683; Percent complete: 17.1%; Average loss: 2.8718\n",
      "Iteration: 684; Percent complete: 17.1%; Average loss: 3.3302\n",
      "Iteration: 685; Percent complete: 17.1%; Average loss: 3.0151\n",
      "Iteration: 686; Percent complete: 17.2%; Average loss: 3.1373\n",
      "Iteration: 687; Percent complete: 17.2%; Average loss: 3.0712\n",
      "Iteration: 688; Percent complete: 17.2%; Average loss: 3.2920\n",
      "Iteration: 689; Percent complete: 17.2%; Average loss: 3.0012\n",
      "Iteration: 690; Percent complete: 17.2%; Average loss: 3.0569\n",
      "Iteration: 691; Percent complete: 17.3%; Average loss: 3.1233\n",
      "Iteration: 692; Percent complete: 17.3%; Average loss: 3.0372\n",
      "Iteration: 693; Percent complete: 17.3%; Average loss: 3.2751\n",
      "Iteration: 694; Percent complete: 17.3%; Average loss: 3.1252\n",
      "Iteration: 695; Percent complete: 17.4%; Average loss: 3.3010\n",
      "Iteration: 696; Percent complete: 17.4%; Average loss: 3.0357\n",
      "Iteration: 697; Percent complete: 17.4%; Average loss: 2.8209\n",
      "Iteration: 698; Percent complete: 17.4%; Average loss: 3.0393\n",
      "Iteration: 699; Percent complete: 17.5%; Average loss: 3.1974\n",
      "Iteration: 700; Percent complete: 17.5%; Average loss: 3.2222\n",
      "Iteration: 701; Percent complete: 17.5%; Average loss: 3.1639\n",
      "Iteration: 702; Percent complete: 17.5%; Average loss: 2.9865\n",
      "Iteration: 703; Percent complete: 17.6%; Average loss: 2.8028\n",
      "Iteration: 704; Percent complete: 17.6%; Average loss: 3.2465\n",
      "Iteration: 705; Percent complete: 17.6%; Average loss: 2.9447\n",
      "Iteration: 706; Percent complete: 17.6%; Average loss: 3.2302\n",
      "Iteration: 707; Percent complete: 17.7%; Average loss: 2.8512\n",
      "Iteration: 708; Percent complete: 17.7%; Average loss: 2.8580\n",
      "Iteration: 709; Percent complete: 17.7%; Average loss: 2.9964\n",
      "Iteration: 710; Percent complete: 17.8%; Average loss: 3.3233\n",
      "Iteration: 711; Percent complete: 17.8%; Average loss: 3.2002\n",
      "Iteration: 712; Percent complete: 17.8%; Average loss: 2.6966\n",
      "Iteration: 713; Percent complete: 17.8%; Average loss: 3.0663\n",
      "Iteration: 714; Percent complete: 17.8%; Average loss: 2.9757\n",
      "Iteration: 715; Percent complete: 17.9%; Average loss: 3.2723\n",
      "Iteration: 716; Percent complete: 17.9%; Average loss: 3.1242\n",
      "Iteration: 717; Percent complete: 17.9%; Average loss: 3.2508\n",
      "Iteration: 718; Percent complete: 17.9%; Average loss: 3.0898\n",
      "Iteration: 719; Percent complete: 18.0%; Average loss: 3.0625\n",
      "Iteration: 720; Percent complete: 18.0%; Average loss: 3.0955\n",
      "Iteration: 721; Percent complete: 18.0%; Average loss: 2.6885\n",
      "Iteration: 722; Percent complete: 18.1%; Average loss: 3.0840\n",
      "Iteration: 723; Percent complete: 18.1%; Average loss: 3.1958\n",
      "Iteration: 724; Percent complete: 18.1%; Average loss: 3.1556\n",
      "Iteration: 725; Percent complete: 18.1%; Average loss: 2.8278\n",
      "Iteration: 726; Percent complete: 18.1%; Average loss: 3.2307\n",
      "Iteration: 727; Percent complete: 18.2%; Average loss: 2.8783\n",
      "Iteration: 728; Percent complete: 18.2%; Average loss: 3.0106\n",
      "Iteration: 729; Percent complete: 18.2%; Average loss: 3.1970\n",
      "Iteration: 730; Percent complete: 18.2%; Average loss: 3.1539\n",
      "Iteration: 731; Percent complete: 18.3%; Average loss: 2.9179\n",
      "Iteration: 732; Percent complete: 18.3%; Average loss: 2.9553\n",
      "Iteration: 733; Percent complete: 18.3%; Average loss: 3.0195\n",
      "Iteration: 734; Percent complete: 18.4%; Average loss: 2.9238\n",
      "Iteration: 735; Percent complete: 18.4%; Average loss: 3.0377\n",
      "Iteration: 736; Percent complete: 18.4%; Average loss: 2.9559\n",
      "Iteration: 737; Percent complete: 18.4%; Average loss: 3.0318\n",
      "Iteration: 738; Percent complete: 18.4%; Average loss: 3.1989\n",
      "Iteration: 739; Percent complete: 18.5%; Average loss: 3.3083\n",
      "Iteration: 740; Percent complete: 18.5%; Average loss: 3.0603\n",
      "Iteration: 741; Percent complete: 18.5%; Average loss: 2.8952\n",
      "Iteration: 742; Percent complete: 18.6%; Average loss: 3.0892\n",
      "Iteration: 743; Percent complete: 18.6%; Average loss: 3.1520\n",
      "Iteration: 744; Percent complete: 18.6%; Average loss: 3.0921\n",
      "Iteration: 745; Percent complete: 18.6%; Average loss: 3.0720\n",
      "Iteration: 746; Percent complete: 18.6%; Average loss: 2.9204\n",
      "Iteration: 747; Percent complete: 18.7%; Average loss: 2.8495\n",
      "Iteration: 748; Percent complete: 18.7%; Average loss: 3.0062\n",
      "Iteration: 749; Percent complete: 18.7%; Average loss: 3.0185\n",
      "Iteration: 750; Percent complete: 18.8%; Average loss: 3.0279\n",
      "Iteration: 751; Percent complete: 18.8%; Average loss: 3.0788\n",
      "Iteration: 752; Percent complete: 18.8%; Average loss: 3.0782\n",
      "Iteration: 753; Percent complete: 18.8%; Average loss: 3.1104\n",
      "Iteration: 754; Percent complete: 18.9%; Average loss: 3.0915\n",
      "Iteration: 755; Percent complete: 18.9%; Average loss: 3.0558\n",
      "Iteration: 756; Percent complete: 18.9%; Average loss: 3.0701\n",
      "Iteration: 757; Percent complete: 18.9%; Average loss: 3.1058\n",
      "Iteration: 758; Percent complete: 18.9%; Average loss: 2.8827\n",
      "Iteration: 759; Percent complete: 19.0%; Average loss: 3.0929\n",
      "Iteration: 760; Percent complete: 19.0%; Average loss: 3.0533\n",
      "Iteration: 761; Percent complete: 19.0%; Average loss: 3.0286\n",
      "Iteration: 762; Percent complete: 19.1%; Average loss: 3.1931\n",
      "Iteration: 763; Percent complete: 19.1%; Average loss: 3.1484\n",
      "Iteration: 764; Percent complete: 19.1%; Average loss: 2.9832\n",
      "Iteration: 765; Percent complete: 19.1%; Average loss: 3.3448\n",
      "Iteration: 766; Percent complete: 19.1%; Average loss: 3.0088\n",
      "Iteration: 767; Percent complete: 19.2%; Average loss: 2.9212\n",
      "Iteration: 768; Percent complete: 19.2%; Average loss: 3.0385\n",
      "Iteration: 769; Percent complete: 19.2%; Average loss: 3.2609\n",
      "Iteration: 770; Percent complete: 19.2%; Average loss: 2.6850\n",
      "Iteration: 771; Percent complete: 19.3%; Average loss: 3.1929\n",
      "Iteration: 772; Percent complete: 19.3%; Average loss: 2.8621\n",
      "Iteration: 773; Percent complete: 19.3%; Average loss: 2.9230\n",
      "Iteration: 774; Percent complete: 19.4%; Average loss: 3.0048\n",
      "Iteration: 775; Percent complete: 19.4%; Average loss: 3.1931\n",
      "Iteration: 776; Percent complete: 19.4%; Average loss: 2.9381\n",
      "Iteration: 777; Percent complete: 19.4%; Average loss: 3.0657\n",
      "Iteration: 778; Percent complete: 19.4%; Average loss: 3.0606\n",
      "Iteration: 779; Percent complete: 19.5%; Average loss: 3.2591\n",
      "Iteration: 780; Percent complete: 19.5%; Average loss: 3.0027\n",
      "Iteration: 781; Percent complete: 19.5%; Average loss: 3.1254\n",
      "Iteration: 782; Percent complete: 19.6%; Average loss: 2.9620\n",
      "Iteration: 783; Percent complete: 19.6%; Average loss: 3.1791\n",
      "Iteration: 784; Percent complete: 19.6%; Average loss: 2.8378\n",
      "Iteration: 785; Percent complete: 19.6%; Average loss: 3.2458\n",
      "Iteration: 786; Percent complete: 19.7%; Average loss: 2.9738\n",
      "Iteration: 787; Percent complete: 19.7%; Average loss: 3.0382\n",
      "Iteration: 788; Percent complete: 19.7%; Average loss: 3.3071\n",
      "Iteration: 789; Percent complete: 19.7%; Average loss: 3.0011\n",
      "Iteration: 790; Percent complete: 19.8%; Average loss: 2.7043\n",
      "Iteration: 791; Percent complete: 19.8%; Average loss: 3.2896\n",
      "Iteration: 792; Percent complete: 19.8%; Average loss: 2.9492\n",
      "Iteration: 793; Percent complete: 19.8%; Average loss: 2.8414\n",
      "Iteration: 794; Percent complete: 19.9%; Average loss: 2.8563\n",
      "Iteration: 795; Percent complete: 19.9%; Average loss: 2.9693\n",
      "Iteration: 796; Percent complete: 19.9%; Average loss: 2.8702\n",
      "Iteration: 797; Percent complete: 19.9%; Average loss: 3.0016\n",
      "Iteration: 798; Percent complete: 20.0%; Average loss: 3.3377\n",
      "Iteration: 799; Percent complete: 20.0%; Average loss: 2.7839\n",
      "Iteration: 800; Percent complete: 20.0%; Average loss: 3.1318\n",
      "Iteration: 801; Percent complete: 20.0%; Average loss: 3.0507\n",
      "Iteration: 802; Percent complete: 20.1%; Average loss: 2.9893\n",
      "Iteration: 803; Percent complete: 20.1%; Average loss: 3.1130\n",
      "Iteration: 804; Percent complete: 20.1%; Average loss: 2.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 805; Percent complete: 20.1%; Average loss: 2.8865\n",
      "Iteration: 806; Percent complete: 20.2%; Average loss: 3.1373\n",
      "Iteration: 807; Percent complete: 20.2%; Average loss: 2.7135\n",
      "Iteration: 808; Percent complete: 20.2%; Average loss: 2.9431\n",
      "Iteration: 809; Percent complete: 20.2%; Average loss: 2.9535\n",
      "Iteration: 810; Percent complete: 20.2%; Average loss: 2.8953\n",
      "Iteration: 811; Percent complete: 20.3%; Average loss: 3.0020\n",
      "Iteration: 812; Percent complete: 20.3%; Average loss: 3.2816\n",
      "Iteration: 813; Percent complete: 20.3%; Average loss: 3.0219\n",
      "Iteration: 814; Percent complete: 20.3%; Average loss: 3.1160\n",
      "Iteration: 815; Percent complete: 20.4%; Average loss: 3.1284\n",
      "Iteration: 816; Percent complete: 20.4%; Average loss: 2.9450\n",
      "Iteration: 817; Percent complete: 20.4%; Average loss: 2.9581\n",
      "Iteration: 818; Percent complete: 20.4%; Average loss: 3.0028\n",
      "Iteration: 819; Percent complete: 20.5%; Average loss: 2.9057\n",
      "Iteration: 820; Percent complete: 20.5%; Average loss: 3.0178\n",
      "Iteration: 821; Percent complete: 20.5%; Average loss: 3.2941\n",
      "Iteration: 822; Percent complete: 20.5%; Average loss: 3.0633\n",
      "Iteration: 823; Percent complete: 20.6%; Average loss: 3.1822\n",
      "Iteration: 824; Percent complete: 20.6%; Average loss: 2.8544\n",
      "Iteration: 825; Percent complete: 20.6%; Average loss: 2.9165\n",
      "Iteration: 826; Percent complete: 20.6%; Average loss: 2.9779\n",
      "Iteration: 827; Percent complete: 20.7%; Average loss: 2.9646\n",
      "Iteration: 828; Percent complete: 20.7%; Average loss: 3.0299\n",
      "Iteration: 829; Percent complete: 20.7%; Average loss: 3.1860\n",
      "Iteration: 830; Percent complete: 20.8%; Average loss: 2.9837\n",
      "Iteration: 831; Percent complete: 20.8%; Average loss: 3.0244\n",
      "Iteration: 832; Percent complete: 20.8%; Average loss: 3.0360\n",
      "Iteration: 833; Percent complete: 20.8%; Average loss: 3.0875\n",
      "Iteration: 834; Percent complete: 20.8%; Average loss: 2.8728\n",
      "Iteration: 835; Percent complete: 20.9%; Average loss: 3.0442\n",
      "Iteration: 836; Percent complete: 20.9%; Average loss: 2.7039\n",
      "Iteration: 837; Percent complete: 20.9%; Average loss: 2.9689\n",
      "Iteration: 838; Percent complete: 20.9%; Average loss: 3.1923\n",
      "Iteration: 839; Percent complete: 21.0%; Average loss: 2.9922\n",
      "Iteration: 840; Percent complete: 21.0%; Average loss: 3.0059\n",
      "Iteration: 841; Percent complete: 21.0%; Average loss: 2.9333\n",
      "Iteration: 842; Percent complete: 21.1%; Average loss: 3.1583\n",
      "Iteration: 843; Percent complete: 21.1%; Average loss: 3.0576\n",
      "Iteration: 844; Percent complete: 21.1%; Average loss: 3.0860\n",
      "Iteration: 845; Percent complete: 21.1%; Average loss: 2.9862\n",
      "Iteration: 846; Percent complete: 21.1%; Average loss: 2.6069\n",
      "Iteration: 847; Percent complete: 21.2%; Average loss: 3.0601\n",
      "Iteration: 848; Percent complete: 21.2%; Average loss: 3.0247\n",
      "Iteration: 849; Percent complete: 21.2%; Average loss: 3.0980\n",
      "Iteration: 850; Percent complete: 21.2%; Average loss: 2.9754\n",
      "Iteration: 851; Percent complete: 21.3%; Average loss: 3.0874\n",
      "Iteration: 852; Percent complete: 21.3%; Average loss: 3.1912\n",
      "Iteration: 853; Percent complete: 21.3%; Average loss: 3.1038\n",
      "Iteration: 854; Percent complete: 21.3%; Average loss: 3.1543\n",
      "Iteration: 855; Percent complete: 21.4%; Average loss: 3.0260\n",
      "Iteration: 856; Percent complete: 21.4%; Average loss: 3.1786\n",
      "Iteration: 857; Percent complete: 21.4%; Average loss: 2.9962\n",
      "Iteration: 858; Percent complete: 21.4%; Average loss: 2.7570\n",
      "Iteration: 859; Percent complete: 21.5%; Average loss: 2.9702\n",
      "Iteration: 860; Percent complete: 21.5%; Average loss: 2.9544\n",
      "Iteration: 861; Percent complete: 21.5%; Average loss: 3.1239\n",
      "Iteration: 862; Percent complete: 21.6%; Average loss: 2.8796\n",
      "Iteration: 863; Percent complete: 21.6%; Average loss: 3.0293\n",
      "Iteration: 864; Percent complete: 21.6%; Average loss: 3.1979\n",
      "Iteration: 865; Percent complete: 21.6%; Average loss: 2.9421\n",
      "Iteration: 866; Percent complete: 21.6%; Average loss: 3.0244\n",
      "Iteration: 867; Percent complete: 21.7%; Average loss: 2.8983\n",
      "Iteration: 868; Percent complete: 21.7%; Average loss: 2.5844\n",
      "Iteration: 869; Percent complete: 21.7%; Average loss: 3.0148\n",
      "Iteration: 870; Percent complete: 21.8%; Average loss: 3.0264\n",
      "Iteration: 871; Percent complete: 21.8%; Average loss: 3.0199\n",
      "Iteration: 872; Percent complete: 21.8%; Average loss: 2.8857\n",
      "Iteration: 873; Percent complete: 21.8%; Average loss: 2.8443\n",
      "Iteration: 874; Percent complete: 21.9%; Average loss: 2.8178\n",
      "Iteration: 875; Percent complete: 21.9%; Average loss: 3.1364\n",
      "Iteration: 876; Percent complete: 21.9%; Average loss: 3.0701\n",
      "Iteration: 877; Percent complete: 21.9%; Average loss: 2.9500\n",
      "Iteration: 878; Percent complete: 21.9%; Average loss: 3.1768\n",
      "Iteration: 879; Percent complete: 22.0%; Average loss: 2.9374\n",
      "Iteration: 880; Percent complete: 22.0%; Average loss: 2.8527\n",
      "Iteration: 881; Percent complete: 22.0%; Average loss: 2.9391\n",
      "Iteration: 882; Percent complete: 22.1%; Average loss: 2.8740\n",
      "Iteration: 883; Percent complete: 22.1%; Average loss: 2.8097\n",
      "Iteration: 884; Percent complete: 22.1%; Average loss: 2.8847\n",
      "Iteration: 885; Percent complete: 22.1%; Average loss: 2.9183\n",
      "Iteration: 886; Percent complete: 22.1%; Average loss: 2.8384\n",
      "Iteration: 887; Percent complete: 22.2%; Average loss: 2.9730\n",
      "Iteration: 888; Percent complete: 22.2%; Average loss: 2.7372\n",
      "Iteration: 889; Percent complete: 22.2%; Average loss: 2.8664\n",
      "Iteration: 890; Percent complete: 22.2%; Average loss: 2.7765\n",
      "Iteration: 891; Percent complete: 22.3%; Average loss: 3.0044\n",
      "Iteration: 892; Percent complete: 22.3%; Average loss: 2.9660\n",
      "Iteration: 893; Percent complete: 22.3%; Average loss: 3.0297\n",
      "Iteration: 894; Percent complete: 22.4%; Average loss: 3.2117\n",
      "Iteration: 895; Percent complete: 22.4%; Average loss: 3.0854\n",
      "Iteration: 896; Percent complete: 22.4%; Average loss: 3.0013\n",
      "Iteration: 897; Percent complete: 22.4%; Average loss: 2.8861\n",
      "Iteration: 898; Percent complete: 22.4%; Average loss: 2.7391\n",
      "Iteration: 899; Percent complete: 22.5%; Average loss: 2.9298\n",
      "Iteration: 900; Percent complete: 22.5%; Average loss: 2.7235\n",
      "Iteration: 901; Percent complete: 22.5%; Average loss: 2.8308\n",
      "Iteration: 902; Percent complete: 22.6%; Average loss: 3.2866\n",
      "Iteration: 903; Percent complete: 22.6%; Average loss: 3.0313\n",
      "Iteration: 904; Percent complete: 22.6%; Average loss: 3.1757\n",
      "Iteration: 905; Percent complete: 22.6%; Average loss: 3.0202\n",
      "Iteration: 906; Percent complete: 22.7%; Average loss: 2.8935\n",
      "Iteration: 907; Percent complete: 22.7%; Average loss: 3.0801\n",
      "Iteration: 908; Percent complete: 22.7%; Average loss: 2.8802\n",
      "Iteration: 909; Percent complete: 22.7%; Average loss: 3.0846\n",
      "Iteration: 910; Percent complete: 22.8%; Average loss: 2.9985\n",
      "Iteration: 911; Percent complete: 22.8%; Average loss: 3.0221\n",
      "Iteration: 912; Percent complete: 22.8%; Average loss: 3.0471\n",
      "Iteration: 913; Percent complete: 22.8%; Average loss: 2.9251\n",
      "Iteration: 914; Percent complete: 22.9%; Average loss: 3.0263\n",
      "Iteration: 915; Percent complete: 22.9%; Average loss: 3.1324\n",
      "Iteration: 916; Percent complete: 22.9%; Average loss: 3.1264\n",
      "Iteration: 917; Percent complete: 22.9%; Average loss: 2.9278\n",
      "Iteration: 918; Percent complete: 22.9%; Average loss: 2.9429\n",
      "Iteration: 919; Percent complete: 23.0%; Average loss: 2.9451\n",
      "Iteration: 920; Percent complete: 23.0%; Average loss: 3.0570\n",
      "Iteration: 921; Percent complete: 23.0%; Average loss: 2.8524\n",
      "Iteration: 922; Percent complete: 23.1%; Average loss: 3.0473\n",
      "Iteration: 923; Percent complete: 23.1%; Average loss: 3.0118\n",
      "Iteration: 924; Percent complete: 23.1%; Average loss: 3.0923\n",
      "Iteration: 925; Percent complete: 23.1%; Average loss: 2.8784\n",
      "Iteration: 926; Percent complete: 23.2%; Average loss: 2.9793\n",
      "Iteration: 927; Percent complete: 23.2%; Average loss: 3.2297\n",
      "Iteration: 928; Percent complete: 23.2%; Average loss: 3.2269\n",
      "Iteration: 929; Percent complete: 23.2%; Average loss: 2.8885\n",
      "Iteration: 930; Percent complete: 23.2%; Average loss: 3.0462\n",
      "Iteration: 931; Percent complete: 23.3%; Average loss: 3.0509\n",
      "Iteration: 932; Percent complete: 23.3%; Average loss: 2.9315\n",
      "Iteration: 933; Percent complete: 23.3%; Average loss: 2.8646\n",
      "Iteration: 934; Percent complete: 23.4%; Average loss: 2.9253\n",
      "Iteration: 935; Percent complete: 23.4%; Average loss: 2.6551\n",
      "Iteration: 936; Percent complete: 23.4%; Average loss: 3.2131\n",
      "Iteration: 937; Percent complete: 23.4%; Average loss: 2.7130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 938; Percent complete: 23.4%; Average loss: 3.2455\n",
      "Iteration: 939; Percent complete: 23.5%; Average loss: 2.7410\n",
      "Iteration: 940; Percent complete: 23.5%; Average loss: 2.9439\n",
      "Iteration: 941; Percent complete: 23.5%; Average loss: 2.8463\n",
      "Iteration: 942; Percent complete: 23.5%; Average loss: 2.9876\n",
      "Iteration: 943; Percent complete: 23.6%; Average loss: 2.7541\n",
      "Iteration: 944; Percent complete: 23.6%; Average loss: 2.8363\n",
      "Iteration: 945; Percent complete: 23.6%; Average loss: 2.9182\n",
      "Iteration: 946; Percent complete: 23.6%; Average loss: 2.8883\n",
      "Iteration: 947; Percent complete: 23.7%; Average loss: 2.8646\n",
      "Iteration: 948; Percent complete: 23.7%; Average loss: 3.0061\n",
      "Iteration: 949; Percent complete: 23.7%; Average loss: 3.0173\n",
      "Iteration: 950; Percent complete: 23.8%; Average loss: 3.0896\n",
      "Iteration: 951; Percent complete: 23.8%; Average loss: 2.8836\n",
      "Iteration: 952; Percent complete: 23.8%; Average loss: 2.7953\n",
      "Iteration: 953; Percent complete: 23.8%; Average loss: 2.9732\n",
      "Iteration: 954; Percent complete: 23.8%; Average loss: 3.0185\n",
      "Iteration: 955; Percent complete: 23.9%; Average loss: 2.8844\n",
      "Iteration: 956; Percent complete: 23.9%; Average loss: 3.0175\n",
      "Iteration: 957; Percent complete: 23.9%; Average loss: 2.9199\n",
      "Iteration: 958; Percent complete: 23.9%; Average loss: 2.8496\n",
      "Iteration: 959; Percent complete: 24.0%; Average loss: 3.1763\n",
      "Iteration: 960; Percent complete: 24.0%; Average loss: 2.9707\n",
      "Iteration: 961; Percent complete: 24.0%; Average loss: 2.8839\n",
      "Iteration: 962; Percent complete: 24.1%; Average loss: 2.9095\n",
      "Iteration: 963; Percent complete: 24.1%; Average loss: 2.9099\n",
      "Iteration: 964; Percent complete: 24.1%; Average loss: 2.8412\n",
      "Iteration: 965; Percent complete: 24.1%; Average loss: 2.9172\n",
      "Iteration: 966; Percent complete: 24.1%; Average loss: 2.9366\n",
      "Iteration: 967; Percent complete: 24.2%; Average loss: 2.7984\n",
      "Iteration: 968; Percent complete: 24.2%; Average loss: 2.9671\n",
      "Iteration: 969; Percent complete: 24.2%; Average loss: 2.9901\n",
      "Iteration: 970; Percent complete: 24.2%; Average loss: 2.8466\n",
      "Iteration: 971; Percent complete: 24.3%; Average loss: 2.9195\n",
      "Iteration: 972; Percent complete: 24.3%; Average loss: 2.9457\n",
      "Iteration: 973; Percent complete: 24.3%; Average loss: 2.7744\n",
      "Iteration: 974; Percent complete: 24.3%; Average loss: 2.7201\n",
      "Iteration: 975; Percent complete: 24.4%; Average loss: 2.8473\n",
      "Iteration: 976; Percent complete: 24.4%; Average loss: 3.3291\n",
      "Iteration: 977; Percent complete: 24.4%; Average loss: 2.6714\n",
      "Iteration: 978; Percent complete: 24.4%; Average loss: 2.9586\n",
      "Iteration: 979; Percent complete: 24.5%; Average loss: 2.8560\n",
      "Iteration: 980; Percent complete: 24.5%; Average loss: 3.1641\n",
      "Iteration: 981; Percent complete: 24.5%; Average loss: 3.0854\n",
      "Iteration: 982; Percent complete: 24.6%; Average loss: 2.7865\n",
      "Iteration: 983; Percent complete: 24.6%; Average loss: 3.0614\n",
      "Iteration: 984; Percent complete: 24.6%; Average loss: 3.1884\n",
      "Iteration: 985; Percent complete: 24.6%; Average loss: 2.7309\n",
      "Iteration: 986; Percent complete: 24.6%; Average loss: 3.0577\n",
      "Iteration: 987; Percent complete: 24.7%; Average loss: 3.2464\n",
      "Iteration: 988; Percent complete: 24.7%; Average loss: 3.1948\n",
      "Iteration: 989; Percent complete: 24.7%; Average loss: 2.9789\n",
      "Iteration: 990; Percent complete: 24.8%; Average loss: 2.8836\n",
      "Iteration: 991; Percent complete: 24.8%; Average loss: 2.9603\n",
      "Iteration: 992; Percent complete: 24.8%; Average loss: 2.8209\n",
      "Iteration: 993; Percent complete: 24.8%; Average loss: 3.1053\n",
      "Iteration: 994; Percent complete: 24.9%; Average loss: 2.9208\n",
      "Iteration: 995; Percent complete: 24.9%; Average loss: 2.8859\n",
      "Iteration: 996; Percent complete: 24.9%; Average loss: 2.6431\n",
      "Iteration: 997; Percent complete: 24.9%; Average loss: 2.9912\n",
      "Iteration: 998; Percent complete: 24.9%; Average loss: 2.6714\n",
      "Iteration: 999; Percent complete: 25.0%; Average loss: 2.8478\n",
      "Iteration: 1000; Percent complete: 25.0%; Average loss: 2.9024\n",
      "Iteration: 1001; Percent complete: 25.0%; Average loss: 2.7581\n",
      "Iteration: 1002; Percent complete: 25.1%; Average loss: 2.7013\n",
      "Iteration: 1003; Percent complete: 25.1%; Average loss: 2.7593\n",
      "Iteration: 1004; Percent complete: 25.1%; Average loss: 2.8768\n",
      "Iteration: 1005; Percent complete: 25.1%; Average loss: 2.8110\n",
      "Iteration: 1006; Percent complete: 25.1%; Average loss: 2.7801\n",
      "Iteration: 1007; Percent complete: 25.2%; Average loss: 2.8912\n",
      "Iteration: 1008; Percent complete: 25.2%; Average loss: 2.8094\n",
      "Iteration: 1009; Percent complete: 25.2%; Average loss: 3.1316\n",
      "Iteration: 1010; Percent complete: 25.2%; Average loss: 2.8759\n",
      "Iteration: 1011; Percent complete: 25.3%; Average loss: 3.0241\n",
      "Iteration: 1012; Percent complete: 25.3%; Average loss: 2.8657\n",
      "Iteration: 1013; Percent complete: 25.3%; Average loss: 2.9257\n",
      "Iteration: 1014; Percent complete: 25.4%; Average loss: 2.8557\n",
      "Iteration: 1015; Percent complete: 25.4%; Average loss: 3.0366\n",
      "Iteration: 1016; Percent complete: 25.4%; Average loss: 3.0366\n",
      "Iteration: 1017; Percent complete: 25.4%; Average loss: 2.9034\n",
      "Iteration: 1018; Percent complete: 25.4%; Average loss: 2.9406\n",
      "Iteration: 1019; Percent complete: 25.5%; Average loss: 3.0281\n",
      "Iteration: 1020; Percent complete: 25.5%; Average loss: 3.1519\n",
      "Iteration: 1021; Percent complete: 25.5%; Average loss: 2.8451\n",
      "Iteration: 1022; Percent complete: 25.6%; Average loss: 2.9233\n",
      "Iteration: 1023; Percent complete: 25.6%; Average loss: 2.6979\n",
      "Iteration: 1024; Percent complete: 25.6%; Average loss: 2.8428\n",
      "Iteration: 1025; Percent complete: 25.6%; Average loss: 3.0353\n",
      "Iteration: 1026; Percent complete: 25.7%; Average loss: 2.8925\n",
      "Iteration: 1027; Percent complete: 25.7%; Average loss: 2.8848\n",
      "Iteration: 1028; Percent complete: 25.7%; Average loss: 2.9400\n",
      "Iteration: 1029; Percent complete: 25.7%; Average loss: 2.9783\n",
      "Iteration: 1030; Percent complete: 25.8%; Average loss: 2.7010\n",
      "Iteration: 1031; Percent complete: 25.8%; Average loss: 2.7264\n",
      "Iteration: 1032; Percent complete: 25.8%; Average loss: 2.8287\n",
      "Iteration: 1033; Percent complete: 25.8%; Average loss: 2.7701\n",
      "Iteration: 1034; Percent complete: 25.9%; Average loss: 3.1426\n",
      "Iteration: 1035; Percent complete: 25.9%; Average loss: 2.7576\n",
      "Iteration: 1036; Percent complete: 25.9%; Average loss: 2.7017\n",
      "Iteration: 1037; Percent complete: 25.9%; Average loss: 3.0981\n",
      "Iteration: 1038; Percent complete: 25.9%; Average loss: 3.1176\n",
      "Iteration: 1039; Percent complete: 26.0%; Average loss: 2.8615\n",
      "Iteration: 1040; Percent complete: 26.0%; Average loss: 2.8848\n",
      "Iteration: 1041; Percent complete: 26.0%; Average loss: 2.8091\n",
      "Iteration: 1042; Percent complete: 26.1%; Average loss: 2.9335\n",
      "Iteration: 1043; Percent complete: 26.1%; Average loss: 3.1308\n",
      "Iteration: 1044; Percent complete: 26.1%; Average loss: 2.9707\n",
      "Iteration: 1045; Percent complete: 26.1%; Average loss: 2.9778\n",
      "Iteration: 1046; Percent complete: 26.2%; Average loss: 2.8152\n",
      "Iteration: 1047; Percent complete: 26.2%; Average loss: 3.0866\n",
      "Iteration: 1048; Percent complete: 26.2%; Average loss: 3.1326\n",
      "Iteration: 1049; Percent complete: 26.2%; Average loss: 2.8761\n",
      "Iteration: 1050; Percent complete: 26.2%; Average loss: 2.8678\n",
      "Iteration: 1051; Percent complete: 26.3%; Average loss: 2.9068\n",
      "Iteration: 1052; Percent complete: 26.3%; Average loss: 2.8216\n",
      "Iteration: 1053; Percent complete: 26.3%; Average loss: 2.9098\n",
      "Iteration: 1054; Percent complete: 26.4%; Average loss: 2.9058\n",
      "Iteration: 1055; Percent complete: 26.4%; Average loss: 2.9182\n",
      "Iteration: 1056; Percent complete: 26.4%; Average loss: 2.9346\n",
      "Iteration: 1057; Percent complete: 26.4%; Average loss: 2.8450\n",
      "Iteration: 1058; Percent complete: 26.5%; Average loss: 2.8808\n",
      "Iteration: 1059; Percent complete: 26.5%; Average loss: 2.7823\n",
      "Iteration: 1060; Percent complete: 26.5%; Average loss: 2.8765\n",
      "Iteration: 1061; Percent complete: 26.5%; Average loss: 2.9248\n",
      "Iteration: 1062; Percent complete: 26.6%; Average loss: 3.0054\n",
      "Iteration: 1063; Percent complete: 26.6%; Average loss: 3.0458\n",
      "Iteration: 1064; Percent complete: 26.6%; Average loss: 3.1742\n",
      "Iteration: 1065; Percent complete: 26.6%; Average loss: 2.6642\n",
      "Iteration: 1066; Percent complete: 26.7%; Average loss: 3.5128\n",
      "Iteration: 1067; Percent complete: 26.7%; Average loss: 2.5452\n",
      "Iteration: 1068; Percent complete: 26.7%; Average loss: 3.1428\n",
      "Iteration: 1069; Percent complete: 26.7%; Average loss: 2.8708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1070; Percent complete: 26.8%; Average loss: 2.7867\n",
      "Iteration: 1071; Percent complete: 26.8%; Average loss: 3.1237\n",
      "Iteration: 1072; Percent complete: 26.8%; Average loss: 2.9889\n",
      "Iteration: 1073; Percent complete: 26.8%; Average loss: 2.9339\n",
      "Iteration: 1074; Percent complete: 26.9%; Average loss: 2.9003\n",
      "Iteration: 1075; Percent complete: 26.9%; Average loss: 3.0286\n",
      "Iteration: 1076; Percent complete: 26.9%; Average loss: 2.4790\n",
      "Iteration: 1077; Percent complete: 26.9%; Average loss: 2.9385\n",
      "Iteration: 1078; Percent complete: 27.0%; Average loss: 2.5615\n",
      "Iteration: 1079; Percent complete: 27.0%; Average loss: 2.8095\n",
      "Iteration: 1080; Percent complete: 27.0%; Average loss: 3.1641\n",
      "Iteration: 1081; Percent complete: 27.0%; Average loss: 3.0510\n",
      "Iteration: 1082; Percent complete: 27.1%; Average loss: 2.6764\n",
      "Iteration: 1083; Percent complete: 27.1%; Average loss: 3.0404\n",
      "Iteration: 1084; Percent complete: 27.1%; Average loss: 2.9792\n",
      "Iteration: 1085; Percent complete: 27.1%; Average loss: 2.8321\n",
      "Iteration: 1086; Percent complete: 27.2%; Average loss: 2.7993\n",
      "Iteration: 1087; Percent complete: 27.2%; Average loss: 3.0153\n",
      "Iteration: 1088; Percent complete: 27.2%; Average loss: 2.9658\n",
      "Iteration: 1089; Percent complete: 27.2%; Average loss: 2.8506\n",
      "Iteration: 1090; Percent complete: 27.3%; Average loss: 2.8028\n",
      "Iteration: 1091; Percent complete: 27.3%; Average loss: 2.8408\n",
      "Iteration: 1092; Percent complete: 27.3%; Average loss: 3.1400\n",
      "Iteration: 1093; Percent complete: 27.3%; Average loss: 2.8754\n",
      "Iteration: 1094; Percent complete: 27.4%; Average loss: 2.8311\n",
      "Iteration: 1095; Percent complete: 27.4%; Average loss: 2.8942\n",
      "Iteration: 1096; Percent complete: 27.4%; Average loss: 2.8675\n",
      "Iteration: 1097; Percent complete: 27.4%; Average loss: 3.0558\n",
      "Iteration: 1098; Percent complete: 27.5%; Average loss: 2.7367\n",
      "Iteration: 1099; Percent complete: 27.5%; Average loss: 3.0944\n",
      "Iteration: 1100; Percent complete: 27.5%; Average loss: 3.0515\n",
      "Iteration: 1101; Percent complete: 27.5%; Average loss: 2.8129\n",
      "Iteration: 1102; Percent complete: 27.6%; Average loss: 2.8238\n",
      "Iteration: 1103; Percent complete: 27.6%; Average loss: 2.8329\n",
      "Iteration: 1104; Percent complete: 27.6%; Average loss: 3.1336\n",
      "Iteration: 1105; Percent complete: 27.6%; Average loss: 2.8229\n",
      "Iteration: 1106; Percent complete: 27.7%; Average loss: 2.7769\n",
      "Iteration: 1107; Percent complete: 27.7%; Average loss: 3.1137\n",
      "Iteration: 1108; Percent complete: 27.7%; Average loss: 2.9896\n",
      "Iteration: 1109; Percent complete: 27.7%; Average loss: 2.9908\n",
      "Iteration: 1110; Percent complete: 27.8%; Average loss: 2.9028\n",
      "Iteration: 1111; Percent complete: 27.8%; Average loss: 2.8952\n",
      "Iteration: 1112; Percent complete: 27.8%; Average loss: 2.9506\n",
      "Iteration: 1113; Percent complete: 27.8%; Average loss: 2.9681\n",
      "Iteration: 1114; Percent complete: 27.9%; Average loss: 2.7725\n",
      "Iteration: 1115; Percent complete: 27.9%; Average loss: 2.9061\n",
      "Iteration: 1116; Percent complete: 27.9%; Average loss: 2.5989\n",
      "Iteration: 1117; Percent complete: 27.9%; Average loss: 2.8561\n",
      "Iteration: 1118; Percent complete: 28.0%; Average loss: 2.9236\n",
      "Iteration: 1119; Percent complete: 28.0%; Average loss: 2.9114\n",
      "Iteration: 1120; Percent complete: 28.0%; Average loss: 2.8884\n",
      "Iteration: 1121; Percent complete: 28.0%; Average loss: 2.7388\n",
      "Iteration: 1122; Percent complete: 28.1%; Average loss: 2.7704\n",
      "Iteration: 1123; Percent complete: 28.1%; Average loss: 2.9180\n",
      "Iteration: 1124; Percent complete: 28.1%; Average loss: 2.9792\n",
      "Iteration: 1125; Percent complete: 28.1%; Average loss: 2.6641\n",
      "Iteration: 1126; Percent complete: 28.1%; Average loss: 2.9507\n",
      "Iteration: 1127; Percent complete: 28.2%; Average loss: 2.7920\n",
      "Iteration: 1128; Percent complete: 28.2%; Average loss: 2.8755\n",
      "Iteration: 1129; Percent complete: 28.2%; Average loss: 2.7318\n",
      "Iteration: 1130; Percent complete: 28.2%; Average loss: 2.7226\n",
      "Iteration: 1131; Percent complete: 28.3%; Average loss: 2.8424\n",
      "Iteration: 1132; Percent complete: 28.3%; Average loss: 2.7780\n",
      "Iteration: 1133; Percent complete: 28.3%; Average loss: 2.7997\n",
      "Iteration: 1134; Percent complete: 28.3%; Average loss: 3.1304\n",
      "Iteration: 1135; Percent complete: 28.4%; Average loss: 3.1182\n",
      "Iteration: 1136; Percent complete: 28.4%; Average loss: 2.8511\n",
      "Iteration: 1137; Percent complete: 28.4%; Average loss: 3.1224\n",
      "Iteration: 1138; Percent complete: 28.4%; Average loss: 2.7846\n",
      "Iteration: 1139; Percent complete: 28.5%; Average loss: 2.7967\n",
      "Iteration: 1140; Percent complete: 28.5%; Average loss: 2.8903\n",
      "Iteration: 1141; Percent complete: 28.5%; Average loss: 2.7845\n",
      "Iteration: 1142; Percent complete: 28.5%; Average loss: 2.9533\n",
      "Iteration: 1143; Percent complete: 28.6%; Average loss: 2.6386\n",
      "Iteration: 1144; Percent complete: 28.6%; Average loss: 2.9540\n",
      "Iteration: 1145; Percent complete: 28.6%; Average loss: 2.9191\n",
      "Iteration: 1146; Percent complete: 28.6%; Average loss: 3.0614\n",
      "Iteration: 1147; Percent complete: 28.7%; Average loss: 2.8293\n",
      "Iteration: 1148; Percent complete: 28.7%; Average loss: 2.8018\n",
      "Iteration: 1149; Percent complete: 28.7%; Average loss: 2.8653\n",
      "Iteration: 1150; Percent complete: 28.7%; Average loss: 2.9382\n",
      "Iteration: 1151; Percent complete: 28.8%; Average loss: 2.8327\n",
      "Iteration: 1152; Percent complete: 28.8%; Average loss: 2.9172\n",
      "Iteration: 1153; Percent complete: 28.8%; Average loss: 2.9713\n",
      "Iteration: 1154; Percent complete: 28.8%; Average loss: 2.7496\n",
      "Iteration: 1155; Percent complete: 28.9%; Average loss: 2.8468\n",
      "Iteration: 1156; Percent complete: 28.9%; Average loss: 2.7226\n",
      "Iteration: 1157; Percent complete: 28.9%; Average loss: 3.0196\n",
      "Iteration: 1158; Percent complete: 28.9%; Average loss: 3.0446\n",
      "Iteration: 1159; Percent complete: 29.0%; Average loss: 2.9899\n",
      "Iteration: 1160; Percent complete: 29.0%; Average loss: 2.7978\n",
      "Iteration: 1161; Percent complete: 29.0%; Average loss: 2.9082\n",
      "Iteration: 1162; Percent complete: 29.0%; Average loss: 3.0664\n",
      "Iteration: 1163; Percent complete: 29.1%; Average loss: 2.9471\n",
      "Iteration: 1164; Percent complete: 29.1%; Average loss: 2.7126\n",
      "Iteration: 1165; Percent complete: 29.1%; Average loss: 2.8211\n",
      "Iteration: 1166; Percent complete: 29.1%; Average loss: 3.1046\n",
      "Iteration: 1167; Percent complete: 29.2%; Average loss: 3.0427\n",
      "Iteration: 1168; Percent complete: 29.2%; Average loss: 2.7899\n",
      "Iteration: 1169; Percent complete: 29.2%; Average loss: 2.9938\n",
      "Iteration: 1170; Percent complete: 29.2%; Average loss: 2.9853\n",
      "Iteration: 1171; Percent complete: 29.3%; Average loss: 2.6483\n",
      "Iteration: 1172; Percent complete: 29.3%; Average loss: 2.9685\n",
      "Iteration: 1173; Percent complete: 29.3%; Average loss: 2.7542\n",
      "Iteration: 1174; Percent complete: 29.3%; Average loss: 2.9408\n",
      "Iteration: 1175; Percent complete: 29.4%; Average loss: 2.9182\n",
      "Iteration: 1176; Percent complete: 29.4%; Average loss: 2.6620\n",
      "Iteration: 1177; Percent complete: 29.4%; Average loss: 2.7597\n",
      "Iteration: 1178; Percent complete: 29.4%; Average loss: 2.8259\n",
      "Iteration: 1179; Percent complete: 29.5%; Average loss: 2.9554\n",
      "Iteration: 1180; Percent complete: 29.5%; Average loss: 3.0665\n",
      "Iteration: 1181; Percent complete: 29.5%; Average loss: 2.6428\n",
      "Iteration: 1182; Percent complete: 29.5%; Average loss: 2.8845\n",
      "Iteration: 1183; Percent complete: 29.6%; Average loss: 2.8067\n",
      "Iteration: 1184; Percent complete: 29.6%; Average loss: 2.8901\n",
      "Iteration: 1185; Percent complete: 29.6%; Average loss: 2.5988\n",
      "Iteration: 1186; Percent complete: 29.6%; Average loss: 2.8481\n",
      "Iteration: 1187; Percent complete: 29.7%; Average loss: 2.9764\n",
      "Iteration: 1188; Percent complete: 29.7%; Average loss: 2.6948\n",
      "Iteration: 1189; Percent complete: 29.7%; Average loss: 2.9093\n",
      "Iteration: 1190; Percent complete: 29.8%; Average loss: 2.8137\n",
      "Iteration: 1191; Percent complete: 29.8%; Average loss: 3.1937\n",
      "Iteration: 1192; Percent complete: 29.8%; Average loss: 2.8733\n",
      "Iteration: 1193; Percent complete: 29.8%; Average loss: 3.0168\n",
      "Iteration: 1194; Percent complete: 29.8%; Average loss: 3.1041\n",
      "Iteration: 1195; Percent complete: 29.9%; Average loss: 3.1095\n",
      "Iteration: 1196; Percent complete: 29.9%; Average loss: 2.8577\n",
      "Iteration: 1197; Percent complete: 29.9%; Average loss: 2.9107\n",
      "Iteration: 1198; Percent complete: 29.9%; Average loss: 2.7467\n",
      "Iteration: 1199; Percent complete: 30.0%; Average loss: 3.0281\n",
      "Iteration: 1200; Percent complete: 30.0%; Average loss: 2.6325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1201; Percent complete: 30.0%; Average loss: 2.6333\n",
      "Iteration: 1202; Percent complete: 30.0%; Average loss: 3.0505\n",
      "Iteration: 1203; Percent complete: 30.1%; Average loss: 2.9594\n",
      "Iteration: 1204; Percent complete: 30.1%; Average loss: 2.9222\n",
      "Iteration: 1205; Percent complete: 30.1%; Average loss: 2.5905\n",
      "Iteration: 1206; Percent complete: 30.1%; Average loss: 2.9363\n",
      "Iteration: 1207; Percent complete: 30.2%; Average loss: 3.1615\n",
      "Iteration: 1208; Percent complete: 30.2%; Average loss: 2.7524\n",
      "Iteration: 1209; Percent complete: 30.2%; Average loss: 2.8556\n",
      "Iteration: 1210; Percent complete: 30.2%; Average loss: 2.9699\n",
      "Iteration: 1211; Percent complete: 30.3%; Average loss: 2.8683\n",
      "Iteration: 1212; Percent complete: 30.3%; Average loss: 2.6954\n",
      "Iteration: 1213; Percent complete: 30.3%; Average loss: 2.8540\n",
      "Iteration: 1214; Percent complete: 30.3%; Average loss: 2.5875\n",
      "Iteration: 1215; Percent complete: 30.4%; Average loss: 2.5692\n",
      "Iteration: 1216; Percent complete: 30.4%; Average loss: 3.0135\n",
      "Iteration: 1217; Percent complete: 30.4%; Average loss: 2.6848\n",
      "Iteration: 1218; Percent complete: 30.4%; Average loss: 2.9035\n",
      "Iteration: 1219; Percent complete: 30.5%; Average loss: 2.7186\n",
      "Iteration: 1220; Percent complete: 30.5%; Average loss: 2.5916\n",
      "Iteration: 1221; Percent complete: 30.5%; Average loss: 2.8435\n",
      "Iteration: 1222; Percent complete: 30.6%; Average loss: 2.9960\n",
      "Iteration: 1223; Percent complete: 30.6%; Average loss: 2.6396\n",
      "Iteration: 1224; Percent complete: 30.6%; Average loss: 2.9516\n",
      "Iteration: 1225; Percent complete: 30.6%; Average loss: 2.7475\n",
      "Iteration: 1226; Percent complete: 30.6%; Average loss: 2.8383\n",
      "Iteration: 1227; Percent complete: 30.7%; Average loss: 3.0019\n",
      "Iteration: 1228; Percent complete: 30.7%; Average loss: 2.8288\n",
      "Iteration: 1229; Percent complete: 30.7%; Average loss: 2.6663\n",
      "Iteration: 1230; Percent complete: 30.8%; Average loss: 2.9258\n",
      "Iteration: 1231; Percent complete: 30.8%; Average loss: 2.8198\n",
      "Iteration: 1232; Percent complete: 30.8%; Average loss: 2.7545\n",
      "Iteration: 1233; Percent complete: 30.8%; Average loss: 2.9370\n",
      "Iteration: 1234; Percent complete: 30.9%; Average loss: 2.6975\n",
      "Iteration: 1235; Percent complete: 30.9%; Average loss: 2.6592\n",
      "Iteration: 1236; Percent complete: 30.9%; Average loss: 2.9682\n",
      "Iteration: 1237; Percent complete: 30.9%; Average loss: 2.9939\n",
      "Iteration: 1238; Percent complete: 30.9%; Average loss: 2.8508\n",
      "Iteration: 1239; Percent complete: 31.0%; Average loss: 2.7187\n",
      "Iteration: 1240; Percent complete: 31.0%; Average loss: 2.9636\n",
      "Iteration: 1241; Percent complete: 31.0%; Average loss: 2.6028\n",
      "Iteration: 1242; Percent complete: 31.1%; Average loss: 2.9655\n",
      "Iteration: 1243; Percent complete: 31.1%; Average loss: 2.9643\n",
      "Iteration: 1244; Percent complete: 31.1%; Average loss: 2.7607\n",
      "Iteration: 1245; Percent complete: 31.1%; Average loss: 2.9979\n",
      "Iteration: 1246; Percent complete: 31.1%; Average loss: 2.8666\n",
      "Iteration: 1247; Percent complete: 31.2%; Average loss: 2.7028\n",
      "Iteration: 1248; Percent complete: 31.2%; Average loss: 2.8800\n",
      "Iteration: 1249; Percent complete: 31.2%; Average loss: 2.9373\n",
      "Iteration: 1250; Percent complete: 31.2%; Average loss: 3.0051\n",
      "Iteration: 1251; Percent complete: 31.3%; Average loss: 2.8753\n",
      "Iteration: 1252; Percent complete: 31.3%; Average loss: 2.7044\n",
      "Iteration: 1253; Percent complete: 31.3%; Average loss: 2.7439\n",
      "Iteration: 1254; Percent complete: 31.4%; Average loss: 2.8448\n",
      "Iteration: 1255; Percent complete: 31.4%; Average loss: 3.1195\n",
      "Iteration: 1256; Percent complete: 31.4%; Average loss: 2.9871\n",
      "Iteration: 1257; Percent complete: 31.4%; Average loss: 2.7007\n",
      "Iteration: 1258; Percent complete: 31.4%; Average loss: 2.7356\n",
      "Iteration: 1259; Percent complete: 31.5%; Average loss: 2.7198\n",
      "Iteration: 1260; Percent complete: 31.5%; Average loss: 2.9424\n",
      "Iteration: 1261; Percent complete: 31.5%; Average loss: 2.7603\n",
      "Iteration: 1262; Percent complete: 31.6%; Average loss: 2.7917\n",
      "Iteration: 1263; Percent complete: 31.6%; Average loss: 2.8916\n",
      "Iteration: 1264; Percent complete: 31.6%; Average loss: 3.0058\n",
      "Iteration: 1265; Percent complete: 31.6%; Average loss: 2.7889\n",
      "Iteration: 1266; Percent complete: 31.6%; Average loss: 3.0205\n",
      "Iteration: 1267; Percent complete: 31.7%; Average loss: 2.8004\n",
      "Iteration: 1268; Percent complete: 31.7%; Average loss: 2.9185\n",
      "Iteration: 1269; Percent complete: 31.7%; Average loss: 2.8469\n",
      "Iteration: 1270; Percent complete: 31.8%; Average loss: 2.7498\n",
      "Iteration: 1271; Percent complete: 31.8%; Average loss: 2.6779\n",
      "Iteration: 1272; Percent complete: 31.8%; Average loss: 2.8639\n",
      "Iteration: 1273; Percent complete: 31.8%; Average loss: 2.8506\n",
      "Iteration: 1274; Percent complete: 31.9%; Average loss: 2.9772\n",
      "Iteration: 1275; Percent complete: 31.9%; Average loss: 2.7242\n",
      "Iteration: 1276; Percent complete: 31.9%; Average loss: 2.8356\n",
      "Iteration: 1277; Percent complete: 31.9%; Average loss: 2.9228\n",
      "Iteration: 1278; Percent complete: 31.9%; Average loss: 2.7856\n",
      "Iteration: 1279; Percent complete: 32.0%; Average loss: 2.7112\n",
      "Iteration: 1280; Percent complete: 32.0%; Average loss: 2.8817\n",
      "Iteration: 1281; Percent complete: 32.0%; Average loss: 2.7172\n",
      "Iteration: 1282; Percent complete: 32.0%; Average loss: 2.7182\n",
      "Iteration: 1283; Percent complete: 32.1%; Average loss: 2.5600\n",
      "Iteration: 1284; Percent complete: 32.1%; Average loss: 2.5903\n",
      "Iteration: 1285; Percent complete: 32.1%; Average loss: 2.6936\n",
      "Iteration: 1286; Percent complete: 32.1%; Average loss: 2.9814\n",
      "Iteration: 1287; Percent complete: 32.2%; Average loss: 2.7027\n",
      "Iteration: 1288; Percent complete: 32.2%; Average loss: 2.7678\n",
      "Iteration: 1289; Percent complete: 32.2%; Average loss: 2.6091\n",
      "Iteration: 1290; Percent complete: 32.2%; Average loss: 2.8018\n",
      "Iteration: 1291; Percent complete: 32.3%; Average loss: 2.6575\n",
      "Iteration: 1292; Percent complete: 32.3%; Average loss: 2.6472\n",
      "Iteration: 1293; Percent complete: 32.3%; Average loss: 2.7449\n",
      "Iteration: 1294; Percent complete: 32.4%; Average loss: 2.8939\n",
      "Iteration: 1295; Percent complete: 32.4%; Average loss: 2.7969\n",
      "Iteration: 1296; Percent complete: 32.4%; Average loss: 2.7225\n",
      "Iteration: 1297; Percent complete: 32.4%; Average loss: 2.6913\n",
      "Iteration: 1298; Percent complete: 32.5%; Average loss: 2.6941\n",
      "Iteration: 1299; Percent complete: 32.5%; Average loss: 2.9306\n",
      "Iteration: 1300; Percent complete: 32.5%; Average loss: 2.8454\n",
      "Iteration: 1301; Percent complete: 32.5%; Average loss: 2.6303\n",
      "Iteration: 1302; Percent complete: 32.6%; Average loss: 2.6388\n",
      "Iteration: 1303; Percent complete: 32.6%; Average loss: 2.6224\n",
      "Iteration: 1304; Percent complete: 32.6%; Average loss: 2.7330\n",
      "Iteration: 1305; Percent complete: 32.6%; Average loss: 2.8979\n",
      "Iteration: 1306; Percent complete: 32.6%; Average loss: 2.8948\n",
      "Iteration: 1307; Percent complete: 32.7%; Average loss: 2.7585\n",
      "Iteration: 1308; Percent complete: 32.7%; Average loss: 3.1338\n",
      "Iteration: 1309; Percent complete: 32.7%; Average loss: 2.7141\n",
      "Iteration: 1310; Percent complete: 32.8%; Average loss: 2.5837\n",
      "Iteration: 1311; Percent complete: 32.8%; Average loss: 2.8175\n",
      "Iteration: 1312; Percent complete: 32.8%; Average loss: 2.8071\n",
      "Iteration: 1313; Percent complete: 32.8%; Average loss: 3.1751\n",
      "Iteration: 1314; Percent complete: 32.9%; Average loss: 2.6891\n",
      "Iteration: 1315; Percent complete: 32.9%; Average loss: 2.8459\n",
      "Iteration: 1316; Percent complete: 32.9%; Average loss: 2.6990\n",
      "Iteration: 1317; Percent complete: 32.9%; Average loss: 2.8526\n",
      "Iteration: 1318; Percent complete: 33.0%; Average loss: 2.7352\n",
      "Iteration: 1319; Percent complete: 33.0%; Average loss: 2.8978\n",
      "Iteration: 1320; Percent complete: 33.0%; Average loss: 2.7663\n",
      "Iteration: 1321; Percent complete: 33.0%; Average loss: 3.0711\n",
      "Iteration: 1322; Percent complete: 33.1%; Average loss: 2.8460\n",
      "Iteration: 1323; Percent complete: 33.1%; Average loss: 2.7484\n",
      "Iteration: 1324; Percent complete: 33.1%; Average loss: 2.8750\n",
      "Iteration: 1325; Percent complete: 33.1%; Average loss: 2.6411\n",
      "Iteration: 1326; Percent complete: 33.1%; Average loss: 2.9650\n",
      "Iteration: 1327; Percent complete: 33.2%; Average loss: 2.7253\n",
      "Iteration: 1328; Percent complete: 33.2%; Average loss: 2.8066\n",
      "Iteration: 1329; Percent complete: 33.2%; Average loss: 2.8108\n",
      "Iteration: 1330; Percent complete: 33.2%; Average loss: 2.7101\n",
      "Iteration: 1331; Percent complete: 33.3%; Average loss: 2.7796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1332; Percent complete: 33.3%; Average loss: 2.8933\n",
      "Iteration: 1333; Percent complete: 33.3%; Average loss: 2.8423\n",
      "Iteration: 1334; Percent complete: 33.4%; Average loss: 2.8495\n",
      "Iteration: 1335; Percent complete: 33.4%; Average loss: 2.8388\n",
      "Iteration: 1336; Percent complete: 33.4%; Average loss: 2.7905\n",
      "Iteration: 1337; Percent complete: 33.4%; Average loss: 2.7273\n",
      "Iteration: 1338; Percent complete: 33.5%; Average loss: 2.7588\n",
      "Iteration: 1339; Percent complete: 33.5%; Average loss: 2.8971\n",
      "Iteration: 1340; Percent complete: 33.5%; Average loss: 2.8623\n",
      "Iteration: 1341; Percent complete: 33.5%; Average loss: 2.9023\n",
      "Iteration: 1342; Percent complete: 33.6%; Average loss: 2.8837\n",
      "Iteration: 1343; Percent complete: 33.6%; Average loss: 2.9793\n",
      "Iteration: 1344; Percent complete: 33.6%; Average loss: 2.7350\n",
      "Iteration: 1345; Percent complete: 33.6%; Average loss: 2.8442\n",
      "Iteration: 1346; Percent complete: 33.7%; Average loss: 2.8286\n",
      "Iteration: 1347; Percent complete: 33.7%; Average loss: 2.7187\n",
      "Iteration: 1348; Percent complete: 33.7%; Average loss: 2.9808\n",
      "Iteration: 1349; Percent complete: 33.7%; Average loss: 2.7259\n",
      "Iteration: 1350; Percent complete: 33.8%; Average loss: 2.8000\n",
      "Iteration: 1351; Percent complete: 33.8%; Average loss: 2.7648\n",
      "Iteration: 1352; Percent complete: 33.8%; Average loss: 2.7182\n",
      "Iteration: 1353; Percent complete: 33.8%; Average loss: 2.9297\n",
      "Iteration: 1354; Percent complete: 33.9%; Average loss: 2.4490\n",
      "Iteration: 1355; Percent complete: 33.9%; Average loss: 2.8876\n",
      "Iteration: 1356; Percent complete: 33.9%; Average loss: 2.7754\n",
      "Iteration: 1357; Percent complete: 33.9%; Average loss: 2.8933\n",
      "Iteration: 1358; Percent complete: 34.0%; Average loss: 2.8296\n",
      "Iteration: 1359; Percent complete: 34.0%; Average loss: 3.0813\n",
      "Iteration: 1360; Percent complete: 34.0%; Average loss: 2.8261\n",
      "Iteration: 1361; Percent complete: 34.0%; Average loss: 2.7390\n",
      "Iteration: 1362; Percent complete: 34.1%; Average loss: 2.9344\n",
      "Iteration: 1363; Percent complete: 34.1%; Average loss: 2.7503\n",
      "Iteration: 1364; Percent complete: 34.1%; Average loss: 3.1798\n",
      "Iteration: 1365; Percent complete: 34.1%; Average loss: 2.7935\n",
      "Iteration: 1366; Percent complete: 34.2%; Average loss: 2.5439\n",
      "Iteration: 1367; Percent complete: 34.2%; Average loss: 3.0478\n",
      "Iteration: 1368; Percent complete: 34.2%; Average loss: 3.2360\n",
      "Iteration: 1369; Percent complete: 34.2%; Average loss: 2.6772\n",
      "Iteration: 1370; Percent complete: 34.2%; Average loss: 2.7408\n",
      "Iteration: 1371; Percent complete: 34.3%; Average loss: 2.7829\n",
      "Iteration: 1372; Percent complete: 34.3%; Average loss: 2.8342\n",
      "Iteration: 1373; Percent complete: 34.3%; Average loss: 2.7450\n",
      "Iteration: 1374; Percent complete: 34.4%; Average loss: 2.8110\n",
      "Iteration: 1375; Percent complete: 34.4%; Average loss: 2.6323\n",
      "Iteration: 1376; Percent complete: 34.4%; Average loss: 2.8791\n",
      "Iteration: 1377; Percent complete: 34.4%; Average loss: 2.8865\n",
      "Iteration: 1378; Percent complete: 34.4%; Average loss: 2.7869\n",
      "Iteration: 1379; Percent complete: 34.5%; Average loss: 2.6865\n",
      "Iteration: 1380; Percent complete: 34.5%; Average loss: 2.7837\n",
      "Iteration: 1381; Percent complete: 34.5%; Average loss: 2.8961\n",
      "Iteration: 1382; Percent complete: 34.5%; Average loss: 2.7945\n",
      "Iteration: 1383; Percent complete: 34.6%; Average loss: 2.8289\n",
      "Iteration: 1384; Percent complete: 34.6%; Average loss: 2.8532\n",
      "Iteration: 1385; Percent complete: 34.6%; Average loss: 2.7637\n",
      "Iteration: 1386; Percent complete: 34.6%; Average loss: 2.9203\n",
      "Iteration: 1387; Percent complete: 34.7%; Average loss: 2.7591\n",
      "Iteration: 1388; Percent complete: 34.7%; Average loss: 2.7875\n",
      "Iteration: 1389; Percent complete: 34.7%; Average loss: 2.6468\n",
      "Iteration: 1390; Percent complete: 34.8%; Average loss: 2.8579\n",
      "Iteration: 1391; Percent complete: 34.8%; Average loss: 2.9270\n",
      "Iteration: 1392; Percent complete: 34.8%; Average loss: 2.8485\n",
      "Iteration: 1393; Percent complete: 34.8%; Average loss: 2.7431\n",
      "Iteration: 1394; Percent complete: 34.8%; Average loss: 2.8375\n",
      "Iteration: 1395; Percent complete: 34.9%; Average loss: 3.1469\n",
      "Iteration: 1396; Percent complete: 34.9%; Average loss: 2.6128\n",
      "Iteration: 1397; Percent complete: 34.9%; Average loss: 2.9182\n",
      "Iteration: 1398; Percent complete: 34.9%; Average loss: 3.0554\n",
      "Iteration: 1399; Percent complete: 35.0%; Average loss: 2.7288\n",
      "Iteration: 1400; Percent complete: 35.0%; Average loss: 2.7722\n",
      "Iteration: 1401; Percent complete: 35.0%; Average loss: 2.7742\n",
      "Iteration: 1402; Percent complete: 35.0%; Average loss: 2.7571\n",
      "Iteration: 1403; Percent complete: 35.1%; Average loss: 2.8553\n",
      "Iteration: 1404; Percent complete: 35.1%; Average loss: 2.7574\n",
      "Iteration: 1405; Percent complete: 35.1%; Average loss: 2.8383\n",
      "Iteration: 1406; Percent complete: 35.1%; Average loss: 2.9758\n",
      "Iteration: 1407; Percent complete: 35.2%; Average loss: 2.8214\n",
      "Iteration: 1408; Percent complete: 35.2%; Average loss: 2.8055\n",
      "Iteration: 1409; Percent complete: 35.2%; Average loss: 2.9379\n",
      "Iteration: 1410; Percent complete: 35.2%; Average loss: 2.8395\n",
      "Iteration: 1411; Percent complete: 35.3%; Average loss: 2.6782\n",
      "Iteration: 1412; Percent complete: 35.3%; Average loss: 2.8806\n",
      "Iteration: 1413; Percent complete: 35.3%; Average loss: 2.7203\n",
      "Iteration: 1414; Percent complete: 35.4%; Average loss: 2.7204\n",
      "Iteration: 1415; Percent complete: 35.4%; Average loss: 2.8266\n",
      "Iteration: 1416; Percent complete: 35.4%; Average loss: 2.5902\n",
      "Iteration: 1417; Percent complete: 35.4%; Average loss: 2.9483\n",
      "Iteration: 1418; Percent complete: 35.4%; Average loss: 3.1674\n",
      "Iteration: 1419; Percent complete: 35.5%; Average loss: 2.5812\n",
      "Iteration: 1420; Percent complete: 35.5%; Average loss: 2.6194\n",
      "Iteration: 1421; Percent complete: 35.5%; Average loss: 2.7148\n",
      "Iteration: 1422; Percent complete: 35.5%; Average loss: 2.7600\n",
      "Iteration: 1423; Percent complete: 35.6%; Average loss: 2.7808\n",
      "Iteration: 1424; Percent complete: 35.6%; Average loss: 2.5245\n",
      "Iteration: 1425; Percent complete: 35.6%; Average loss: 2.8917\n",
      "Iteration: 1426; Percent complete: 35.6%; Average loss: 2.9948\n",
      "Iteration: 1427; Percent complete: 35.7%; Average loss: 2.8986\n",
      "Iteration: 1428; Percent complete: 35.7%; Average loss: 2.9403\n",
      "Iteration: 1429; Percent complete: 35.7%; Average loss: 2.6399\n",
      "Iteration: 1430; Percent complete: 35.8%; Average loss: 2.7786\n",
      "Iteration: 1431; Percent complete: 35.8%; Average loss: 2.7981\n",
      "Iteration: 1432; Percent complete: 35.8%; Average loss: 2.7982\n",
      "Iteration: 1433; Percent complete: 35.8%; Average loss: 2.7660\n",
      "Iteration: 1434; Percent complete: 35.9%; Average loss: 2.6588\n",
      "Iteration: 1435; Percent complete: 35.9%; Average loss: 2.7644\n",
      "Iteration: 1436; Percent complete: 35.9%; Average loss: 2.7247\n",
      "Iteration: 1437; Percent complete: 35.9%; Average loss: 3.0439\n",
      "Iteration: 1438; Percent complete: 35.9%; Average loss: 2.7625\n",
      "Iteration: 1439; Percent complete: 36.0%; Average loss: 2.8580\n",
      "Iteration: 1440; Percent complete: 36.0%; Average loss: 2.6204\n",
      "Iteration: 1441; Percent complete: 36.0%; Average loss: 2.7383\n",
      "Iteration: 1442; Percent complete: 36.0%; Average loss: 2.9946\n",
      "Iteration: 1443; Percent complete: 36.1%; Average loss: 2.9822\n",
      "Iteration: 1444; Percent complete: 36.1%; Average loss: 2.8900\n",
      "Iteration: 1445; Percent complete: 36.1%; Average loss: 2.8436\n",
      "Iteration: 1446; Percent complete: 36.1%; Average loss: 2.5744\n",
      "Iteration: 1447; Percent complete: 36.2%; Average loss: 2.7253\n",
      "Iteration: 1448; Percent complete: 36.2%; Average loss: 2.6628\n",
      "Iteration: 1449; Percent complete: 36.2%; Average loss: 2.3438\n",
      "Iteration: 1450; Percent complete: 36.2%; Average loss: 2.6878\n",
      "Iteration: 1451; Percent complete: 36.3%; Average loss: 2.9953\n",
      "Iteration: 1452; Percent complete: 36.3%; Average loss: 2.8301\n",
      "Iteration: 1453; Percent complete: 36.3%; Average loss: 2.7617\n",
      "Iteration: 1454; Percent complete: 36.4%; Average loss: 2.8493\n",
      "Iteration: 1455; Percent complete: 36.4%; Average loss: 2.7460\n",
      "Iteration: 1456; Percent complete: 36.4%; Average loss: 3.0116\n",
      "Iteration: 1457; Percent complete: 36.4%; Average loss: 2.7319\n",
      "Iteration: 1458; Percent complete: 36.4%; Average loss: 2.5152\n",
      "Iteration: 1459; Percent complete: 36.5%; Average loss: 2.8269\n",
      "Iteration: 1460; Percent complete: 36.5%; Average loss: 2.7336\n",
      "Iteration: 1461; Percent complete: 36.5%; Average loss: 2.4542\n",
      "Iteration: 1462; Percent complete: 36.5%; Average loss: 2.6691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1463; Percent complete: 36.6%; Average loss: 2.8548\n",
      "Iteration: 1464; Percent complete: 36.6%; Average loss: 2.5950\n",
      "Iteration: 1465; Percent complete: 36.6%; Average loss: 2.8620\n",
      "Iteration: 1466; Percent complete: 36.6%; Average loss: 2.4825\n",
      "Iteration: 1467; Percent complete: 36.7%; Average loss: 2.7991\n",
      "Iteration: 1468; Percent complete: 36.7%; Average loss: 2.8660\n",
      "Iteration: 1469; Percent complete: 36.7%; Average loss: 2.6505\n",
      "Iteration: 1470; Percent complete: 36.8%; Average loss: 2.8801\n",
      "Iteration: 1471; Percent complete: 36.8%; Average loss: 2.6040\n",
      "Iteration: 1472; Percent complete: 36.8%; Average loss: 2.6878\n",
      "Iteration: 1473; Percent complete: 36.8%; Average loss: 2.8223\n",
      "Iteration: 1474; Percent complete: 36.9%; Average loss: 2.7796\n",
      "Iteration: 1475; Percent complete: 36.9%; Average loss: 2.7332\n",
      "Iteration: 1476; Percent complete: 36.9%; Average loss: 2.7354\n",
      "Iteration: 1477; Percent complete: 36.9%; Average loss: 2.8472\n",
      "Iteration: 1478; Percent complete: 37.0%; Average loss: 2.8817\n",
      "Iteration: 1479; Percent complete: 37.0%; Average loss: 2.5494\n",
      "Iteration: 1480; Percent complete: 37.0%; Average loss: 2.9314\n",
      "Iteration: 1481; Percent complete: 37.0%; Average loss: 2.8245\n",
      "Iteration: 1482; Percent complete: 37.0%; Average loss: 2.8358\n",
      "Iteration: 1483; Percent complete: 37.1%; Average loss: 2.6248\n",
      "Iteration: 1484; Percent complete: 37.1%; Average loss: 2.6919\n",
      "Iteration: 1485; Percent complete: 37.1%; Average loss: 3.0996\n",
      "Iteration: 1486; Percent complete: 37.1%; Average loss: 2.7458\n",
      "Iteration: 1487; Percent complete: 37.2%; Average loss: 2.7208\n",
      "Iteration: 1488; Percent complete: 37.2%; Average loss: 2.6759\n",
      "Iteration: 1489; Percent complete: 37.2%; Average loss: 2.8861\n",
      "Iteration: 1490; Percent complete: 37.2%; Average loss: 2.8852\n",
      "Iteration: 1491; Percent complete: 37.3%; Average loss: 2.6251\n",
      "Iteration: 1492; Percent complete: 37.3%; Average loss: 3.1174\n",
      "Iteration: 1493; Percent complete: 37.3%; Average loss: 2.9273\n",
      "Iteration: 1494; Percent complete: 37.4%; Average loss: 2.7603\n",
      "Iteration: 1495; Percent complete: 37.4%; Average loss: 2.8271\n",
      "Iteration: 1496; Percent complete: 37.4%; Average loss: 2.6012\n",
      "Iteration: 1497; Percent complete: 37.4%; Average loss: 2.6695\n",
      "Iteration: 1498; Percent complete: 37.5%; Average loss: 2.8452\n",
      "Iteration: 1499; Percent complete: 37.5%; Average loss: 2.7424\n",
      "Iteration: 1500; Percent complete: 37.5%; Average loss: 2.6652\n",
      "Iteration: 1501; Percent complete: 37.5%; Average loss: 2.7075\n",
      "Iteration: 1502; Percent complete: 37.5%; Average loss: 2.7632\n",
      "Iteration: 1503; Percent complete: 37.6%; Average loss: 2.8958\n",
      "Iteration: 1504; Percent complete: 37.6%; Average loss: 3.0243\n",
      "Iteration: 1505; Percent complete: 37.6%; Average loss: 2.4049\n",
      "Iteration: 1506; Percent complete: 37.6%; Average loss: 2.8705\n",
      "Iteration: 1507; Percent complete: 37.7%; Average loss: 2.5803\n",
      "Iteration: 1508; Percent complete: 37.7%; Average loss: 2.7971\n",
      "Iteration: 1509; Percent complete: 37.7%; Average loss: 2.9408\n",
      "Iteration: 1510; Percent complete: 37.8%; Average loss: 2.8758\n",
      "Iteration: 1511; Percent complete: 37.8%; Average loss: 2.5715\n",
      "Iteration: 1512; Percent complete: 37.8%; Average loss: 2.9342\n",
      "Iteration: 1513; Percent complete: 37.8%; Average loss: 2.7199\n",
      "Iteration: 1514; Percent complete: 37.9%; Average loss: 2.8922\n",
      "Iteration: 1515; Percent complete: 37.9%; Average loss: 2.8169\n",
      "Iteration: 1516; Percent complete: 37.9%; Average loss: 3.1191\n",
      "Iteration: 1517; Percent complete: 37.9%; Average loss: 2.7599\n",
      "Iteration: 1518; Percent complete: 38.0%; Average loss: 2.7406\n",
      "Iteration: 1519; Percent complete: 38.0%; Average loss: 2.8433\n",
      "Iteration: 1520; Percent complete: 38.0%; Average loss: 2.5252\n",
      "Iteration: 1521; Percent complete: 38.0%; Average loss: 2.4848\n",
      "Iteration: 1522; Percent complete: 38.0%; Average loss: 2.9907\n",
      "Iteration: 1523; Percent complete: 38.1%; Average loss: 2.9127\n",
      "Iteration: 1524; Percent complete: 38.1%; Average loss: 2.7640\n",
      "Iteration: 1525; Percent complete: 38.1%; Average loss: 2.7090\n",
      "Iteration: 1526; Percent complete: 38.1%; Average loss: 2.8330\n",
      "Iteration: 1527; Percent complete: 38.2%; Average loss: 2.7850\n",
      "Iteration: 1528; Percent complete: 38.2%; Average loss: 2.9324\n",
      "Iteration: 1529; Percent complete: 38.2%; Average loss: 2.7689\n",
      "Iteration: 1530; Percent complete: 38.2%; Average loss: 2.5773\n",
      "Iteration: 1531; Percent complete: 38.3%; Average loss: 2.7226\n",
      "Iteration: 1532; Percent complete: 38.3%; Average loss: 2.9450\n",
      "Iteration: 1533; Percent complete: 38.3%; Average loss: 2.8035\n",
      "Iteration: 1534; Percent complete: 38.4%; Average loss: 2.5538\n",
      "Iteration: 1535; Percent complete: 38.4%; Average loss: 2.4826\n",
      "Iteration: 1536; Percent complete: 38.4%; Average loss: 2.7271\n",
      "Iteration: 1537; Percent complete: 38.4%; Average loss: 2.6681\n",
      "Iteration: 1538; Percent complete: 38.5%; Average loss: 2.7470\n",
      "Iteration: 1539; Percent complete: 38.5%; Average loss: 2.7589\n",
      "Iteration: 1540; Percent complete: 38.5%; Average loss: 2.7271\n",
      "Iteration: 1541; Percent complete: 38.5%; Average loss: 2.6284\n",
      "Iteration: 1542; Percent complete: 38.6%; Average loss: 2.8637\n",
      "Iteration: 1543; Percent complete: 38.6%; Average loss: 2.8461\n",
      "Iteration: 1544; Percent complete: 38.6%; Average loss: 2.7439\n",
      "Iteration: 1545; Percent complete: 38.6%; Average loss: 2.6823\n",
      "Iteration: 1546; Percent complete: 38.6%; Average loss: 2.6872\n",
      "Iteration: 1547; Percent complete: 38.7%; Average loss: 2.4983\n",
      "Iteration: 1548; Percent complete: 38.7%; Average loss: 2.8623\n",
      "Iteration: 1549; Percent complete: 38.7%; Average loss: 2.8328\n",
      "Iteration: 1550; Percent complete: 38.8%; Average loss: 2.5776\n",
      "Iteration: 1551; Percent complete: 38.8%; Average loss: 2.5521\n",
      "Iteration: 1552; Percent complete: 38.8%; Average loss: 2.6916\n",
      "Iteration: 1553; Percent complete: 38.8%; Average loss: 2.8741\n",
      "Iteration: 1554; Percent complete: 38.9%; Average loss: 2.5827\n",
      "Iteration: 1555; Percent complete: 38.9%; Average loss: 2.6035\n",
      "Iteration: 1556; Percent complete: 38.9%; Average loss: 2.7633\n",
      "Iteration: 1557; Percent complete: 38.9%; Average loss: 3.0047\n",
      "Iteration: 1558; Percent complete: 39.0%; Average loss: 2.8199\n",
      "Iteration: 1559; Percent complete: 39.0%; Average loss: 2.4656\n",
      "Iteration: 1560; Percent complete: 39.0%; Average loss: 2.7483\n",
      "Iteration: 1561; Percent complete: 39.0%; Average loss: 2.7165\n",
      "Iteration: 1562; Percent complete: 39.1%; Average loss: 2.7675\n",
      "Iteration: 1563; Percent complete: 39.1%; Average loss: 2.6088\n",
      "Iteration: 1564; Percent complete: 39.1%; Average loss: 2.7964\n",
      "Iteration: 1565; Percent complete: 39.1%; Average loss: 2.6720\n",
      "Iteration: 1566; Percent complete: 39.1%; Average loss: 2.9284\n",
      "Iteration: 1567; Percent complete: 39.2%; Average loss: 2.7467\n",
      "Iteration: 1568; Percent complete: 39.2%; Average loss: 2.6991\n",
      "Iteration: 1569; Percent complete: 39.2%; Average loss: 2.6446\n",
      "Iteration: 1570; Percent complete: 39.2%; Average loss: 2.6395\n",
      "Iteration: 1571; Percent complete: 39.3%; Average loss: 2.7716\n",
      "Iteration: 1572; Percent complete: 39.3%; Average loss: 2.7736\n",
      "Iteration: 1573; Percent complete: 39.3%; Average loss: 2.7719\n",
      "Iteration: 1574; Percent complete: 39.4%; Average loss: 2.7193\n",
      "Iteration: 1575; Percent complete: 39.4%; Average loss: 2.5430\n",
      "Iteration: 1576; Percent complete: 39.4%; Average loss: 2.9494\n",
      "Iteration: 1577; Percent complete: 39.4%; Average loss: 2.7399\n",
      "Iteration: 1578; Percent complete: 39.5%; Average loss: 2.5141\n",
      "Iteration: 1579; Percent complete: 39.5%; Average loss: 2.7323\n",
      "Iteration: 1580; Percent complete: 39.5%; Average loss: 2.8571\n",
      "Iteration: 1581; Percent complete: 39.5%; Average loss: 2.5958\n",
      "Iteration: 1582; Percent complete: 39.6%; Average loss: 2.9245\n",
      "Iteration: 1583; Percent complete: 39.6%; Average loss: 2.7412\n",
      "Iteration: 1584; Percent complete: 39.6%; Average loss: 2.7468\n",
      "Iteration: 1585; Percent complete: 39.6%; Average loss: 2.5803\n",
      "Iteration: 1586; Percent complete: 39.6%; Average loss: 2.7452\n",
      "Iteration: 1587; Percent complete: 39.7%; Average loss: 2.7848\n",
      "Iteration: 1588; Percent complete: 39.7%; Average loss: 2.9908\n",
      "Iteration: 1589; Percent complete: 39.7%; Average loss: 2.8481\n",
      "Iteration: 1590; Percent complete: 39.8%; Average loss: 2.7760\n",
      "Iteration: 1591; Percent complete: 39.8%; Average loss: 2.5903\n",
      "Iteration: 1592; Percent complete: 39.8%; Average loss: 2.6923\n",
      "Iteration: 1593; Percent complete: 39.8%; Average loss: 2.6298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1594; Percent complete: 39.9%; Average loss: 2.8318\n",
      "Iteration: 1595; Percent complete: 39.9%; Average loss: 2.6002\n",
      "Iteration: 1596; Percent complete: 39.9%; Average loss: 2.9927\n",
      "Iteration: 1597; Percent complete: 39.9%; Average loss: 2.9985\n",
      "Iteration: 1598; Percent complete: 40.0%; Average loss: 2.9222\n",
      "Iteration: 1599; Percent complete: 40.0%; Average loss: 2.4940\n",
      "Iteration: 1600; Percent complete: 40.0%; Average loss: 2.8246\n",
      "Iteration: 1601; Percent complete: 40.0%; Average loss: 2.9342\n",
      "Iteration: 1602; Percent complete: 40.1%; Average loss: 2.8197\n",
      "Iteration: 1603; Percent complete: 40.1%; Average loss: 2.6459\n",
      "Iteration: 1604; Percent complete: 40.1%; Average loss: 2.9047\n",
      "Iteration: 1605; Percent complete: 40.1%; Average loss: 2.9568\n",
      "Iteration: 1606; Percent complete: 40.2%; Average loss: 2.7569\n",
      "Iteration: 1607; Percent complete: 40.2%; Average loss: 2.8163\n",
      "Iteration: 1608; Percent complete: 40.2%; Average loss: 2.6594\n",
      "Iteration: 1609; Percent complete: 40.2%; Average loss: 2.6887\n",
      "Iteration: 1610; Percent complete: 40.2%; Average loss: 2.7935\n",
      "Iteration: 1611; Percent complete: 40.3%; Average loss: 2.6300\n",
      "Iteration: 1612; Percent complete: 40.3%; Average loss: 2.7644\n",
      "Iteration: 1613; Percent complete: 40.3%; Average loss: 2.6913\n",
      "Iteration: 1614; Percent complete: 40.4%; Average loss: 2.6853\n",
      "Iteration: 1615; Percent complete: 40.4%; Average loss: 2.7903\n",
      "Iteration: 1616; Percent complete: 40.4%; Average loss: 2.8333\n",
      "Iteration: 1617; Percent complete: 40.4%; Average loss: 2.6786\n",
      "Iteration: 1618; Percent complete: 40.5%; Average loss: 2.7846\n",
      "Iteration: 1619; Percent complete: 40.5%; Average loss: 2.5068\n",
      "Iteration: 1620; Percent complete: 40.5%; Average loss: 2.9620\n",
      "Iteration: 1621; Percent complete: 40.5%; Average loss: 3.0900\n",
      "Iteration: 1622; Percent complete: 40.6%; Average loss: 2.5599\n",
      "Iteration: 1623; Percent complete: 40.6%; Average loss: 2.6304\n",
      "Iteration: 1624; Percent complete: 40.6%; Average loss: 2.7849\n",
      "Iteration: 1625; Percent complete: 40.6%; Average loss: 2.6598\n",
      "Iteration: 1626; Percent complete: 40.6%; Average loss: 2.6296\n",
      "Iteration: 1627; Percent complete: 40.7%; Average loss: 2.8108\n",
      "Iteration: 1628; Percent complete: 40.7%; Average loss: 2.6502\n",
      "Iteration: 1629; Percent complete: 40.7%; Average loss: 2.6242\n",
      "Iteration: 1630; Percent complete: 40.8%; Average loss: 3.0088\n",
      "Iteration: 1631; Percent complete: 40.8%; Average loss: 2.6854\n",
      "Iteration: 1632; Percent complete: 40.8%; Average loss: 2.9763\n",
      "Iteration: 1633; Percent complete: 40.8%; Average loss: 2.5942\n",
      "Iteration: 1634; Percent complete: 40.8%; Average loss: 2.6665\n",
      "Iteration: 1635; Percent complete: 40.9%; Average loss: 2.7657\n",
      "Iteration: 1636; Percent complete: 40.9%; Average loss: 3.1035\n",
      "Iteration: 1637; Percent complete: 40.9%; Average loss: 2.5443\n",
      "Iteration: 1638; Percent complete: 40.9%; Average loss: 2.8619\n",
      "Iteration: 1639; Percent complete: 41.0%; Average loss: 2.8052\n",
      "Iteration: 1640; Percent complete: 41.0%; Average loss: 2.8932\n",
      "Iteration: 1641; Percent complete: 41.0%; Average loss: 2.5707\n",
      "Iteration: 1642; Percent complete: 41.0%; Average loss: 2.7636\n",
      "Iteration: 1643; Percent complete: 41.1%; Average loss: 2.7414\n",
      "Iteration: 1644; Percent complete: 41.1%; Average loss: 2.8796\n",
      "Iteration: 1645; Percent complete: 41.1%; Average loss: 2.7663\n",
      "Iteration: 1646; Percent complete: 41.1%; Average loss: 2.6826\n",
      "Iteration: 1647; Percent complete: 41.2%; Average loss: 2.5888\n",
      "Iteration: 1648; Percent complete: 41.2%; Average loss: 2.7555\n",
      "Iteration: 1649; Percent complete: 41.2%; Average loss: 2.6144\n",
      "Iteration: 1650; Percent complete: 41.2%; Average loss: 2.6241\n",
      "Iteration: 1651; Percent complete: 41.3%; Average loss: 2.9912\n",
      "Iteration: 1652; Percent complete: 41.3%; Average loss: 2.7131\n",
      "Iteration: 1653; Percent complete: 41.3%; Average loss: 2.6069\n",
      "Iteration: 1654; Percent complete: 41.3%; Average loss: 2.4926\n",
      "Iteration: 1655; Percent complete: 41.4%; Average loss: 2.7276\n",
      "Iteration: 1656; Percent complete: 41.4%; Average loss: 2.7716\n",
      "Iteration: 1657; Percent complete: 41.4%; Average loss: 2.5583\n",
      "Iteration: 1658; Percent complete: 41.4%; Average loss: 2.6802\n",
      "Iteration: 1659; Percent complete: 41.5%; Average loss: 2.7340\n",
      "Iteration: 1660; Percent complete: 41.5%; Average loss: 2.6630\n",
      "Iteration: 1661; Percent complete: 41.5%; Average loss: 2.4582\n",
      "Iteration: 1662; Percent complete: 41.5%; Average loss: 2.9527\n",
      "Iteration: 1663; Percent complete: 41.6%; Average loss: 2.6659\n",
      "Iteration: 1664; Percent complete: 41.6%; Average loss: 2.5500\n",
      "Iteration: 1665; Percent complete: 41.6%; Average loss: 2.6412\n",
      "Iteration: 1666; Percent complete: 41.6%; Average loss: 2.7022\n",
      "Iteration: 1667; Percent complete: 41.7%; Average loss: 2.8873\n",
      "Iteration: 1668; Percent complete: 41.7%; Average loss: 2.8423\n",
      "Iteration: 1669; Percent complete: 41.7%; Average loss: 2.8741\n",
      "Iteration: 1670; Percent complete: 41.8%; Average loss: 2.8389\n",
      "Iteration: 1671; Percent complete: 41.8%; Average loss: 2.7137\n",
      "Iteration: 1672; Percent complete: 41.8%; Average loss: 2.9410\n",
      "Iteration: 1673; Percent complete: 41.8%; Average loss: 2.7182\n",
      "Iteration: 1674; Percent complete: 41.9%; Average loss: 2.6098\n",
      "Iteration: 1675; Percent complete: 41.9%; Average loss: 2.7833\n",
      "Iteration: 1676; Percent complete: 41.9%; Average loss: 2.8104\n",
      "Iteration: 1677; Percent complete: 41.9%; Average loss: 2.7714\n",
      "Iteration: 1678; Percent complete: 41.9%; Average loss: 2.7243\n",
      "Iteration: 1679; Percent complete: 42.0%; Average loss: 2.8161\n",
      "Iteration: 1680; Percent complete: 42.0%; Average loss: 2.7211\n",
      "Iteration: 1681; Percent complete: 42.0%; Average loss: 2.8101\n",
      "Iteration: 1682; Percent complete: 42.0%; Average loss: 2.6876\n",
      "Iteration: 1683; Percent complete: 42.1%; Average loss: 2.9034\n",
      "Iteration: 1684; Percent complete: 42.1%; Average loss: 2.9930\n",
      "Iteration: 1685; Percent complete: 42.1%; Average loss: 2.6352\n",
      "Iteration: 1686; Percent complete: 42.1%; Average loss: 2.7230\n",
      "Iteration: 1687; Percent complete: 42.2%; Average loss: 2.6177\n",
      "Iteration: 1688; Percent complete: 42.2%; Average loss: 2.7991\n",
      "Iteration: 1689; Percent complete: 42.2%; Average loss: 2.6370\n",
      "Iteration: 1690; Percent complete: 42.2%; Average loss: 2.5829\n",
      "Iteration: 1691; Percent complete: 42.3%; Average loss: 2.5447\n",
      "Iteration: 1692; Percent complete: 42.3%; Average loss: 2.7003\n",
      "Iteration: 1693; Percent complete: 42.3%; Average loss: 2.6905\n",
      "Iteration: 1694; Percent complete: 42.4%; Average loss: 2.8335\n",
      "Iteration: 1695; Percent complete: 42.4%; Average loss: 3.0885\n",
      "Iteration: 1696; Percent complete: 42.4%; Average loss: 2.8248\n",
      "Iteration: 1697; Percent complete: 42.4%; Average loss: 2.7621\n",
      "Iteration: 1698; Percent complete: 42.4%; Average loss: 2.5719\n",
      "Iteration: 1699; Percent complete: 42.5%; Average loss: 2.7563\n",
      "Iteration: 1700; Percent complete: 42.5%; Average loss: 2.8938\n",
      "Iteration: 1701; Percent complete: 42.5%; Average loss: 2.7041\n",
      "Iteration: 1702; Percent complete: 42.5%; Average loss: 2.8415\n",
      "Iteration: 1703; Percent complete: 42.6%; Average loss: 2.6374\n",
      "Iteration: 1704; Percent complete: 42.6%; Average loss: 2.8135\n",
      "Iteration: 1705; Percent complete: 42.6%; Average loss: 2.8978\n",
      "Iteration: 1706; Percent complete: 42.6%; Average loss: 2.8937\n",
      "Iteration: 1707; Percent complete: 42.7%; Average loss: 2.6583\n",
      "Iteration: 1708; Percent complete: 42.7%; Average loss: 2.8827\n",
      "Iteration: 1709; Percent complete: 42.7%; Average loss: 2.4989\n",
      "Iteration: 1710; Percent complete: 42.8%; Average loss: 2.6959\n",
      "Iteration: 1711; Percent complete: 42.8%; Average loss: 2.7443\n",
      "Iteration: 1712; Percent complete: 42.8%; Average loss: 2.6212\n",
      "Iteration: 1713; Percent complete: 42.8%; Average loss: 2.7649\n",
      "Iteration: 1714; Percent complete: 42.9%; Average loss: 2.5716\n",
      "Iteration: 1715; Percent complete: 42.9%; Average loss: 2.6289\n",
      "Iteration: 1716; Percent complete: 42.9%; Average loss: 2.5704\n",
      "Iteration: 1717; Percent complete: 42.9%; Average loss: 2.7245\n",
      "Iteration: 1718; Percent complete: 43.0%; Average loss: 2.9638\n",
      "Iteration: 1719; Percent complete: 43.0%; Average loss: 2.5958\n",
      "Iteration: 1720; Percent complete: 43.0%; Average loss: 2.6334\n",
      "Iteration: 1721; Percent complete: 43.0%; Average loss: 2.4939\n",
      "Iteration: 1722; Percent complete: 43.0%; Average loss: 2.5677\n",
      "Iteration: 1723; Percent complete: 43.1%; Average loss: 2.6133\n",
      "Iteration: 1724; Percent complete: 43.1%; Average loss: 2.8164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1725; Percent complete: 43.1%; Average loss: 2.6227\n",
      "Iteration: 1726; Percent complete: 43.1%; Average loss: 2.6840\n",
      "Iteration: 1727; Percent complete: 43.2%; Average loss: 2.8465\n",
      "Iteration: 1728; Percent complete: 43.2%; Average loss: 2.9543\n",
      "Iteration: 1729; Percent complete: 43.2%; Average loss: 2.6683\n",
      "Iteration: 1730; Percent complete: 43.2%; Average loss: 2.5747\n",
      "Iteration: 1731; Percent complete: 43.3%; Average loss: 2.6574\n",
      "Iteration: 1732; Percent complete: 43.3%; Average loss: 2.6659\n",
      "Iteration: 1733; Percent complete: 43.3%; Average loss: 2.7059\n",
      "Iteration: 1734; Percent complete: 43.4%; Average loss: 2.6482\n",
      "Iteration: 1735; Percent complete: 43.4%; Average loss: 2.7327\n",
      "Iteration: 1736; Percent complete: 43.4%; Average loss: 2.8921\n",
      "Iteration: 1737; Percent complete: 43.4%; Average loss: 2.6751\n",
      "Iteration: 1738; Percent complete: 43.5%; Average loss: 2.8008\n",
      "Iteration: 1739; Percent complete: 43.5%; Average loss: 2.9124\n",
      "Iteration: 1740; Percent complete: 43.5%; Average loss: 3.0117\n",
      "Iteration: 1741; Percent complete: 43.5%; Average loss: 2.5756\n",
      "Iteration: 1742; Percent complete: 43.5%; Average loss: 2.7003\n",
      "Iteration: 1743; Percent complete: 43.6%; Average loss: 2.7374\n",
      "Iteration: 1744; Percent complete: 43.6%; Average loss: 2.7296\n",
      "Iteration: 1745; Percent complete: 43.6%; Average loss: 2.6099\n",
      "Iteration: 1746; Percent complete: 43.6%; Average loss: 2.8034\n",
      "Iteration: 1747; Percent complete: 43.7%; Average loss: 2.8187\n",
      "Iteration: 1748; Percent complete: 43.7%; Average loss: 2.8589\n",
      "Iteration: 1749; Percent complete: 43.7%; Average loss: 2.8267\n",
      "Iteration: 1750; Percent complete: 43.8%; Average loss: 2.6824\n",
      "Iteration: 1751; Percent complete: 43.8%; Average loss: 2.8927\n",
      "Iteration: 1752; Percent complete: 43.8%; Average loss: 2.7174\n",
      "Iteration: 1753; Percent complete: 43.8%; Average loss: 2.9126\n",
      "Iteration: 1754; Percent complete: 43.9%; Average loss: 2.9942\n",
      "Iteration: 1755; Percent complete: 43.9%; Average loss: 2.9285\n",
      "Iteration: 1756; Percent complete: 43.9%; Average loss: 2.8572\n",
      "Iteration: 1757; Percent complete: 43.9%; Average loss: 2.6197\n",
      "Iteration: 1758; Percent complete: 44.0%; Average loss: 2.8738\n",
      "Iteration: 1759; Percent complete: 44.0%; Average loss: 2.7034\n",
      "Iteration: 1760; Percent complete: 44.0%; Average loss: 2.6296\n",
      "Iteration: 1761; Percent complete: 44.0%; Average loss: 2.6503\n",
      "Iteration: 1762; Percent complete: 44.0%; Average loss: 2.6867\n",
      "Iteration: 1763; Percent complete: 44.1%; Average loss: 2.7888\n",
      "Iteration: 1764; Percent complete: 44.1%; Average loss: 2.6662\n",
      "Iteration: 1765; Percent complete: 44.1%; Average loss: 2.8026\n",
      "Iteration: 1766; Percent complete: 44.1%; Average loss: 2.8779\n",
      "Iteration: 1767; Percent complete: 44.2%; Average loss: 2.6203\n",
      "Iteration: 1768; Percent complete: 44.2%; Average loss: 2.5774\n",
      "Iteration: 1769; Percent complete: 44.2%; Average loss: 2.6904\n",
      "Iteration: 1770; Percent complete: 44.2%; Average loss: 2.6294\n",
      "Iteration: 1771; Percent complete: 44.3%; Average loss: 2.8569\n",
      "Iteration: 1772; Percent complete: 44.3%; Average loss: 2.7928\n",
      "Iteration: 1773; Percent complete: 44.3%; Average loss: 2.8236\n",
      "Iteration: 1774; Percent complete: 44.4%; Average loss: 3.0336\n",
      "Iteration: 1775; Percent complete: 44.4%; Average loss: 2.7180\n",
      "Iteration: 1776; Percent complete: 44.4%; Average loss: 2.6362\n",
      "Iteration: 1777; Percent complete: 44.4%; Average loss: 2.5318\n",
      "Iteration: 1778; Percent complete: 44.5%; Average loss: 2.5376\n",
      "Iteration: 1779; Percent complete: 44.5%; Average loss: 2.6321\n",
      "Iteration: 1780; Percent complete: 44.5%; Average loss: 2.8175\n",
      "Iteration: 1781; Percent complete: 44.5%; Average loss: 2.6883\n",
      "Iteration: 1782; Percent complete: 44.5%; Average loss: 2.6612\n",
      "Iteration: 1783; Percent complete: 44.6%; Average loss: 2.8229\n",
      "Iteration: 1784; Percent complete: 44.6%; Average loss: 2.5076\n",
      "Iteration: 1785; Percent complete: 44.6%; Average loss: 2.6925\n",
      "Iteration: 1786; Percent complete: 44.6%; Average loss: 2.5475\n",
      "Iteration: 1787; Percent complete: 44.7%; Average loss: 2.4429\n",
      "Iteration: 1788; Percent complete: 44.7%; Average loss: 2.7021\n",
      "Iteration: 1789; Percent complete: 44.7%; Average loss: 2.5327\n",
      "Iteration: 1790; Percent complete: 44.8%; Average loss: 2.4810\n",
      "Iteration: 1791; Percent complete: 44.8%; Average loss: 2.5284\n",
      "Iteration: 1792; Percent complete: 44.8%; Average loss: 2.7677\n",
      "Iteration: 1793; Percent complete: 44.8%; Average loss: 2.7812\n",
      "Iteration: 1794; Percent complete: 44.9%; Average loss: 2.6494\n",
      "Iteration: 1795; Percent complete: 44.9%; Average loss: 2.6860\n",
      "Iteration: 1796; Percent complete: 44.9%; Average loss: 2.5762\n",
      "Iteration: 1797; Percent complete: 44.9%; Average loss: 2.8376\n",
      "Iteration: 1798; Percent complete: 45.0%; Average loss: 2.6732\n",
      "Iteration: 1799; Percent complete: 45.0%; Average loss: 2.9801\n",
      "Iteration: 1800; Percent complete: 45.0%; Average loss: 2.8145\n",
      "Iteration: 1801; Percent complete: 45.0%; Average loss: 2.5659\n",
      "Iteration: 1802; Percent complete: 45.1%; Average loss: 2.8075\n",
      "Iteration: 1803; Percent complete: 45.1%; Average loss: 2.5652\n",
      "Iteration: 1804; Percent complete: 45.1%; Average loss: 2.6427\n",
      "Iteration: 1805; Percent complete: 45.1%; Average loss: 2.7019\n",
      "Iteration: 1806; Percent complete: 45.1%; Average loss: 2.7211\n",
      "Iteration: 1807; Percent complete: 45.2%; Average loss: 2.9437\n",
      "Iteration: 1808; Percent complete: 45.2%; Average loss: 2.4378\n",
      "Iteration: 1809; Percent complete: 45.2%; Average loss: 2.9150\n",
      "Iteration: 1810; Percent complete: 45.2%; Average loss: 2.6792\n",
      "Iteration: 1811; Percent complete: 45.3%; Average loss: 2.6320\n",
      "Iteration: 1812; Percent complete: 45.3%; Average loss: 2.9347\n",
      "Iteration: 1813; Percent complete: 45.3%; Average loss: 2.7698\n",
      "Iteration: 1814; Percent complete: 45.4%; Average loss: 2.7169\n",
      "Iteration: 1815; Percent complete: 45.4%; Average loss: 2.6018\n",
      "Iteration: 1816; Percent complete: 45.4%; Average loss: 2.5428\n",
      "Iteration: 1817; Percent complete: 45.4%; Average loss: 2.7709\n",
      "Iteration: 1818; Percent complete: 45.5%; Average loss: 2.4615\n",
      "Iteration: 1819; Percent complete: 45.5%; Average loss: 2.8007\n",
      "Iteration: 1820; Percent complete: 45.5%; Average loss: 2.6257\n",
      "Iteration: 1821; Percent complete: 45.5%; Average loss: 2.7810\n",
      "Iteration: 1822; Percent complete: 45.6%; Average loss: 2.6471\n",
      "Iteration: 1823; Percent complete: 45.6%; Average loss: 2.7952\n",
      "Iteration: 1824; Percent complete: 45.6%; Average loss: 2.6968\n",
      "Iteration: 1825; Percent complete: 45.6%; Average loss: 2.7800\n",
      "Iteration: 1826; Percent complete: 45.6%; Average loss: 2.6533\n",
      "Iteration: 1827; Percent complete: 45.7%; Average loss: 2.5208\n",
      "Iteration: 1828; Percent complete: 45.7%; Average loss: 2.6662\n",
      "Iteration: 1829; Percent complete: 45.7%; Average loss: 2.4163\n",
      "Iteration: 1830; Percent complete: 45.8%; Average loss: 2.7986\n",
      "Iteration: 1831; Percent complete: 45.8%; Average loss: 2.7314\n",
      "Iteration: 1832; Percent complete: 45.8%; Average loss: 2.7073\n",
      "Iteration: 1833; Percent complete: 45.8%; Average loss: 2.7509\n",
      "Iteration: 1834; Percent complete: 45.9%; Average loss: 2.8078\n",
      "Iteration: 1835; Percent complete: 45.9%; Average loss: 2.7794\n",
      "Iteration: 1836; Percent complete: 45.9%; Average loss: 2.5185\n",
      "Iteration: 1837; Percent complete: 45.9%; Average loss: 2.4026\n",
      "Iteration: 1838; Percent complete: 46.0%; Average loss: 2.7880\n",
      "Iteration: 1839; Percent complete: 46.0%; Average loss: 2.6480\n",
      "Iteration: 1840; Percent complete: 46.0%; Average loss: 2.8472\n",
      "Iteration: 1841; Percent complete: 46.0%; Average loss: 2.5762\n",
      "Iteration: 1842; Percent complete: 46.1%; Average loss: 2.8485\n",
      "Iteration: 1843; Percent complete: 46.1%; Average loss: 2.7439\n",
      "Iteration: 1844; Percent complete: 46.1%; Average loss: 2.6798\n",
      "Iteration: 1845; Percent complete: 46.1%; Average loss: 2.4889\n",
      "Iteration: 1846; Percent complete: 46.2%; Average loss: 2.7053\n",
      "Iteration: 1847; Percent complete: 46.2%; Average loss: 2.7569\n",
      "Iteration: 1848; Percent complete: 46.2%; Average loss: 2.6275\n",
      "Iteration: 1849; Percent complete: 46.2%; Average loss: 2.5526\n",
      "Iteration: 1850; Percent complete: 46.2%; Average loss: 2.8581\n",
      "Iteration: 1851; Percent complete: 46.3%; Average loss: 2.5312\n",
      "Iteration: 1852; Percent complete: 46.3%; Average loss: 2.8731\n",
      "Iteration: 1853; Percent complete: 46.3%; Average loss: 2.7092\n",
      "Iteration: 1854; Percent complete: 46.4%; Average loss: 2.5304\n",
      "Iteration: 1855; Percent complete: 46.4%; Average loss: 2.6664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1856; Percent complete: 46.4%; Average loss: 2.6589\n",
      "Iteration: 1857; Percent complete: 46.4%; Average loss: 2.6855\n",
      "Iteration: 1858; Percent complete: 46.5%; Average loss: 2.7085\n",
      "Iteration: 1859; Percent complete: 46.5%; Average loss: 2.8050\n",
      "Iteration: 1860; Percent complete: 46.5%; Average loss: 2.5935\n",
      "Iteration: 1861; Percent complete: 46.5%; Average loss: 2.8424\n",
      "Iteration: 1862; Percent complete: 46.6%; Average loss: 2.3284\n",
      "Iteration: 1863; Percent complete: 46.6%; Average loss: 2.6462\n",
      "Iteration: 1864; Percent complete: 46.6%; Average loss: 2.6494\n",
      "Iteration: 1865; Percent complete: 46.6%; Average loss: 2.8861\n",
      "Iteration: 1866; Percent complete: 46.7%; Average loss: 2.6770\n",
      "Iteration: 1867; Percent complete: 46.7%; Average loss: 2.7457\n",
      "Iteration: 1868; Percent complete: 46.7%; Average loss: 2.7736\n",
      "Iteration: 1869; Percent complete: 46.7%; Average loss: 2.7143\n",
      "Iteration: 1870; Percent complete: 46.8%; Average loss: 2.6358\n",
      "Iteration: 1871; Percent complete: 46.8%; Average loss: 2.5321\n",
      "Iteration: 1872; Percent complete: 46.8%; Average loss: 2.6284\n",
      "Iteration: 1873; Percent complete: 46.8%; Average loss: 2.7728\n",
      "Iteration: 1874; Percent complete: 46.9%; Average loss: 2.5730\n",
      "Iteration: 1875; Percent complete: 46.9%; Average loss: 2.7564\n",
      "Iteration: 1876; Percent complete: 46.9%; Average loss: 2.8012\n",
      "Iteration: 1877; Percent complete: 46.9%; Average loss: 2.5658\n",
      "Iteration: 1878; Percent complete: 46.9%; Average loss: 2.4989\n",
      "Iteration: 1879; Percent complete: 47.0%; Average loss: 2.7726\n",
      "Iteration: 1880; Percent complete: 47.0%; Average loss: 2.6664\n",
      "Iteration: 1881; Percent complete: 47.0%; Average loss: 2.9558\n",
      "Iteration: 1882; Percent complete: 47.0%; Average loss: 2.8934\n",
      "Iteration: 1883; Percent complete: 47.1%; Average loss: 2.5593\n",
      "Iteration: 1884; Percent complete: 47.1%; Average loss: 2.6718\n",
      "Iteration: 1885; Percent complete: 47.1%; Average loss: 2.5299\n",
      "Iteration: 1886; Percent complete: 47.1%; Average loss: 2.6301\n",
      "Iteration: 1887; Percent complete: 47.2%; Average loss: 2.7973\n",
      "Iteration: 1888; Percent complete: 47.2%; Average loss: 2.7104\n",
      "Iteration: 1889; Percent complete: 47.2%; Average loss: 2.8405\n",
      "Iteration: 1890; Percent complete: 47.2%; Average loss: 2.6320\n",
      "Iteration: 1891; Percent complete: 47.3%; Average loss: 2.5630\n",
      "Iteration: 1892; Percent complete: 47.3%; Average loss: 2.9325\n",
      "Iteration: 1893; Percent complete: 47.3%; Average loss: 2.6720\n",
      "Iteration: 1894; Percent complete: 47.3%; Average loss: 2.6396\n",
      "Iteration: 1895; Percent complete: 47.4%; Average loss: 2.5318\n",
      "Iteration: 1896; Percent complete: 47.4%; Average loss: 2.6702\n",
      "Iteration: 1897; Percent complete: 47.4%; Average loss: 2.7822\n",
      "Iteration: 1898; Percent complete: 47.4%; Average loss: 2.6239\n",
      "Iteration: 1899; Percent complete: 47.5%; Average loss: 2.7940\n",
      "Iteration: 1900; Percent complete: 47.5%; Average loss: 2.8459\n",
      "Iteration: 1901; Percent complete: 47.5%; Average loss: 2.5926\n",
      "Iteration: 1902; Percent complete: 47.5%; Average loss: 2.6515\n",
      "Iteration: 1903; Percent complete: 47.6%; Average loss: 2.9012\n",
      "Iteration: 1904; Percent complete: 47.6%; Average loss: 2.4497\n",
      "Iteration: 1905; Percent complete: 47.6%; Average loss: 2.7119\n",
      "Iteration: 1906; Percent complete: 47.6%; Average loss: 2.4458\n",
      "Iteration: 1907; Percent complete: 47.7%; Average loss: 2.8508\n",
      "Iteration: 1908; Percent complete: 47.7%; Average loss: 2.6473\n",
      "Iteration: 1909; Percent complete: 47.7%; Average loss: 2.6684\n",
      "Iteration: 1910; Percent complete: 47.8%; Average loss: 2.9168\n",
      "Iteration: 1911; Percent complete: 47.8%; Average loss: 2.6033\n",
      "Iteration: 1912; Percent complete: 47.8%; Average loss: 2.5522\n",
      "Iteration: 1913; Percent complete: 47.8%; Average loss: 2.8361\n",
      "Iteration: 1914; Percent complete: 47.9%; Average loss: 2.6801\n",
      "Iteration: 1915; Percent complete: 47.9%; Average loss: 2.6710\n",
      "Iteration: 1916; Percent complete: 47.9%; Average loss: 2.6248\n",
      "Iteration: 1917; Percent complete: 47.9%; Average loss: 2.8251\n",
      "Iteration: 1918; Percent complete: 47.9%; Average loss: 2.7188\n",
      "Iteration: 1919; Percent complete: 48.0%; Average loss: 3.0136\n",
      "Iteration: 1920; Percent complete: 48.0%; Average loss: 2.6423\n",
      "Iteration: 1921; Percent complete: 48.0%; Average loss: 2.6394\n",
      "Iteration: 1922; Percent complete: 48.0%; Average loss: 2.8144\n",
      "Iteration: 1923; Percent complete: 48.1%; Average loss: 2.5029\n",
      "Iteration: 1924; Percent complete: 48.1%; Average loss: 2.7473\n",
      "Iteration: 1925; Percent complete: 48.1%; Average loss: 2.7947\n",
      "Iteration: 1926; Percent complete: 48.1%; Average loss: 2.7350\n",
      "Iteration: 1927; Percent complete: 48.2%; Average loss: 2.4837\n",
      "Iteration: 1928; Percent complete: 48.2%; Average loss: 2.6443\n",
      "Iteration: 1929; Percent complete: 48.2%; Average loss: 2.6531\n",
      "Iteration: 1930; Percent complete: 48.2%; Average loss: 2.5420\n",
      "Iteration: 1931; Percent complete: 48.3%; Average loss: 2.6855\n",
      "Iteration: 1932; Percent complete: 48.3%; Average loss: 2.5681\n",
      "Iteration: 1933; Percent complete: 48.3%; Average loss: 2.8165\n",
      "Iteration: 1934; Percent complete: 48.4%; Average loss: 2.6764\n",
      "Iteration: 1935; Percent complete: 48.4%; Average loss: 2.5719\n",
      "Iteration: 1936; Percent complete: 48.4%; Average loss: 2.5942\n",
      "Iteration: 1937; Percent complete: 48.4%; Average loss: 2.6366\n",
      "Iteration: 1938; Percent complete: 48.4%; Average loss: 2.6189\n",
      "Iteration: 1939; Percent complete: 48.5%; Average loss: 2.6144\n",
      "Iteration: 1940; Percent complete: 48.5%; Average loss: 2.8866\n",
      "Iteration: 1941; Percent complete: 48.5%; Average loss: 2.8188\n",
      "Iteration: 1942; Percent complete: 48.5%; Average loss: 2.6435\n",
      "Iteration: 1943; Percent complete: 48.6%; Average loss: 2.5957\n",
      "Iteration: 1944; Percent complete: 48.6%; Average loss: 2.6581\n",
      "Iteration: 1945; Percent complete: 48.6%; Average loss: 2.6092\n",
      "Iteration: 1946; Percent complete: 48.6%; Average loss: 2.6707\n",
      "Iteration: 1947; Percent complete: 48.7%; Average loss: 2.5752\n",
      "Iteration: 1948; Percent complete: 48.7%; Average loss: 2.5942\n",
      "Iteration: 1949; Percent complete: 48.7%; Average loss: 2.9165\n",
      "Iteration: 1950; Percent complete: 48.8%; Average loss: 2.6576\n",
      "Iteration: 1951; Percent complete: 48.8%; Average loss: 2.6154\n",
      "Iteration: 1952; Percent complete: 48.8%; Average loss: 2.5559\n",
      "Iteration: 1953; Percent complete: 48.8%; Average loss: 2.8584\n",
      "Iteration: 1954; Percent complete: 48.9%; Average loss: 2.6588\n",
      "Iteration: 1955; Percent complete: 48.9%; Average loss: 2.5152\n",
      "Iteration: 1956; Percent complete: 48.9%; Average loss: 2.9127\n",
      "Iteration: 1957; Percent complete: 48.9%; Average loss: 2.4473\n",
      "Iteration: 1958; Percent complete: 48.9%; Average loss: 2.7340\n",
      "Iteration: 1959; Percent complete: 49.0%; Average loss: 2.3473\n",
      "Iteration: 1960; Percent complete: 49.0%; Average loss: 2.6814\n",
      "Iteration: 1961; Percent complete: 49.0%; Average loss: 2.5656\n",
      "Iteration: 1962; Percent complete: 49.0%; Average loss: 2.6555\n",
      "Iteration: 1963; Percent complete: 49.1%; Average loss: 2.4538\n",
      "Iteration: 1964; Percent complete: 49.1%; Average loss: 2.6342\n",
      "Iteration: 1965; Percent complete: 49.1%; Average loss: 2.4339\n",
      "Iteration: 1966; Percent complete: 49.1%; Average loss: 2.4463\n",
      "Iteration: 1967; Percent complete: 49.2%; Average loss: 2.8971\n",
      "Iteration: 1968; Percent complete: 49.2%; Average loss: 2.5408\n",
      "Iteration: 1969; Percent complete: 49.2%; Average loss: 2.9511\n",
      "Iteration: 1970; Percent complete: 49.2%; Average loss: 2.8051\n",
      "Iteration: 1971; Percent complete: 49.3%; Average loss: 2.6490\n",
      "Iteration: 1972; Percent complete: 49.3%; Average loss: 2.8297\n",
      "Iteration: 1973; Percent complete: 49.3%; Average loss: 2.7346\n",
      "Iteration: 1974; Percent complete: 49.4%; Average loss: 2.5903\n",
      "Iteration: 1975; Percent complete: 49.4%; Average loss: 2.5473\n",
      "Iteration: 1976; Percent complete: 49.4%; Average loss: 2.5280\n",
      "Iteration: 1977; Percent complete: 49.4%; Average loss: 2.5779\n",
      "Iteration: 1978; Percent complete: 49.5%; Average loss: 2.6431\n",
      "Iteration: 1979; Percent complete: 49.5%; Average loss: 2.5678\n",
      "Iteration: 1980; Percent complete: 49.5%; Average loss: 2.5770\n",
      "Iteration: 1981; Percent complete: 49.5%; Average loss: 2.6698\n",
      "Iteration: 1982; Percent complete: 49.5%; Average loss: 2.6070\n",
      "Iteration: 1983; Percent complete: 49.6%; Average loss: 2.6515\n",
      "Iteration: 1984; Percent complete: 49.6%; Average loss: 2.7752\n",
      "Iteration: 1985; Percent complete: 49.6%; Average loss: 2.4924\n",
      "Iteration: 1986; Percent complete: 49.6%; Average loss: 2.6188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1987; Percent complete: 49.7%; Average loss: 2.6850\n",
      "Iteration: 1988; Percent complete: 49.7%; Average loss: 2.6242\n",
      "Iteration: 1989; Percent complete: 49.7%; Average loss: 2.5658\n",
      "Iteration: 1990; Percent complete: 49.8%; Average loss: 2.6230\n",
      "Iteration: 1991; Percent complete: 49.8%; Average loss: 2.6374\n",
      "Iteration: 1992; Percent complete: 49.8%; Average loss: 2.7831\n",
      "Iteration: 1993; Percent complete: 49.8%; Average loss: 2.6113\n",
      "Iteration: 1994; Percent complete: 49.9%; Average loss: 2.9125\n",
      "Iteration: 1995; Percent complete: 49.9%; Average loss: 2.8054\n",
      "Iteration: 1996; Percent complete: 49.9%; Average loss: 2.6805\n",
      "Iteration: 1997; Percent complete: 49.9%; Average loss: 2.7406\n",
      "Iteration: 1998; Percent complete: 50.0%; Average loss: 2.6885\n",
      "Iteration: 1999; Percent complete: 50.0%; Average loss: 2.7061\n",
      "Iteration: 2000; Percent complete: 50.0%; Average loss: 2.6558\n",
      "Iteration: 2001; Percent complete: 50.0%; Average loss: 2.5165\n",
      "Iteration: 2002; Percent complete: 50.0%; Average loss: 2.8031\n",
      "Iteration: 2003; Percent complete: 50.1%; Average loss: 2.6241\n",
      "Iteration: 2004; Percent complete: 50.1%; Average loss: 2.5763\n",
      "Iteration: 2005; Percent complete: 50.1%; Average loss: 2.5562\n",
      "Iteration: 2006; Percent complete: 50.1%; Average loss: 2.8444\n",
      "Iteration: 2007; Percent complete: 50.2%; Average loss: 2.4706\n",
      "Iteration: 2008; Percent complete: 50.2%; Average loss: 2.6747\n",
      "Iteration: 2009; Percent complete: 50.2%; Average loss: 2.7004\n",
      "Iteration: 2010; Percent complete: 50.2%; Average loss: 2.6092\n",
      "Iteration: 2011; Percent complete: 50.3%; Average loss: 2.8218\n",
      "Iteration: 2012; Percent complete: 50.3%; Average loss: 2.4427\n",
      "Iteration: 2013; Percent complete: 50.3%; Average loss: 2.6044\n",
      "Iteration: 2014; Percent complete: 50.3%; Average loss: 2.4253\n",
      "Iteration: 2015; Percent complete: 50.4%; Average loss: 2.5853\n",
      "Iteration: 2016; Percent complete: 50.4%; Average loss: 2.7259\n",
      "Iteration: 2017; Percent complete: 50.4%; Average loss: 2.6518\n",
      "Iteration: 2018; Percent complete: 50.4%; Average loss: 2.6952\n",
      "Iteration: 2019; Percent complete: 50.5%; Average loss: 2.6679\n",
      "Iteration: 2020; Percent complete: 50.5%; Average loss: 2.7096\n",
      "Iteration: 2021; Percent complete: 50.5%; Average loss: 2.6273\n",
      "Iteration: 2022; Percent complete: 50.5%; Average loss: 2.6408\n",
      "Iteration: 2023; Percent complete: 50.6%; Average loss: 2.6036\n",
      "Iteration: 2024; Percent complete: 50.6%; Average loss: 2.4369\n",
      "Iteration: 2025; Percent complete: 50.6%; Average loss: 2.7144\n",
      "Iteration: 2026; Percent complete: 50.6%; Average loss: 2.3456\n",
      "Iteration: 2027; Percent complete: 50.7%; Average loss: 2.5076\n",
      "Iteration: 2028; Percent complete: 50.7%; Average loss: 2.3244\n",
      "Iteration: 2029; Percent complete: 50.7%; Average loss: 2.6676\n",
      "Iteration: 2030; Percent complete: 50.7%; Average loss: 2.4990\n",
      "Iteration: 2031; Percent complete: 50.8%; Average loss: 2.5829\n",
      "Iteration: 2032; Percent complete: 50.8%; Average loss: 2.4527\n",
      "Iteration: 2033; Percent complete: 50.8%; Average loss: 2.6291\n",
      "Iteration: 2034; Percent complete: 50.8%; Average loss: 2.6014\n",
      "Iteration: 2035; Percent complete: 50.9%; Average loss: 2.4834\n",
      "Iteration: 2036; Percent complete: 50.9%; Average loss: 2.4860\n",
      "Iteration: 2037; Percent complete: 50.9%; Average loss: 2.6158\n",
      "Iteration: 2038; Percent complete: 50.9%; Average loss: 2.7424\n",
      "Iteration: 2039; Percent complete: 51.0%; Average loss: 2.5159\n",
      "Iteration: 2040; Percent complete: 51.0%; Average loss: 2.6802\n",
      "Iteration: 2041; Percent complete: 51.0%; Average loss: 2.6016\n",
      "Iteration: 2042; Percent complete: 51.0%; Average loss: 2.5290\n",
      "Iteration: 2043; Percent complete: 51.1%; Average loss: 2.5737\n",
      "Iteration: 2044; Percent complete: 51.1%; Average loss: 2.6327\n",
      "Iteration: 2045; Percent complete: 51.1%; Average loss: 2.9428\n",
      "Iteration: 2046; Percent complete: 51.1%; Average loss: 2.6141\n",
      "Iteration: 2047; Percent complete: 51.2%; Average loss: 2.5692\n",
      "Iteration: 2048; Percent complete: 51.2%; Average loss: 2.4403\n",
      "Iteration: 2049; Percent complete: 51.2%; Average loss: 2.7809\n",
      "Iteration: 2050; Percent complete: 51.2%; Average loss: 2.4362\n",
      "Iteration: 2051; Percent complete: 51.3%; Average loss: 2.8570\n",
      "Iteration: 2052; Percent complete: 51.3%; Average loss: 2.5518\n",
      "Iteration: 2053; Percent complete: 51.3%; Average loss: 2.4093\n",
      "Iteration: 2054; Percent complete: 51.3%; Average loss: 2.5814\n",
      "Iteration: 2055; Percent complete: 51.4%; Average loss: 2.6449\n",
      "Iteration: 2056; Percent complete: 51.4%; Average loss: 2.4448\n",
      "Iteration: 2057; Percent complete: 51.4%; Average loss: 2.4262\n",
      "Iteration: 2058; Percent complete: 51.4%; Average loss: 2.5251\n",
      "Iteration: 2059; Percent complete: 51.5%; Average loss: 2.6264\n",
      "Iteration: 2060; Percent complete: 51.5%; Average loss: 2.7000\n",
      "Iteration: 2061; Percent complete: 51.5%; Average loss: 2.5710\n",
      "Iteration: 2062; Percent complete: 51.5%; Average loss: 2.8274\n",
      "Iteration: 2063; Percent complete: 51.6%; Average loss: 2.4626\n",
      "Iteration: 2064; Percent complete: 51.6%; Average loss: 2.4799\n",
      "Iteration: 2065; Percent complete: 51.6%; Average loss: 2.6334\n",
      "Iteration: 2066; Percent complete: 51.6%; Average loss: 2.4744\n",
      "Iteration: 2067; Percent complete: 51.7%; Average loss: 2.5876\n",
      "Iteration: 2068; Percent complete: 51.7%; Average loss: 2.4217\n",
      "Iteration: 2069; Percent complete: 51.7%; Average loss: 2.8533\n",
      "Iteration: 2070; Percent complete: 51.7%; Average loss: 2.4030\n",
      "Iteration: 2071; Percent complete: 51.8%; Average loss: 2.6064\n",
      "Iteration: 2072; Percent complete: 51.8%; Average loss: 2.8483\n",
      "Iteration: 2073; Percent complete: 51.8%; Average loss: 2.6117\n",
      "Iteration: 2074; Percent complete: 51.8%; Average loss: 2.4983\n",
      "Iteration: 2075; Percent complete: 51.9%; Average loss: 2.6483\n",
      "Iteration: 2076; Percent complete: 51.9%; Average loss: 2.5262\n",
      "Iteration: 2077; Percent complete: 51.9%; Average loss: 2.6333\n",
      "Iteration: 2078; Percent complete: 51.9%; Average loss: 2.5428\n",
      "Iteration: 2079; Percent complete: 52.0%; Average loss: 2.3594\n",
      "Iteration: 2080; Percent complete: 52.0%; Average loss: 2.8509\n",
      "Iteration: 2081; Percent complete: 52.0%; Average loss: 2.5591\n",
      "Iteration: 2082; Percent complete: 52.0%; Average loss: 2.6730\n",
      "Iteration: 2083; Percent complete: 52.1%; Average loss: 2.5737\n",
      "Iteration: 2084; Percent complete: 52.1%; Average loss: 2.4891\n",
      "Iteration: 2085; Percent complete: 52.1%; Average loss: 2.7770\n",
      "Iteration: 2086; Percent complete: 52.1%; Average loss: 2.7563\n",
      "Iteration: 2087; Percent complete: 52.2%; Average loss: 2.4903\n",
      "Iteration: 2088; Percent complete: 52.2%; Average loss: 2.5678\n",
      "Iteration: 2089; Percent complete: 52.2%; Average loss: 2.6985\n",
      "Iteration: 2090; Percent complete: 52.2%; Average loss: 2.5864\n",
      "Iteration: 2091; Percent complete: 52.3%; Average loss: 2.6205\n",
      "Iteration: 2092; Percent complete: 52.3%; Average loss: 2.6306\n",
      "Iteration: 2093; Percent complete: 52.3%; Average loss: 2.6716\n",
      "Iteration: 2094; Percent complete: 52.3%; Average loss: 2.6044\n",
      "Iteration: 2095; Percent complete: 52.4%; Average loss: 2.5339\n",
      "Iteration: 2096; Percent complete: 52.4%; Average loss: 2.8575\n",
      "Iteration: 2097; Percent complete: 52.4%; Average loss: 2.7239\n",
      "Iteration: 2098; Percent complete: 52.4%; Average loss: 2.6072\n",
      "Iteration: 2099; Percent complete: 52.5%; Average loss: 2.6259\n",
      "Iteration: 2100; Percent complete: 52.5%; Average loss: 2.7144\n",
      "Iteration: 2101; Percent complete: 52.5%; Average loss: 2.5626\n",
      "Iteration: 2102; Percent complete: 52.5%; Average loss: 2.6273\n",
      "Iteration: 2103; Percent complete: 52.6%; Average loss: 2.6776\n",
      "Iteration: 2104; Percent complete: 52.6%; Average loss: 2.5946\n",
      "Iteration: 2105; Percent complete: 52.6%; Average loss: 2.8359\n",
      "Iteration: 2106; Percent complete: 52.6%; Average loss: 2.5934\n",
      "Iteration: 2107; Percent complete: 52.7%; Average loss: 2.6039\n",
      "Iteration: 2108; Percent complete: 52.7%; Average loss: 2.4165\n",
      "Iteration: 2109; Percent complete: 52.7%; Average loss: 2.7060\n",
      "Iteration: 2110; Percent complete: 52.8%; Average loss: 2.8189\n",
      "Iteration: 2111; Percent complete: 52.8%; Average loss: 2.4595\n",
      "Iteration: 2112; Percent complete: 52.8%; Average loss: 2.8360\n",
      "Iteration: 2113; Percent complete: 52.8%; Average loss: 2.7262\n",
      "Iteration: 2114; Percent complete: 52.8%; Average loss: 2.6369\n",
      "Iteration: 2115; Percent complete: 52.9%; Average loss: 2.5889\n",
      "Iteration: 2116; Percent complete: 52.9%; Average loss: 2.8957\n",
      "Iteration: 2117; Percent complete: 52.9%; Average loss: 2.5452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2118; Percent complete: 52.9%; Average loss: 2.5768\n",
      "Iteration: 2119; Percent complete: 53.0%; Average loss: 2.6955\n",
      "Iteration: 2120; Percent complete: 53.0%; Average loss: 2.7813\n",
      "Iteration: 2121; Percent complete: 53.0%; Average loss: 2.5019\n",
      "Iteration: 2122; Percent complete: 53.0%; Average loss: 2.8460\n",
      "Iteration: 2123; Percent complete: 53.1%; Average loss: 2.3662\n",
      "Iteration: 2124; Percent complete: 53.1%; Average loss: 2.6954\n",
      "Iteration: 2125; Percent complete: 53.1%; Average loss: 2.6144\n",
      "Iteration: 2126; Percent complete: 53.1%; Average loss: 2.6765\n",
      "Iteration: 2127; Percent complete: 53.2%; Average loss: 2.8669\n",
      "Iteration: 2128; Percent complete: 53.2%; Average loss: 2.4526\n",
      "Iteration: 2129; Percent complete: 53.2%; Average loss: 2.2271\n",
      "Iteration: 2130; Percent complete: 53.2%; Average loss: 2.6612\n",
      "Iteration: 2131; Percent complete: 53.3%; Average loss: 2.4634\n",
      "Iteration: 2132; Percent complete: 53.3%; Average loss: 2.4363\n",
      "Iteration: 2133; Percent complete: 53.3%; Average loss: 2.6660\n",
      "Iteration: 2134; Percent complete: 53.3%; Average loss: 2.4671\n",
      "Iteration: 2135; Percent complete: 53.4%; Average loss: 2.5594\n",
      "Iteration: 2136; Percent complete: 53.4%; Average loss: 2.6718\n",
      "Iteration: 2137; Percent complete: 53.4%; Average loss: 2.7536\n",
      "Iteration: 2138; Percent complete: 53.4%; Average loss: 2.6688\n",
      "Iteration: 2139; Percent complete: 53.5%; Average loss: 2.4966\n",
      "Iteration: 2140; Percent complete: 53.5%; Average loss: 2.7072\n",
      "Iteration: 2141; Percent complete: 53.5%; Average loss: 2.4719\n",
      "Iteration: 2142; Percent complete: 53.5%; Average loss: 2.6501\n",
      "Iteration: 2143; Percent complete: 53.6%; Average loss: 2.8087\n",
      "Iteration: 2144; Percent complete: 53.6%; Average loss: 2.6560\n",
      "Iteration: 2145; Percent complete: 53.6%; Average loss: 2.6036\n",
      "Iteration: 2146; Percent complete: 53.6%; Average loss: 2.6124\n",
      "Iteration: 2147; Percent complete: 53.7%; Average loss: 2.5541\n",
      "Iteration: 2148; Percent complete: 53.7%; Average loss: 2.5769\n",
      "Iteration: 2149; Percent complete: 53.7%; Average loss: 2.6304\n",
      "Iteration: 2150; Percent complete: 53.8%; Average loss: 2.6281\n",
      "Iteration: 2151; Percent complete: 53.8%; Average loss: 2.6916\n",
      "Iteration: 2152; Percent complete: 53.8%; Average loss: 2.7612\n",
      "Iteration: 2153; Percent complete: 53.8%; Average loss: 2.3674\n",
      "Iteration: 2154; Percent complete: 53.8%; Average loss: 2.7375\n",
      "Iteration: 2155; Percent complete: 53.9%; Average loss: 2.3231\n",
      "Iteration: 2156; Percent complete: 53.9%; Average loss: 2.5824\n",
      "Iteration: 2157; Percent complete: 53.9%; Average loss: 2.8202\n",
      "Iteration: 2158; Percent complete: 53.9%; Average loss: 2.4586\n",
      "Iteration: 2159; Percent complete: 54.0%; Average loss: 2.5314\n",
      "Iteration: 2160; Percent complete: 54.0%; Average loss: 2.7645\n",
      "Iteration: 2161; Percent complete: 54.0%; Average loss: 3.0900\n",
      "Iteration: 2162; Percent complete: 54.0%; Average loss: 2.6512\n",
      "Iteration: 2163; Percent complete: 54.1%; Average loss: 2.5637\n",
      "Iteration: 2164; Percent complete: 54.1%; Average loss: 2.6978\n",
      "Iteration: 2165; Percent complete: 54.1%; Average loss: 2.5801\n",
      "Iteration: 2166; Percent complete: 54.1%; Average loss: 2.5692\n",
      "Iteration: 2167; Percent complete: 54.2%; Average loss: 2.8950\n",
      "Iteration: 2168; Percent complete: 54.2%; Average loss: 2.6919\n",
      "Iteration: 2169; Percent complete: 54.2%; Average loss: 2.5494\n",
      "Iteration: 2170; Percent complete: 54.2%; Average loss: 2.4997\n",
      "Iteration: 2171; Percent complete: 54.3%; Average loss: 2.6906\n",
      "Iteration: 2172; Percent complete: 54.3%; Average loss: 2.8614\n",
      "Iteration: 2173; Percent complete: 54.3%; Average loss: 2.4558\n",
      "Iteration: 2174; Percent complete: 54.4%; Average loss: 2.6656\n",
      "Iteration: 2175; Percent complete: 54.4%; Average loss: 2.5606\n",
      "Iteration: 2176; Percent complete: 54.4%; Average loss: 2.5890\n",
      "Iteration: 2177; Percent complete: 54.4%; Average loss: 2.7064\n",
      "Iteration: 2178; Percent complete: 54.4%; Average loss: 2.5395\n",
      "Iteration: 2179; Percent complete: 54.5%; Average loss: 2.9353\n",
      "Iteration: 2180; Percent complete: 54.5%; Average loss: 2.5394\n",
      "Iteration: 2181; Percent complete: 54.5%; Average loss: 2.4512\n",
      "Iteration: 2182; Percent complete: 54.5%; Average loss: 2.3223\n",
      "Iteration: 2183; Percent complete: 54.6%; Average loss: 2.5262\n",
      "Iteration: 2184; Percent complete: 54.6%; Average loss: 2.3918\n",
      "Iteration: 2185; Percent complete: 54.6%; Average loss: 2.6925\n",
      "Iteration: 2186; Percent complete: 54.6%; Average loss: 2.6863\n",
      "Iteration: 2187; Percent complete: 54.7%; Average loss: 2.5594\n",
      "Iteration: 2188; Percent complete: 54.7%; Average loss: 2.7181\n",
      "Iteration: 2189; Percent complete: 54.7%; Average loss: 2.4903\n",
      "Iteration: 2190; Percent complete: 54.8%; Average loss: 2.4896\n",
      "Iteration: 2191; Percent complete: 54.8%; Average loss: 2.6898\n",
      "Iteration: 2192; Percent complete: 54.8%; Average loss: 2.7540\n",
      "Iteration: 2193; Percent complete: 54.8%; Average loss: 2.5329\n",
      "Iteration: 2194; Percent complete: 54.9%; Average loss: 2.6180\n",
      "Iteration: 2195; Percent complete: 54.9%; Average loss: 2.7341\n",
      "Iteration: 2196; Percent complete: 54.9%; Average loss: 2.6143\n",
      "Iteration: 2197; Percent complete: 54.9%; Average loss: 2.5107\n",
      "Iteration: 2198; Percent complete: 54.9%; Average loss: 2.7038\n",
      "Iteration: 2199; Percent complete: 55.0%; Average loss: 2.4610\n",
      "Iteration: 2200; Percent complete: 55.0%; Average loss: 2.6034\n",
      "Iteration: 2201; Percent complete: 55.0%; Average loss: 2.4730\n",
      "Iteration: 2202; Percent complete: 55.0%; Average loss: 2.7613\n",
      "Iteration: 2203; Percent complete: 55.1%; Average loss: 2.5214\n",
      "Iteration: 2204; Percent complete: 55.1%; Average loss: 2.8039\n",
      "Iteration: 2205; Percent complete: 55.1%; Average loss: 2.7329\n",
      "Iteration: 2206; Percent complete: 55.1%; Average loss: 2.6104\n",
      "Iteration: 2207; Percent complete: 55.2%; Average loss: 2.4781\n",
      "Iteration: 2208; Percent complete: 55.2%; Average loss: 2.5600\n",
      "Iteration: 2209; Percent complete: 55.2%; Average loss: 2.7727\n",
      "Iteration: 2210; Percent complete: 55.2%; Average loss: 2.4977\n",
      "Iteration: 2211; Percent complete: 55.3%; Average loss: 2.5626\n",
      "Iteration: 2212; Percent complete: 55.3%; Average loss: 2.6614\n",
      "Iteration: 2213; Percent complete: 55.3%; Average loss: 2.5808\n",
      "Iteration: 2214; Percent complete: 55.4%; Average loss: 2.6177\n",
      "Iteration: 2215; Percent complete: 55.4%; Average loss: 2.4596\n",
      "Iteration: 2216; Percent complete: 55.4%; Average loss: 2.6617\n",
      "Iteration: 2217; Percent complete: 55.4%; Average loss: 2.6773\n",
      "Iteration: 2218; Percent complete: 55.5%; Average loss: 2.3833\n",
      "Iteration: 2219; Percent complete: 55.5%; Average loss: 2.6849\n",
      "Iteration: 2220; Percent complete: 55.5%; Average loss: 2.6185\n",
      "Iteration: 2221; Percent complete: 55.5%; Average loss: 2.5062\n",
      "Iteration: 2222; Percent complete: 55.5%; Average loss: 2.6092\n",
      "Iteration: 2223; Percent complete: 55.6%; Average loss: 2.3808\n",
      "Iteration: 2224; Percent complete: 55.6%; Average loss: 2.6459\n",
      "Iteration: 2225; Percent complete: 55.6%; Average loss: 2.5663\n",
      "Iteration: 2226; Percent complete: 55.6%; Average loss: 2.6329\n",
      "Iteration: 2227; Percent complete: 55.7%; Average loss: 2.6739\n",
      "Iteration: 2228; Percent complete: 55.7%; Average loss: 2.5032\n",
      "Iteration: 2229; Percent complete: 55.7%; Average loss: 2.6322\n",
      "Iteration: 2230; Percent complete: 55.8%; Average loss: 2.7188\n",
      "Iteration: 2231; Percent complete: 55.8%; Average loss: 2.4789\n",
      "Iteration: 2232; Percent complete: 55.8%; Average loss: 2.3403\n",
      "Iteration: 2233; Percent complete: 55.8%; Average loss: 2.4367\n",
      "Iteration: 2234; Percent complete: 55.9%; Average loss: 2.8286\n",
      "Iteration: 2235; Percent complete: 55.9%; Average loss: 2.5194\n",
      "Iteration: 2236; Percent complete: 55.9%; Average loss: 2.4701\n",
      "Iteration: 2237; Percent complete: 55.9%; Average loss: 2.4337\n",
      "Iteration: 2238; Percent complete: 56.0%; Average loss: 2.6469\n",
      "Iteration: 2239; Percent complete: 56.0%; Average loss: 2.4743\n",
      "Iteration: 2240; Percent complete: 56.0%; Average loss: 2.6535\n",
      "Iteration: 2241; Percent complete: 56.0%; Average loss: 2.5716\n",
      "Iteration: 2242; Percent complete: 56.0%; Average loss: 2.5037\n",
      "Iteration: 2243; Percent complete: 56.1%; Average loss: 2.4211\n",
      "Iteration: 2244; Percent complete: 56.1%; Average loss: 2.7171\n",
      "Iteration: 2245; Percent complete: 56.1%; Average loss: 2.6785\n",
      "Iteration: 2246; Percent complete: 56.1%; Average loss: 2.6730\n",
      "Iteration: 2247; Percent complete: 56.2%; Average loss: 2.4722\n",
      "Iteration: 2248; Percent complete: 56.2%; Average loss: 2.7088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2249; Percent complete: 56.2%; Average loss: 2.7206\n",
      "Iteration: 2250; Percent complete: 56.2%; Average loss: 2.7334\n",
      "Iteration: 2251; Percent complete: 56.3%; Average loss: 2.5065\n",
      "Iteration: 2252; Percent complete: 56.3%; Average loss: 2.7075\n",
      "Iteration: 2253; Percent complete: 56.3%; Average loss: 2.5620\n",
      "Iteration: 2254; Percent complete: 56.4%; Average loss: 2.7513\n",
      "Iteration: 2255; Percent complete: 56.4%; Average loss: 2.7542\n",
      "Iteration: 2256; Percent complete: 56.4%; Average loss: 2.5059\n",
      "Iteration: 2257; Percent complete: 56.4%; Average loss: 2.4948\n",
      "Iteration: 2258; Percent complete: 56.5%; Average loss: 2.6864\n",
      "Iteration: 2259; Percent complete: 56.5%; Average loss: 2.3271\n",
      "Iteration: 2260; Percent complete: 56.5%; Average loss: 2.6772\n",
      "Iteration: 2261; Percent complete: 56.5%; Average loss: 2.3717\n",
      "Iteration: 2262; Percent complete: 56.5%; Average loss: 2.3618\n",
      "Iteration: 2263; Percent complete: 56.6%; Average loss: 2.2986\n",
      "Iteration: 2264; Percent complete: 56.6%; Average loss: 2.7055\n",
      "Iteration: 2265; Percent complete: 56.6%; Average loss: 2.6185\n",
      "Iteration: 2266; Percent complete: 56.6%; Average loss: 2.4818\n",
      "Iteration: 2267; Percent complete: 56.7%; Average loss: 2.5746\n",
      "Iteration: 2268; Percent complete: 56.7%; Average loss: 2.6344\n",
      "Iteration: 2269; Percent complete: 56.7%; Average loss: 2.4900\n",
      "Iteration: 2270; Percent complete: 56.8%; Average loss: 2.5713\n",
      "Iteration: 2271; Percent complete: 56.8%; Average loss: 2.4673\n",
      "Iteration: 2272; Percent complete: 56.8%; Average loss: 2.7139\n",
      "Iteration: 2273; Percent complete: 56.8%; Average loss: 2.5629\n",
      "Iteration: 2274; Percent complete: 56.9%; Average loss: 2.7535\n",
      "Iteration: 2275; Percent complete: 56.9%; Average loss: 2.8051\n",
      "Iteration: 2276; Percent complete: 56.9%; Average loss: 2.4982\n",
      "Iteration: 2277; Percent complete: 56.9%; Average loss: 2.4602\n",
      "Iteration: 2278; Percent complete: 57.0%; Average loss: 2.5151\n",
      "Iteration: 2279; Percent complete: 57.0%; Average loss: 2.6614\n",
      "Iteration: 2280; Percent complete: 57.0%; Average loss: 2.5228\n",
      "Iteration: 2281; Percent complete: 57.0%; Average loss: 2.2790\n",
      "Iteration: 2282; Percent complete: 57.0%; Average loss: 2.5231\n",
      "Iteration: 2283; Percent complete: 57.1%; Average loss: 2.5623\n",
      "Iteration: 2284; Percent complete: 57.1%; Average loss: 2.6347\n",
      "Iteration: 2285; Percent complete: 57.1%; Average loss: 2.5470\n",
      "Iteration: 2286; Percent complete: 57.1%; Average loss: 2.7378\n",
      "Iteration: 2287; Percent complete: 57.2%; Average loss: 2.6455\n",
      "Iteration: 2288; Percent complete: 57.2%; Average loss: 2.6011\n",
      "Iteration: 2289; Percent complete: 57.2%; Average loss: 2.5244\n",
      "Iteration: 2290; Percent complete: 57.2%; Average loss: 2.4320\n",
      "Iteration: 2291; Percent complete: 57.3%; Average loss: 2.5661\n",
      "Iteration: 2292; Percent complete: 57.3%; Average loss: 2.3761\n",
      "Iteration: 2293; Percent complete: 57.3%; Average loss: 3.0226\n",
      "Iteration: 2294; Percent complete: 57.4%; Average loss: 2.6173\n",
      "Iteration: 2295; Percent complete: 57.4%; Average loss: 2.4598\n",
      "Iteration: 2296; Percent complete: 57.4%; Average loss: 2.3799\n",
      "Iteration: 2297; Percent complete: 57.4%; Average loss: 2.4417\n",
      "Iteration: 2298; Percent complete: 57.5%; Average loss: 2.6177\n",
      "Iteration: 2299; Percent complete: 57.5%; Average loss: 2.6052\n",
      "Iteration: 2300; Percent complete: 57.5%; Average loss: 2.5188\n",
      "Iteration: 2301; Percent complete: 57.5%; Average loss: 2.6239\n",
      "Iteration: 2302; Percent complete: 57.6%; Average loss: 2.5040\n",
      "Iteration: 2303; Percent complete: 57.6%; Average loss: 2.5250\n",
      "Iteration: 2304; Percent complete: 57.6%; Average loss: 2.6338\n",
      "Iteration: 2305; Percent complete: 57.6%; Average loss: 2.7469\n",
      "Iteration: 2306; Percent complete: 57.6%; Average loss: 2.5200\n",
      "Iteration: 2307; Percent complete: 57.7%; Average loss: 2.3959\n",
      "Iteration: 2308; Percent complete: 57.7%; Average loss: 2.7465\n",
      "Iteration: 2309; Percent complete: 57.7%; Average loss: 2.6848\n",
      "Iteration: 2310; Percent complete: 57.8%; Average loss: 2.6154\n",
      "Iteration: 2311; Percent complete: 57.8%; Average loss: 2.4826\n",
      "Iteration: 2312; Percent complete: 57.8%; Average loss: 2.5051\n",
      "Iteration: 2313; Percent complete: 57.8%; Average loss: 2.5079\n",
      "Iteration: 2314; Percent complete: 57.9%; Average loss: 2.5898\n",
      "Iteration: 2315; Percent complete: 57.9%; Average loss: 2.5075\n",
      "Iteration: 2316; Percent complete: 57.9%; Average loss: 2.3297\n",
      "Iteration: 2317; Percent complete: 57.9%; Average loss: 2.4906\n",
      "Iteration: 2318; Percent complete: 58.0%; Average loss: 2.3573\n",
      "Iteration: 2319; Percent complete: 58.0%; Average loss: 2.6414\n",
      "Iteration: 2320; Percent complete: 58.0%; Average loss: 2.4610\n",
      "Iteration: 2321; Percent complete: 58.0%; Average loss: 2.6713\n",
      "Iteration: 2322; Percent complete: 58.1%; Average loss: 2.4284\n",
      "Iteration: 2323; Percent complete: 58.1%; Average loss: 2.4448\n",
      "Iteration: 2324; Percent complete: 58.1%; Average loss: 2.6467\n",
      "Iteration: 2325; Percent complete: 58.1%; Average loss: 2.6166\n",
      "Iteration: 2326; Percent complete: 58.1%; Average loss: 2.6467\n",
      "Iteration: 2327; Percent complete: 58.2%; Average loss: 2.8218\n",
      "Iteration: 2328; Percent complete: 58.2%; Average loss: 2.5505\n",
      "Iteration: 2329; Percent complete: 58.2%; Average loss: 2.5771\n",
      "Iteration: 2330; Percent complete: 58.2%; Average loss: 2.5487\n",
      "Iteration: 2331; Percent complete: 58.3%; Average loss: 2.5692\n",
      "Iteration: 2332; Percent complete: 58.3%; Average loss: 2.7016\n",
      "Iteration: 2333; Percent complete: 58.3%; Average loss: 2.8538\n",
      "Iteration: 2334; Percent complete: 58.4%; Average loss: 2.7154\n",
      "Iteration: 2335; Percent complete: 58.4%; Average loss: 2.5851\n",
      "Iteration: 2336; Percent complete: 58.4%; Average loss: 2.6336\n",
      "Iteration: 2337; Percent complete: 58.4%; Average loss: 2.7125\n",
      "Iteration: 2338; Percent complete: 58.5%; Average loss: 2.7585\n",
      "Iteration: 2339; Percent complete: 58.5%; Average loss: 2.5501\n",
      "Iteration: 2340; Percent complete: 58.5%; Average loss: 2.2932\n",
      "Iteration: 2341; Percent complete: 58.5%; Average loss: 2.3981\n",
      "Iteration: 2342; Percent complete: 58.6%; Average loss: 2.6324\n",
      "Iteration: 2343; Percent complete: 58.6%; Average loss: 2.4934\n",
      "Iteration: 2344; Percent complete: 58.6%; Average loss: 2.7075\n",
      "Iteration: 2345; Percent complete: 58.6%; Average loss: 2.5676\n",
      "Iteration: 2346; Percent complete: 58.7%; Average loss: 2.4571\n",
      "Iteration: 2347; Percent complete: 58.7%; Average loss: 2.4804\n",
      "Iteration: 2348; Percent complete: 58.7%; Average loss: 2.4787\n",
      "Iteration: 2349; Percent complete: 58.7%; Average loss: 2.4578\n",
      "Iteration: 2350; Percent complete: 58.8%; Average loss: 2.4958\n",
      "Iteration: 2351; Percent complete: 58.8%; Average loss: 2.6461\n",
      "Iteration: 2352; Percent complete: 58.8%; Average loss: 2.5041\n",
      "Iteration: 2353; Percent complete: 58.8%; Average loss: 2.5079\n",
      "Iteration: 2354; Percent complete: 58.9%; Average loss: 2.6655\n",
      "Iteration: 2355; Percent complete: 58.9%; Average loss: 2.5824\n",
      "Iteration: 2356; Percent complete: 58.9%; Average loss: 2.5121\n",
      "Iteration: 2357; Percent complete: 58.9%; Average loss: 2.6230\n",
      "Iteration: 2358; Percent complete: 59.0%; Average loss: 2.6244\n",
      "Iteration: 2359; Percent complete: 59.0%; Average loss: 2.3713\n",
      "Iteration: 2360; Percent complete: 59.0%; Average loss: 2.5760\n",
      "Iteration: 2361; Percent complete: 59.0%; Average loss: 2.7700\n",
      "Iteration: 2362; Percent complete: 59.1%; Average loss: 2.4664\n",
      "Iteration: 2363; Percent complete: 59.1%; Average loss: 2.5681\n",
      "Iteration: 2364; Percent complete: 59.1%; Average loss: 2.3144\n",
      "Iteration: 2365; Percent complete: 59.1%; Average loss: 2.3852\n",
      "Iteration: 2366; Percent complete: 59.2%; Average loss: 2.4547\n",
      "Iteration: 2367; Percent complete: 59.2%; Average loss: 2.5699\n",
      "Iteration: 2368; Percent complete: 59.2%; Average loss: 2.4850\n",
      "Iteration: 2369; Percent complete: 59.2%; Average loss: 2.5390\n",
      "Iteration: 2370; Percent complete: 59.2%; Average loss: 2.7975\n",
      "Iteration: 2371; Percent complete: 59.3%; Average loss: 2.6524\n",
      "Iteration: 2372; Percent complete: 59.3%; Average loss: 2.6322\n",
      "Iteration: 2373; Percent complete: 59.3%; Average loss: 2.4836\n",
      "Iteration: 2374; Percent complete: 59.4%; Average loss: 2.7050\n",
      "Iteration: 2375; Percent complete: 59.4%; Average loss: 2.5246\n",
      "Iteration: 2376; Percent complete: 59.4%; Average loss: 2.4008\n",
      "Iteration: 2377; Percent complete: 59.4%; Average loss: 2.3755\n",
      "Iteration: 2378; Percent complete: 59.5%; Average loss: 2.7195\n",
      "Iteration: 2379; Percent complete: 59.5%; Average loss: 2.4807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2380; Percent complete: 59.5%; Average loss: 2.5706\n",
      "Iteration: 2381; Percent complete: 59.5%; Average loss: 2.5432\n",
      "Iteration: 2382; Percent complete: 59.6%; Average loss: 2.4231\n",
      "Iteration: 2383; Percent complete: 59.6%; Average loss: 2.5454\n",
      "Iteration: 2384; Percent complete: 59.6%; Average loss: 2.3457\n",
      "Iteration: 2385; Percent complete: 59.6%; Average loss: 2.6919\n",
      "Iteration: 2386; Percent complete: 59.7%; Average loss: 2.6387\n",
      "Iteration: 2387; Percent complete: 59.7%; Average loss: 2.5835\n",
      "Iteration: 2388; Percent complete: 59.7%; Average loss: 2.4326\n",
      "Iteration: 2389; Percent complete: 59.7%; Average loss: 2.6067\n",
      "Iteration: 2390; Percent complete: 59.8%; Average loss: 2.5138\n",
      "Iteration: 2391; Percent complete: 59.8%; Average loss: 2.3743\n",
      "Iteration: 2392; Percent complete: 59.8%; Average loss: 2.5279\n",
      "Iteration: 2393; Percent complete: 59.8%; Average loss: 2.5258\n",
      "Iteration: 2394; Percent complete: 59.9%; Average loss: 2.4563\n",
      "Iteration: 2395; Percent complete: 59.9%; Average loss: 2.4511\n",
      "Iteration: 2396; Percent complete: 59.9%; Average loss: 2.5211\n",
      "Iteration: 2397; Percent complete: 59.9%; Average loss: 2.4752\n",
      "Iteration: 2398; Percent complete: 60.0%; Average loss: 2.4359\n",
      "Iteration: 2399; Percent complete: 60.0%; Average loss: 2.5114\n",
      "Iteration: 2400; Percent complete: 60.0%; Average loss: 2.5898\n",
      "Iteration: 2401; Percent complete: 60.0%; Average loss: 2.3123\n",
      "Iteration: 2402; Percent complete: 60.1%; Average loss: 2.4100\n",
      "Iteration: 2403; Percent complete: 60.1%; Average loss: 2.5982\n",
      "Iteration: 2404; Percent complete: 60.1%; Average loss: 2.4684\n",
      "Iteration: 2405; Percent complete: 60.1%; Average loss: 2.5390\n",
      "Iteration: 2406; Percent complete: 60.2%; Average loss: 2.6765\n",
      "Iteration: 2407; Percent complete: 60.2%; Average loss: 2.5919\n",
      "Iteration: 2408; Percent complete: 60.2%; Average loss: 2.4334\n",
      "Iteration: 2409; Percent complete: 60.2%; Average loss: 2.6627\n",
      "Iteration: 2410; Percent complete: 60.2%; Average loss: 2.1880\n",
      "Iteration: 2411; Percent complete: 60.3%; Average loss: 2.6207\n",
      "Iteration: 2412; Percent complete: 60.3%; Average loss: 2.7524\n",
      "Iteration: 2413; Percent complete: 60.3%; Average loss: 2.4466\n",
      "Iteration: 2414; Percent complete: 60.4%; Average loss: 2.8305\n",
      "Iteration: 2415; Percent complete: 60.4%; Average loss: 2.4214\n",
      "Iteration: 2416; Percent complete: 60.4%; Average loss: 2.3660\n",
      "Iteration: 2417; Percent complete: 60.4%; Average loss: 2.5320\n",
      "Iteration: 2418; Percent complete: 60.5%; Average loss: 2.6746\n",
      "Iteration: 2419; Percent complete: 60.5%; Average loss: 2.6301\n",
      "Iteration: 2420; Percent complete: 60.5%; Average loss: 2.2828\n",
      "Iteration: 2421; Percent complete: 60.5%; Average loss: 2.5974\n",
      "Iteration: 2422; Percent complete: 60.6%; Average loss: 2.6067\n",
      "Iteration: 2423; Percent complete: 60.6%; Average loss: 2.6370\n",
      "Iteration: 2424; Percent complete: 60.6%; Average loss: 2.6533\n",
      "Iteration: 2425; Percent complete: 60.6%; Average loss: 2.6605\n",
      "Iteration: 2426; Percent complete: 60.7%; Average loss: 2.7349\n",
      "Iteration: 2427; Percent complete: 60.7%; Average loss: 2.7298\n",
      "Iteration: 2428; Percent complete: 60.7%; Average loss: 2.5290\n",
      "Iteration: 2429; Percent complete: 60.7%; Average loss: 2.7687\n",
      "Iteration: 2430; Percent complete: 60.8%; Average loss: 2.4753\n",
      "Iteration: 2431; Percent complete: 60.8%; Average loss: 2.5806\n",
      "Iteration: 2432; Percent complete: 60.8%; Average loss: 2.4207\n",
      "Iteration: 2433; Percent complete: 60.8%; Average loss: 2.6304\n",
      "Iteration: 2434; Percent complete: 60.9%; Average loss: 2.6647\n",
      "Iteration: 2435; Percent complete: 60.9%; Average loss: 2.3853\n",
      "Iteration: 2436; Percent complete: 60.9%; Average loss: 2.5652\n",
      "Iteration: 2437; Percent complete: 60.9%; Average loss: 2.4454\n",
      "Iteration: 2438; Percent complete: 61.0%; Average loss: 2.5550\n",
      "Iteration: 2439; Percent complete: 61.0%; Average loss: 2.4252\n",
      "Iteration: 2440; Percent complete: 61.0%; Average loss: 2.9615\n",
      "Iteration: 2441; Percent complete: 61.0%; Average loss: 2.6912\n",
      "Iteration: 2442; Percent complete: 61.1%; Average loss: 2.5332\n",
      "Iteration: 2443; Percent complete: 61.1%; Average loss: 2.4255\n",
      "Iteration: 2444; Percent complete: 61.1%; Average loss: 2.4982\n",
      "Iteration: 2445; Percent complete: 61.1%; Average loss: 2.6381\n",
      "Iteration: 2446; Percent complete: 61.2%; Average loss: 2.5235\n",
      "Iteration: 2447; Percent complete: 61.2%; Average loss: 2.6453\n",
      "Iteration: 2448; Percent complete: 61.2%; Average loss: 2.5087\n",
      "Iteration: 2449; Percent complete: 61.2%; Average loss: 2.5120\n",
      "Iteration: 2450; Percent complete: 61.3%; Average loss: 2.4712\n",
      "Iteration: 2451; Percent complete: 61.3%; Average loss: 2.5504\n",
      "Iteration: 2452; Percent complete: 61.3%; Average loss: 2.3436\n",
      "Iteration: 2453; Percent complete: 61.3%; Average loss: 2.6307\n",
      "Iteration: 2454; Percent complete: 61.4%; Average loss: 2.6541\n",
      "Iteration: 2455; Percent complete: 61.4%; Average loss: 2.3468\n",
      "Iteration: 2456; Percent complete: 61.4%; Average loss: 2.4194\n",
      "Iteration: 2457; Percent complete: 61.4%; Average loss: 2.5387\n",
      "Iteration: 2458; Percent complete: 61.5%; Average loss: 2.4665\n",
      "Iteration: 2459; Percent complete: 61.5%; Average loss: 2.4231\n",
      "Iteration: 2460; Percent complete: 61.5%; Average loss: 2.6198\n",
      "Iteration: 2461; Percent complete: 61.5%; Average loss: 2.5609\n",
      "Iteration: 2462; Percent complete: 61.6%; Average loss: 2.5772\n",
      "Iteration: 2463; Percent complete: 61.6%; Average loss: 2.7380\n",
      "Iteration: 2464; Percent complete: 61.6%; Average loss: 2.4575\n",
      "Iteration: 2465; Percent complete: 61.6%; Average loss: 2.4999\n",
      "Iteration: 2466; Percent complete: 61.7%; Average loss: 2.6297\n",
      "Iteration: 2467; Percent complete: 61.7%; Average loss: 2.6575\n",
      "Iteration: 2468; Percent complete: 61.7%; Average loss: 2.6875\n",
      "Iteration: 2469; Percent complete: 61.7%; Average loss: 2.1949\n",
      "Iteration: 2470; Percent complete: 61.8%; Average loss: 2.4288\n",
      "Iteration: 2471; Percent complete: 61.8%; Average loss: 2.5406\n",
      "Iteration: 2472; Percent complete: 61.8%; Average loss: 2.6458\n",
      "Iteration: 2473; Percent complete: 61.8%; Average loss: 2.6659\n",
      "Iteration: 2474; Percent complete: 61.9%; Average loss: 2.7396\n",
      "Iteration: 2475; Percent complete: 61.9%; Average loss: 2.3328\n",
      "Iteration: 2476; Percent complete: 61.9%; Average loss: 2.4232\n",
      "Iteration: 2477; Percent complete: 61.9%; Average loss: 2.5594\n",
      "Iteration: 2478; Percent complete: 62.0%; Average loss: 2.5326\n",
      "Iteration: 2479; Percent complete: 62.0%; Average loss: 2.4652\n",
      "Iteration: 2480; Percent complete: 62.0%; Average loss: 2.6505\n",
      "Iteration: 2481; Percent complete: 62.0%; Average loss: 2.5156\n",
      "Iteration: 2482; Percent complete: 62.1%; Average loss: 2.4126\n",
      "Iteration: 2483; Percent complete: 62.1%; Average loss: 2.7113\n",
      "Iteration: 2484; Percent complete: 62.1%; Average loss: 2.5721\n",
      "Iteration: 2485; Percent complete: 62.1%; Average loss: 2.4204\n",
      "Iteration: 2486; Percent complete: 62.2%; Average loss: 2.5385\n",
      "Iteration: 2487; Percent complete: 62.2%; Average loss: 2.4640\n",
      "Iteration: 2488; Percent complete: 62.2%; Average loss: 2.6027\n",
      "Iteration: 2489; Percent complete: 62.2%; Average loss: 2.5437\n",
      "Iteration: 2490; Percent complete: 62.3%; Average loss: 2.7937\n",
      "Iteration: 2491; Percent complete: 62.3%; Average loss: 2.3653\n",
      "Iteration: 2492; Percent complete: 62.3%; Average loss: 2.3925\n",
      "Iteration: 2493; Percent complete: 62.3%; Average loss: 2.3696\n",
      "Iteration: 2494; Percent complete: 62.4%; Average loss: 2.5295\n",
      "Iteration: 2495; Percent complete: 62.4%; Average loss: 2.7013\n",
      "Iteration: 2496; Percent complete: 62.4%; Average loss: 2.6858\n",
      "Iteration: 2497; Percent complete: 62.4%; Average loss: 2.5981\n",
      "Iteration: 2498; Percent complete: 62.5%; Average loss: 2.9138\n",
      "Iteration: 2499; Percent complete: 62.5%; Average loss: 2.4415\n",
      "Iteration: 2500; Percent complete: 62.5%; Average loss: 2.4274\n",
      "Iteration: 2501; Percent complete: 62.5%; Average loss: 2.3865\n",
      "Iteration: 2502; Percent complete: 62.5%; Average loss: 2.4635\n",
      "Iteration: 2503; Percent complete: 62.6%; Average loss: 2.5378\n",
      "Iteration: 2504; Percent complete: 62.6%; Average loss: 2.4786\n",
      "Iteration: 2505; Percent complete: 62.6%; Average loss: 2.5666\n",
      "Iteration: 2506; Percent complete: 62.6%; Average loss: 2.3761\n",
      "Iteration: 2507; Percent complete: 62.7%; Average loss: 2.3684\n",
      "Iteration: 2508; Percent complete: 62.7%; Average loss: 2.4976\n",
      "Iteration: 2509; Percent complete: 62.7%; Average loss: 2.5203\n",
      "Iteration: 2510; Percent complete: 62.7%; Average loss: 2.8815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2511; Percent complete: 62.8%; Average loss: 2.4141\n",
      "Iteration: 2512; Percent complete: 62.8%; Average loss: 2.3451\n",
      "Iteration: 2513; Percent complete: 62.8%; Average loss: 2.2807\n",
      "Iteration: 2514; Percent complete: 62.8%; Average loss: 2.6918\n",
      "Iteration: 2515; Percent complete: 62.9%; Average loss: 2.5722\n",
      "Iteration: 2516; Percent complete: 62.9%; Average loss: 2.5630\n",
      "Iteration: 2517; Percent complete: 62.9%; Average loss: 2.4267\n",
      "Iteration: 2518; Percent complete: 62.9%; Average loss: 2.5218\n",
      "Iteration: 2519; Percent complete: 63.0%; Average loss: 2.4731\n",
      "Iteration: 2520; Percent complete: 63.0%; Average loss: 2.4334\n",
      "Iteration: 2521; Percent complete: 63.0%; Average loss: 2.4544\n",
      "Iteration: 2522; Percent complete: 63.0%; Average loss: 2.6371\n",
      "Iteration: 2523; Percent complete: 63.1%; Average loss: 2.5226\n",
      "Iteration: 2524; Percent complete: 63.1%; Average loss: 2.5874\n",
      "Iteration: 2525; Percent complete: 63.1%; Average loss: 2.5253\n",
      "Iteration: 2526; Percent complete: 63.1%; Average loss: 2.4681\n",
      "Iteration: 2527; Percent complete: 63.2%; Average loss: 2.5018\n",
      "Iteration: 2528; Percent complete: 63.2%; Average loss: 2.6391\n",
      "Iteration: 2529; Percent complete: 63.2%; Average loss: 2.4112\n",
      "Iteration: 2530; Percent complete: 63.2%; Average loss: 2.5289\n",
      "Iteration: 2531; Percent complete: 63.3%; Average loss: 2.5978\n",
      "Iteration: 2532; Percent complete: 63.3%; Average loss: 2.6480\n",
      "Iteration: 2533; Percent complete: 63.3%; Average loss: 2.7092\n",
      "Iteration: 2534; Percent complete: 63.3%; Average loss: 2.4821\n",
      "Iteration: 2535; Percent complete: 63.4%; Average loss: 2.6379\n",
      "Iteration: 2536; Percent complete: 63.4%; Average loss: 2.4922\n",
      "Iteration: 2537; Percent complete: 63.4%; Average loss: 2.6030\n",
      "Iteration: 2538; Percent complete: 63.4%; Average loss: 2.5720\n",
      "Iteration: 2539; Percent complete: 63.5%; Average loss: 2.6498\n",
      "Iteration: 2540; Percent complete: 63.5%; Average loss: 2.6610\n",
      "Iteration: 2541; Percent complete: 63.5%; Average loss: 2.2220\n",
      "Iteration: 2542; Percent complete: 63.5%; Average loss: 2.4791\n",
      "Iteration: 2543; Percent complete: 63.6%; Average loss: 2.4498\n",
      "Iteration: 2544; Percent complete: 63.6%; Average loss: 2.5383\n",
      "Iteration: 2545; Percent complete: 63.6%; Average loss: 2.6107\n",
      "Iteration: 2546; Percent complete: 63.6%; Average loss: 2.6230\n",
      "Iteration: 2547; Percent complete: 63.7%; Average loss: 2.3808\n",
      "Iteration: 2548; Percent complete: 63.7%; Average loss: 2.4521\n",
      "Iteration: 2549; Percent complete: 63.7%; Average loss: 2.4984\n",
      "Iteration: 2550; Percent complete: 63.7%; Average loss: 2.7036\n",
      "Iteration: 2551; Percent complete: 63.8%; Average loss: 2.4836\n",
      "Iteration: 2552; Percent complete: 63.8%; Average loss: 2.4720\n",
      "Iteration: 2553; Percent complete: 63.8%; Average loss: 2.5283\n",
      "Iteration: 2554; Percent complete: 63.8%; Average loss: 2.4078\n",
      "Iteration: 2555; Percent complete: 63.9%; Average loss: 2.3710\n",
      "Iteration: 2556; Percent complete: 63.9%; Average loss: 2.4066\n",
      "Iteration: 2557; Percent complete: 63.9%; Average loss: 2.6718\n",
      "Iteration: 2558; Percent complete: 63.9%; Average loss: 2.5571\n",
      "Iteration: 2559; Percent complete: 64.0%; Average loss: 2.7000\n",
      "Iteration: 2560; Percent complete: 64.0%; Average loss: 2.4479\n",
      "Iteration: 2561; Percent complete: 64.0%; Average loss: 2.6095\n",
      "Iteration: 2562; Percent complete: 64.0%; Average loss: 2.4186\n",
      "Iteration: 2563; Percent complete: 64.1%; Average loss: 2.6276\n",
      "Iteration: 2564; Percent complete: 64.1%; Average loss: 2.7051\n",
      "Iteration: 2565; Percent complete: 64.1%; Average loss: 2.3584\n",
      "Iteration: 2566; Percent complete: 64.1%; Average loss: 2.6894\n",
      "Iteration: 2567; Percent complete: 64.2%; Average loss: 2.1858\n",
      "Iteration: 2568; Percent complete: 64.2%; Average loss: 2.3563\n",
      "Iteration: 2569; Percent complete: 64.2%; Average loss: 2.5506\n",
      "Iteration: 2570; Percent complete: 64.2%; Average loss: 2.5387\n",
      "Iteration: 2571; Percent complete: 64.3%; Average loss: 2.3952\n",
      "Iteration: 2572; Percent complete: 64.3%; Average loss: 2.3965\n",
      "Iteration: 2573; Percent complete: 64.3%; Average loss: 2.5213\n",
      "Iteration: 2574; Percent complete: 64.3%; Average loss: 2.4840\n",
      "Iteration: 2575; Percent complete: 64.4%; Average loss: 2.4258\n",
      "Iteration: 2576; Percent complete: 64.4%; Average loss: 2.7329\n",
      "Iteration: 2577; Percent complete: 64.4%; Average loss: 2.4403\n",
      "Iteration: 2578; Percent complete: 64.5%; Average loss: 2.5844\n",
      "Iteration: 2579; Percent complete: 64.5%; Average loss: 2.2499\n",
      "Iteration: 2580; Percent complete: 64.5%; Average loss: 2.4462\n",
      "Iteration: 2581; Percent complete: 64.5%; Average loss: 2.4502\n",
      "Iteration: 2582; Percent complete: 64.5%; Average loss: 2.8019\n",
      "Iteration: 2583; Percent complete: 64.6%; Average loss: 2.4130\n",
      "Iteration: 2584; Percent complete: 64.6%; Average loss: 2.4245\n",
      "Iteration: 2585; Percent complete: 64.6%; Average loss: 2.4086\n",
      "Iteration: 2586; Percent complete: 64.6%; Average loss: 2.4829\n",
      "Iteration: 2587; Percent complete: 64.7%; Average loss: 2.3957\n",
      "Iteration: 2588; Percent complete: 64.7%; Average loss: 2.5430\n",
      "Iteration: 2589; Percent complete: 64.7%; Average loss: 2.5360\n",
      "Iteration: 2590; Percent complete: 64.8%; Average loss: 2.6860\n",
      "Iteration: 2591; Percent complete: 64.8%; Average loss: 2.7401\n",
      "Iteration: 2592; Percent complete: 64.8%; Average loss: 2.3375\n",
      "Iteration: 2593; Percent complete: 64.8%; Average loss: 2.4254\n",
      "Iteration: 2594; Percent complete: 64.8%; Average loss: 2.2954\n",
      "Iteration: 2595; Percent complete: 64.9%; Average loss: 2.4328\n",
      "Iteration: 2596; Percent complete: 64.9%; Average loss: 2.5287\n",
      "Iteration: 2597; Percent complete: 64.9%; Average loss: 2.5639\n",
      "Iteration: 2598; Percent complete: 65.0%; Average loss: 2.3751\n",
      "Iteration: 2599; Percent complete: 65.0%; Average loss: 2.5524\n",
      "Iteration: 2600; Percent complete: 65.0%; Average loss: 2.5662\n",
      "Iteration: 2601; Percent complete: 65.0%; Average loss: 2.6052\n",
      "Iteration: 2602; Percent complete: 65.0%; Average loss: 2.5135\n",
      "Iteration: 2603; Percent complete: 65.1%; Average loss: 2.5722\n",
      "Iteration: 2604; Percent complete: 65.1%; Average loss: 2.4133\n",
      "Iteration: 2605; Percent complete: 65.1%; Average loss: 2.6076\n",
      "Iteration: 2606; Percent complete: 65.1%; Average loss: 2.3951\n",
      "Iteration: 2607; Percent complete: 65.2%; Average loss: 2.4834\n",
      "Iteration: 2608; Percent complete: 65.2%; Average loss: 2.6788\n",
      "Iteration: 2609; Percent complete: 65.2%; Average loss: 2.4410\n",
      "Iteration: 2610; Percent complete: 65.2%; Average loss: 2.4742\n",
      "Iteration: 2611; Percent complete: 65.3%; Average loss: 2.5845\n",
      "Iteration: 2612; Percent complete: 65.3%; Average loss: 2.6477\n",
      "Iteration: 2613; Percent complete: 65.3%; Average loss: 2.5648\n",
      "Iteration: 2614; Percent complete: 65.3%; Average loss: 2.4352\n",
      "Iteration: 2615; Percent complete: 65.4%; Average loss: 2.5143\n",
      "Iteration: 2616; Percent complete: 65.4%; Average loss: 2.3366\n",
      "Iteration: 2617; Percent complete: 65.4%; Average loss: 2.5274\n",
      "Iteration: 2618; Percent complete: 65.5%; Average loss: 2.2970\n",
      "Iteration: 2619; Percent complete: 65.5%; Average loss: 2.2626\n",
      "Iteration: 2620; Percent complete: 65.5%; Average loss: 2.4046\n",
      "Iteration: 2621; Percent complete: 65.5%; Average loss: 2.3524\n",
      "Iteration: 2622; Percent complete: 65.5%; Average loss: 2.5994\n",
      "Iteration: 2623; Percent complete: 65.6%; Average loss: 2.4242\n",
      "Iteration: 2624; Percent complete: 65.6%; Average loss: 2.7587\n",
      "Iteration: 2625; Percent complete: 65.6%; Average loss: 2.3695\n",
      "Iteration: 2626; Percent complete: 65.6%; Average loss: 2.5617\n",
      "Iteration: 2627; Percent complete: 65.7%; Average loss: 2.4207\n",
      "Iteration: 2628; Percent complete: 65.7%; Average loss: 2.3741\n",
      "Iteration: 2629; Percent complete: 65.7%; Average loss: 2.6920\n",
      "Iteration: 2630; Percent complete: 65.8%; Average loss: 2.6486\n",
      "Iteration: 2631; Percent complete: 65.8%; Average loss: 2.5477\n",
      "Iteration: 2632; Percent complete: 65.8%; Average loss: 2.4662\n",
      "Iteration: 2633; Percent complete: 65.8%; Average loss: 2.2433\n",
      "Iteration: 2634; Percent complete: 65.8%; Average loss: 2.4565\n",
      "Iteration: 2635; Percent complete: 65.9%; Average loss: 2.6120\n",
      "Iteration: 2636; Percent complete: 65.9%; Average loss: 2.7847\n",
      "Iteration: 2637; Percent complete: 65.9%; Average loss: 2.3494\n",
      "Iteration: 2638; Percent complete: 66.0%; Average loss: 2.4902\n",
      "Iteration: 2639; Percent complete: 66.0%; Average loss: 2.3273\n",
      "Iteration: 2640; Percent complete: 66.0%; Average loss: 2.3510\n",
      "Iteration: 2641; Percent complete: 66.0%; Average loss: 2.5966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2642; Percent complete: 66.0%; Average loss: 2.6590\n",
      "Iteration: 2643; Percent complete: 66.1%; Average loss: 2.5486\n",
      "Iteration: 2644; Percent complete: 66.1%; Average loss: 2.5824\n",
      "Iteration: 2645; Percent complete: 66.1%; Average loss: 2.2933\n",
      "Iteration: 2646; Percent complete: 66.1%; Average loss: 2.4955\n",
      "Iteration: 2647; Percent complete: 66.2%; Average loss: 2.4738\n",
      "Iteration: 2648; Percent complete: 66.2%; Average loss: 2.7643\n",
      "Iteration: 2649; Percent complete: 66.2%; Average loss: 2.4763\n",
      "Iteration: 2650; Percent complete: 66.2%; Average loss: 2.4883\n",
      "Iteration: 2651; Percent complete: 66.3%; Average loss: 2.6790\n",
      "Iteration: 2652; Percent complete: 66.3%; Average loss: 2.4882\n",
      "Iteration: 2653; Percent complete: 66.3%; Average loss: 2.3906\n",
      "Iteration: 2654; Percent complete: 66.3%; Average loss: 2.4475\n",
      "Iteration: 2655; Percent complete: 66.4%; Average loss: 2.6782\n",
      "Iteration: 2656; Percent complete: 66.4%; Average loss: 2.5956\n",
      "Iteration: 2657; Percent complete: 66.4%; Average loss: 2.5594\n",
      "Iteration: 2658; Percent complete: 66.5%; Average loss: 2.6032\n",
      "Iteration: 2659; Percent complete: 66.5%; Average loss: 2.7092\n",
      "Iteration: 2660; Percent complete: 66.5%; Average loss: 2.4677\n",
      "Iteration: 2661; Percent complete: 66.5%; Average loss: 2.4028\n",
      "Iteration: 2662; Percent complete: 66.5%; Average loss: 2.4418\n",
      "Iteration: 2663; Percent complete: 66.6%; Average loss: 2.5898\n",
      "Iteration: 2664; Percent complete: 66.6%; Average loss: 2.4006\n",
      "Iteration: 2665; Percent complete: 66.6%; Average loss: 2.6417\n",
      "Iteration: 2666; Percent complete: 66.6%; Average loss: 2.4772\n",
      "Iteration: 2667; Percent complete: 66.7%; Average loss: 2.4474\n",
      "Iteration: 2668; Percent complete: 66.7%; Average loss: 2.5597\n",
      "Iteration: 2669; Percent complete: 66.7%; Average loss: 2.2055\n",
      "Iteration: 2670; Percent complete: 66.8%; Average loss: 2.3896\n",
      "Iteration: 2671; Percent complete: 66.8%; Average loss: 2.4709\n",
      "Iteration: 2672; Percent complete: 66.8%; Average loss: 2.5748\n",
      "Iteration: 2673; Percent complete: 66.8%; Average loss: 2.4455\n",
      "Iteration: 2674; Percent complete: 66.8%; Average loss: 2.4570\n",
      "Iteration: 2675; Percent complete: 66.9%; Average loss: 2.5299\n",
      "Iteration: 2676; Percent complete: 66.9%; Average loss: 2.6549\n",
      "Iteration: 2677; Percent complete: 66.9%; Average loss: 2.4142\n",
      "Iteration: 2678; Percent complete: 67.0%; Average loss: 2.5644\n",
      "Iteration: 2679; Percent complete: 67.0%; Average loss: 2.3519\n",
      "Iteration: 2680; Percent complete: 67.0%; Average loss: 2.3774\n",
      "Iteration: 2681; Percent complete: 67.0%; Average loss: 2.4335\n",
      "Iteration: 2682; Percent complete: 67.0%; Average loss: 2.3211\n",
      "Iteration: 2683; Percent complete: 67.1%; Average loss: 2.3876\n",
      "Iteration: 2684; Percent complete: 67.1%; Average loss: 2.4466\n",
      "Iteration: 2685; Percent complete: 67.1%; Average loss: 2.5642\n",
      "Iteration: 2686; Percent complete: 67.2%; Average loss: 2.5906\n",
      "Iteration: 2687; Percent complete: 67.2%; Average loss: 2.3534\n",
      "Iteration: 2688; Percent complete: 67.2%; Average loss: 2.3221\n",
      "Iteration: 2689; Percent complete: 67.2%; Average loss: 2.4470\n",
      "Iteration: 2690; Percent complete: 67.2%; Average loss: 2.6373\n",
      "Iteration: 2691; Percent complete: 67.3%; Average loss: 2.5207\n",
      "Iteration: 2692; Percent complete: 67.3%; Average loss: 2.3025\n",
      "Iteration: 2693; Percent complete: 67.3%; Average loss: 2.5945\n",
      "Iteration: 2694; Percent complete: 67.3%; Average loss: 2.6072\n",
      "Iteration: 2695; Percent complete: 67.4%; Average loss: 2.5877\n",
      "Iteration: 2696; Percent complete: 67.4%; Average loss: 2.4543\n",
      "Iteration: 2697; Percent complete: 67.4%; Average loss: 2.6127\n",
      "Iteration: 2698; Percent complete: 67.5%; Average loss: 2.1577\n",
      "Iteration: 2699; Percent complete: 67.5%; Average loss: 2.4091\n",
      "Iteration: 2700; Percent complete: 67.5%; Average loss: 2.4729\n",
      "Iteration: 2701; Percent complete: 67.5%; Average loss: 2.5866\n",
      "Iteration: 2702; Percent complete: 67.5%; Average loss: 2.6565\n",
      "Iteration: 2703; Percent complete: 67.6%; Average loss: 2.5546\n",
      "Iteration: 2704; Percent complete: 67.6%; Average loss: 2.6046\n",
      "Iteration: 2705; Percent complete: 67.6%; Average loss: 2.5659\n",
      "Iteration: 2706; Percent complete: 67.7%; Average loss: 2.6582\n",
      "Iteration: 2707; Percent complete: 67.7%; Average loss: 2.3398\n",
      "Iteration: 2708; Percent complete: 67.7%; Average loss: 2.5014\n",
      "Iteration: 2709; Percent complete: 67.7%; Average loss: 2.3629\n",
      "Iteration: 2710; Percent complete: 67.8%; Average loss: 2.6666\n",
      "Iteration: 2711; Percent complete: 67.8%; Average loss: 2.4322\n",
      "Iteration: 2712; Percent complete: 67.8%; Average loss: 2.5443\n",
      "Iteration: 2713; Percent complete: 67.8%; Average loss: 2.6922\n",
      "Iteration: 2714; Percent complete: 67.8%; Average loss: 2.7017\n",
      "Iteration: 2715; Percent complete: 67.9%; Average loss: 2.3687\n",
      "Iteration: 2716; Percent complete: 67.9%; Average loss: 2.3205\n",
      "Iteration: 2717; Percent complete: 67.9%; Average loss: 2.8162\n",
      "Iteration: 2718; Percent complete: 68.0%; Average loss: 2.4951\n",
      "Iteration: 2719; Percent complete: 68.0%; Average loss: 2.3751\n",
      "Iteration: 2720; Percent complete: 68.0%; Average loss: 2.4794\n",
      "Iteration: 2721; Percent complete: 68.0%; Average loss: 2.3950\n",
      "Iteration: 2722; Percent complete: 68.0%; Average loss: 2.5417\n",
      "Iteration: 2723; Percent complete: 68.1%; Average loss: 2.6414\n",
      "Iteration: 2724; Percent complete: 68.1%; Average loss: 2.5577\n",
      "Iteration: 2725; Percent complete: 68.1%; Average loss: 2.7248\n",
      "Iteration: 2726; Percent complete: 68.2%; Average loss: 2.4700\n",
      "Iteration: 2727; Percent complete: 68.2%; Average loss: 2.4304\n",
      "Iteration: 2728; Percent complete: 68.2%; Average loss: 2.4596\n",
      "Iteration: 2729; Percent complete: 68.2%; Average loss: 2.5708\n",
      "Iteration: 2730; Percent complete: 68.2%; Average loss: 2.4274\n",
      "Iteration: 2731; Percent complete: 68.3%; Average loss: 2.4758\n",
      "Iteration: 2732; Percent complete: 68.3%; Average loss: 2.5780\n",
      "Iteration: 2733; Percent complete: 68.3%; Average loss: 2.2837\n",
      "Iteration: 2734; Percent complete: 68.3%; Average loss: 2.7133\n",
      "Iteration: 2735; Percent complete: 68.4%; Average loss: 2.6419\n",
      "Iteration: 2736; Percent complete: 68.4%; Average loss: 2.4019\n",
      "Iteration: 2737; Percent complete: 68.4%; Average loss: 2.6672\n",
      "Iteration: 2738; Percent complete: 68.5%; Average loss: 2.3900\n",
      "Iteration: 2739; Percent complete: 68.5%; Average loss: 2.4444\n",
      "Iteration: 2740; Percent complete: 68.5%; Average loss: 2.4302\n",
      "Iteration: 2741; Percent complete: 68.5%; Average loss: 2.2685\n",
      "Iteration: 2742; Percent complete: 68.5%; Average loss: 2.5856\n",
      "Iteration: 2743; Percent complete: 68.6%; Average loss: 2.4030\n",
      "Iteration: 2744; Percent complete: 68.6%; Average loss: 2.4421\n",
      "Iteration: 2745; Percent complete: 68.6%; Average loss: 2.4609\n",
      "Iteration: 2746; Percent complete: 68.7%; Average loss: 2.1301\n",
      "Iteration: 2747; Percent complete: 68.7%; Average loss: 2.4282\n",
      "Iteration: 2748; Percent complete: 68.7%; Average loss: 2.4200\n",
      "Iteration: 2749; Percent complete: 68.7%; Average loss: 2.4478\n",
      "Iteration: 2750; Percent complete: 68.8%; Average loss: 2.6367\n",
      "Iteration: 2751; Percent complete: 68.8%; Average loss: 2.5728\n",
      "Iteration: 2752; Percent complete: 68.8%; Average loss: 2.6192\n",
      "Iteration: 2753; Percent complete: 68.8%; Average loss: 2.5626\n",
      "Iteration: 2754; Percent complete: 68.8%; Average loss: 2.2470\n",
      "Iteration: 2755; Percent complete: 68.9%; Average loss: 2.5636\n",
      "Iteration: 2756; Percent complete: 68.9%; Average loss: 2.5570\n",
      "Iteration: 2757; Percent complete: 68.9%; Average loss: 2.6062\n",
      "Iteration: 2758; Percent complete: 69.0%; Average loss: 2.5255\n",
      "Iteration: 2759; Percent complete: 69.0%; Average loss: 2.5705\n",
      "Iteration: 2760; Percent complete: 69.0%; Average loss: 2.4960\n",
      "Iteration: 2761; Percent complete: 69.0%; Average loss: 2.5171\n",
      "Iteration: 2762; Percent complete: 69.0%; Average loss: 2.4955\n",
      "Iteration: 2763; Percent complete: 69.1%; Average loss: 2.2899\n",
      "Iteration: 2764; Percent complete: 69.1%; Average loss: 2.4534\n",
      "Iteration: 2765; Percent complete: 69.1%; Average loss: 2.6194\n",
      "Iteration: 2766; Percent complete: 69.2%; Average loss: 2.3725\n",
      "Iteration: 2767; Percent complete: 69.2%; Average loss: 2.3218\n",
      "Iteration: 2768; Percent complete: 69.2%; Average loss: 2.6379\n",
      "Iteration: 2769; Percent complete: 69.2%; Average loss: 2.5245\n",
      "Iteration: 2770; Percent complete: 69.2%; Average loss: 2.4314\n",
      "Iteration: 2771; Percent complete: 69.3%; Average loss: 2.4234\n",
      "Iteration: 2772; Percent complete: 69.3%; Average loss: 2.4537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2773; Percent complete: 69.3%; Average loss: 2.4752\n",
      "Iteration: 2774; Percent complete: 69.3%; Average loss: 2.4654\n",
      "Iteration: 2775; Percent complete: 69.4%; Average loss: 2.6533\n",
      "Iteration: 2776; Percent complete: 69.4%; Average loss: 2.6563\n",
      "Iteration: 2777; Percent complete: 69.4%; Average loss: 2.6636\n",
      "Iteration: 2778; Percent complete: 69.5%; Average loss: 2.3620\n",
      "Iteration: 2779; Percent complete: 69.5%; Average loss: 2.4702\n",
      "Iteration: 2780; Percent complete: 69.5%; Average loss: 2.4737\n",
      "Iteration: 2781; Percent complete: 69.5%; Average loss: 2.4770\n",
      "Iteration: 2782; Percent complete: 69.5%; Average loss: 2.4694\n",
      "Iteration: 2783; Percent complete: 69.6%; Average loss: 2.3946\n",
      "Iteration: 2784; Percent complete: 69.6%; Average loss: 2.5348\n",
      "Iteration: 2785; Percent complete: 69.6%; Average loss: 2.4834\n",
      "Iteration: 2786; Percent complete: 69.7%; Average loss: 2.4384\n",
      "Iteration: 2787; Percent complete: 69.7%; Average loss: 2.5215\n",
      "Iteration: 2788; Percent complete: 69.7%; Average loss: 2.2821\n",
      "Iteration: 2789; Percent complete: 69.7%; Average loss: 2.3349\n",
      "Iteration: 2790; Percent complete: 69.8%; Average loss: 2.6651\n",
      "Iteration: 2791; Percent complete: 69.8%; Average loss: 2.4778\n",
      "Iteration: 2792; Percent complete: 69.8%; Average loss: 2.3083\n",
      "Iteration: 2793; Percent complete: 69.8%; Average loss: 2.5142\n",
      "Iteration: 2794; Percent complete: 69.8%; Average loss: 2.3591\n",
      "Iteration: 2795; Percent complete: 69.9%; Average loss: 2.3332\n",
      "Iteration: 2796; Percent complete: 69.9%; Average loss: 2.3999\n",
      "Iteration: 2797; Percent complete: 69.9%; Average loss: 2.4201\n",
      "Iteration: 2798; Percent complete: 70.0%; Average loss: 2.6134\n",
      "Iteration: 2799; Percent complete: 70.0%; Average loss: 2.5168\n",
      "Iteration: 2800; Percent complete: 70.0%; Average loss: 2.5493\n",
      "Iteration: 2801; Percent complete: 70.0%; Average loss: 2.3388\n",
      "Iteration: 2802; Percent complete: 70.0%; Average loss: 2.5655\n",
      "Iteration: 2803; Percent complete: 70.1%; Average loss: 2.3324\n",
      "Iteration: 2804; Percent complete: 70.1%; Average loss: 2.3720\n",
      "Iteration: 2805; Percent complete: 70.1%; Average loss: 2.4363\n",
      "Iteration: 2806; Percent complete: 70.2%; Average loss: 2.4966\n",
      "Iteration: 2807; Percent complete: 70.2%; Average loss: 2.4793\n",
      "Iteration: 2808; Percent complete: 70.2%; Average loss: 2.6436\n",
      "Iteration: 2809; Percent complete: 70.2%; Average loss: 2.4720\n",
      "Iteration: 2810; Percent complete: 70.2%; Average loss: 2.5991\n",
      "Iteration: 2811; Percent complete: 70.3%; Average loss: 2.1456\n",
      "Iteration: 2812; Percent complete: 70.3%; Average loss: 2.3941\n",
      "Iteration: 2813; Percent complete: 70.3%; Average loss: 2.2214\n",
      "Iteration: 2814; Percent complete: 70.3%; Average loss: 2.4045\n",
      "Iteration: 2815; Percent complete: 70.4%; Average loss: 2.8529\n",
      "Iteration: 2816; Percent complete: 70.4%; Average loss: 2.4033\n",
      "Iteration: 2817; Percent complete: 70.4%; Average loss: 2.5307\n",
      "Iteration: 2818; Percent complete: 70.5%; Average loss: 2.4089\n",
      "Iteration: 2819; Percent complete: 70.5%; Average loss: 2.5177\n",
      "Iteration: 2820; Percent complete: 70.5%; Average loss: 2.3610\n",
      "Iteration: 2821; Percent complete: 70.5%; Average loss: 2.4500\n",
      "Iteration: 2822; Percent complete: 70.5%; Average loss: 2.5711\n",
      "Iteration: 2823; Percent complete: 70.6%; Average loss: 2.1995\n",
      "Iteration: 2824; Percent complete: 70.6%; Average loss: 2.5093\n",
      "Iteration: 2825; Percent complete: 70.6%; Average loss: 2.3513\n",
      "Iteration: 2826; Percent complete: 70.7%; Average loss: 2.5314\n",
      "Iteration: 2827; Percent complete: 70.7%; Average loss: 2.3790\n",
      "Iteration: 2828; Percent complete: 70.7%; Average loss: 2.4772\n",
      "Iteration: 2829; Percent complete: 70.7%; Average loss: 2.6234\n",
      "Iteration: 2830; Percent complete: 70.8%; Average loss: 2.3945\n",
      "Iteration: 2831; Percent complete: 70.8%; Average loss: 2.6432\n",
      "Iteration: 2832; Percent complete: 70.8%; Average loss: 2.4878\n",
      "Iteration: 2833; Percent complete: 70.8%; Average loss: 2.4915\n",
      "Iteration: 2834; Percent complete: 70.9%; Average loss: 2.4640\n",
      "Iteration: 2835; Percent complete: 70.9%; Average loss: 2.3911\n",
      "Iteration: 2836; Percent complete: 70.9%; Average loss: 2.4211\n",
      "Iteration: 2837; Percent complete: 70.9%; Average loss: 2.4372\n",
      "Iteration: 2838; Percent complete: 71.0%; Average loss: 2.3510\n",
      "Iteration: 2839; Percent complete: 71.0%; Average loss: 2.3940\n",
      "Iteration: 2840; Percent complete: 71.0%; Average loss: 2.4000\n",
      "Iteration: 2841; Percent complete: 71.0%; Average loss: 2.4251\n",
      "Iteration: 2842; Percent complete: 71.0%; Average loss: 2.4651\n",
      "Iteration: 2843; Percent complete: 71.1%; Average loss: 2.3962\n",
      "Iteration: 2844; Percent complete: 71.1%; Average loss: 2.5916\n",
      "Iteration: 2845; Percent complete: 71.1%; Average loss: 2.4327\n",
      "Iteration: 2846; Percent complete: 71.2%; Average loss: 2.3055\n",
      "Iteration: 2847; Percent complete: 71.2%; Average loss: 2.5110\n",
      "Iteration: 2848; Percent complete: 71.2%; Average loss: 2.4865\n",
      "Iteration: 2849; Percent complete: 71.2%; Average loss: 2.5005\n",
      "Iteration: 2850; Percent complete: 71.2%; Average loss: 2.4581\n",
      "Iteration: 2851; Percent complete: 71.3%; Average loss: 2.5937\n",
      "Iteration: 2852; Percent complete: 71.3%; Average loss: 2.3792\n",
      "Iteration: 2853; Percent complete: 71.3%; Average loss: 2.5248\n",
      "Iteration: 2854; Percent complete: 71.4%; Average loss: 2.5605\n",
      "Iteration: 2855; Percent complete: 71.4%; Average loss: 2.4892\n",
      "Iteration: 2856; Percent complete: 71.4%; Average loss: 2.4211\n",
      "Iteration: 2857; Percent complete: 71.4%; Average loss: 2.4405\n",
      "Iteration: 2858; Percent complete: 71.5%; Average loss: 2.2557\n",
      "Iteration: 2859; Percent complete: 71.5%; Average loss: 2.5036\n",
      "Iteration: 2860; Percent complete: 71.5%; Average loss: 2.4937\n",
      "Iteration: 2861; Percent complete: 71.5%; Average loss: 2.4422\n",
      "Iteration: 2862; Percent complete: 71.5%; Average loss: 2.3119\n",
      "Iteration: 2863; Percent complete: 71.6%; Average loss: 2.4609\n",
      "Iteration: 2864; Percent complete: 71.6%; Average loss: 2.4117\n",
      "Iteration: 2865; Percent complete: 71.6%; Average loss: 2.3396\n",
      "Iteration: 2866; Percent complete: 71.7%; Average loss: 2.2502\n",
      "Iteration: 2867; Percent complete: 71.7%; Average loss: 2.5182\n",
      "Iteration: 2868; Percent complete: 71.7%; Average loss: 2.1746\n",
      "Iteration: 2869; Percent complete: 71.7%; Average loss: 2.4164\n",
      "Iteration: 2870; Percent complete: 71.8%; Average loss: 2.4023\n",
      "Iteration: 2871; Percent complete: 71.8%; Average loss: 2.2486\n",
      "Iteration: 2872; Percent complete: 71.8%; Average loss: 2.3644\n",
      "Iteration: 2873; Percent complete: 71.8%; Average loss: 2.2462\n",
      "Iteration: 2874; Percent complete: 71.9%; Average loss: 2.4581\n",
      "Iteration: 2875; Percent complete: 71.9%; Average loss: 2.4858\n",
      "Iteration: 2876; Percent complete: 71.9%; Average loss: 2.5399\n",
      "Iteration: 2877; Percent complete: 71.9%; Average loss: 2.5795\n",
      "Iteration: 2878; Percent complete: 72.0%; Average loss: 2.3765\n",
      "Iteration: 2879; Percent complete: 72.0%; Average loss: 2.2852\n",
      "Iteration: 2880; Percent complete: 72.0%; Average loss: 2.2945\n",
      "Iteration: 2881; Percent complete: 72.0%; Average loss: 2.4123\n",
      "Iteration: 2882; Percent complete: 72.0%; Average loss: 2.4362\n",
      "Iteration: 2883; Percent complete: 72.1%; Average loss: 2.3558\n",
      "Iteration: 2884; Percent complete: 72.1%; Average loss: 2.3218\n",
      "Iteration: 2885; Percent complete: 72.1%; Average loss: 2.4878\n",
      "Iteration: 2886; Percent complete: 72.2%; Average loss: 2.4386\n",
      "Iteration: 2887; Percent complete: 72.2%; Average loss: 2.5370\n",
      "Iteration: 2888; Percent complete: 72.2%; Average loss: 2.4660\n",
      "Iteration: 2889; Percent complete: 72.2%; Average loss: 2.3693\n",
      "Iteration: 2890; Percent complete: 72.2%; Average loss: 2.1788\n",
      "Iteration: 2891; Percent complete: 72.3%; Average loss: 2.4901\n",
      "Iteration: 2892; Percent complete: 72.3%; Average loss: 2.5387\n",
      "Iteration: 2893; Percent complete: 72.3%; Average loss: 2.5817\n",
      "Iteration: 2894; Percent complete: 72.4%; Average loss: 2.3410\n",
      "Iteration: 2895; Percent complete: 72.4%; Average loss: 2.4885\n",
      "Iteration: 2896; Percent complete: 72.4%; Average loss: 2.2607\n",
      "Iteration: 2897; Percent complete: 72.4%; Average loss: 2.2870\n",
      "Iteration: 2898; Percent complete: 72.5%; Average loss: 2.3663\n",
      "Iteration: 2899; Percent complete: 72.5%; Average loss: 2.2987\n",
      "Iteration: 2900; Percent complete: 72.5%; Average loss: 2.3887\n",
      "Iteration: 2901; Percent complete: 72.5%; Average loss: 2.1151\n",
      "Iteration: 2902; Percent complete: 72.5%; Average loss: 2.3648\n",
      "Iteration: 2903; Percent complete: 72.6%; Average loss: 2.5305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2904; Percent complete: 72.6%; Average loss: 2.3350\n",
      "Iteration: 2905; Percent complete: 72.6%; Average loss: 2.5220\n",
      "Iteration: 2906; Percent complete: 72.7%; Average loss: 2.2477\n",
      "Iteration: 2907; Percent complete: 72.7%; Average loss: 2.5330\n",
      "Iteration: 2908; Percent complete: 72.7%; Average loss: 2.8788\n",
      "Iteration: 2909; Percent complete: 72.7%; Average loss: 2.5529\n",
      "Iteration: 2910; Percent complete: 72.8%; Average loss: 2.3615\n",
      "Iteration: 2911; Percent complete: 72.8%; Average loss: 2.3160\n",
      "Iteration: 2912; Percent complete: 72.8%; Average loss: 2.4622\n",
      "Iteration: 2913; Percent complete: 72.8%; Average loss: 2.4126\n",
      "Iteration: 2914; Percent complete: 72.9%; Average loss: 2.4375\n",
      "Iteration: 2915; Percent complete: 72.9%; Average loss: 2.4524\n",
      "Iteration: 2916; Percent complete: 72.9%; Average loss: 2.3845\n",
      "Iteration: 2917; Percent complete: 72.9%; Average loss: 2.4070\n",
      "Iteration: 2918; Percent complete: 73.0%; Average loss: 2.3127\n",
      "Iteration: 2919; Percent complete: 73.0%; Average loss: 2.3811\n",
      "Iteration: 2920; Percent complete: 73.0%; Average loss: 2.2804\n",
      "Iteration: 2921; Percent complete: 73.0%; Average loss: 2.2415\n",
      "Iteration: 2922; Percent complete: 73.0%; Average loss: 2.3033\n",
      "Iteration: 2923; Percent complete: 73.1%; Average loss: 2.4030\n",
      "Iteration: 2924; Percent complete: 73.1%; Average loss: 2.5067\n",
      "Iteration: 2925; Percent complete: 73.1%; Average loss: 2.5207\n",
      "Iteration: 2926; Percent complete: 73.2%; Average loss: 2.4013\n",
      "Iteration: 2927; Percent complete: 73.2%; Average loss: 2.4139\n",
      "Iteration: 2928; Percent complete: 73.2%; Average loss: 2.3711\n",
      "Iteration: 2929; Percent complete: 73.2%; Average loss: 2.4364\n",
      "Iteration: 2930; Percent complete: 73.2%; Average loss: 2.2945\n",
      "Iteration: 2931; Percent complete: 73.3%; Average loss: 2.4656\n",
      "Iteration: 2932; Percent complete: 73.3%; Average loss: 2.4768\n",
      "Iteration: 2933; Percent complete: 73.3%; Average loss: 2.4062\n",
      "Iteration: 2934; Percent complete: 73.4%; Average loss: 2.3777\n",
      "Iteration: 2935; Percent complete: 73.4%; Average loss: 2.5227\n",
      "Iteration: 2936; Percent complete: 73.4%; Average loss: 2.2312\n",
      "Iteration: 2937; Percent complete: 73.4%; Average loss: 2.4409\n",
      "Iteration: 2938; Percent complete: 73.5%; Average loss: 2.2406\n",
      "Iteration: 2939; Percent complete: 73.5%; Average loss: 2.4939\n",
      "Iteration: 2940; Percent complete: 73.5%; Average loss: 2.5083\n",
      "Iteration: 2941; Percent complete: 73.5%; Average loss: 2.4321\n",
      "Iteration: 2942; Percent complete: 73.6%; Average loss: 2.2459\n",
      "Iteration: 2943; Percent complete: 73.6%; Average loss: 2.2901\n",
      "Iteration: 2944; Percent complete: 73.6%; Average loss: 2.3932\n",
      "Iteration: 2945; Percent complete: 73.6%; Average loss: 2.5790\n",
      "Iteration: 2946; Percent complete: 73.7%; Average loss: 2.3622\n",
      "Iteration: 2947; Percent complete: 73.7%; Average loss: 2.3141\n",
      "Iteration: 2948; Percent complete: 73.7%; Average loss: 2.4951\n",
      "Iteration: 2949; Percent complete: 73.7%; Average loss: 2.4654\n",
      "Iteration: 2950; Percent complete: 73.8%; Average loss: 2.3581\n",
      "Iteration: 2951; Percent complete: 73.8%; Average loss: 2.3704\n",
      "Iteration: 2952; Percent complete: 73.8%; Average loss: 2.5643\n",
      "Iteration: 2953; Percent complete: 73.8%; Average loss: 2.5754\n",
      "Iteration: 2954; Percent complete: 73.9%; Average loss: 2.3521\n",
      "Iteration: 2955; Percent complete: 73.9%; Average loss: 2.3389\n",
      "Iteration: 2956; Percent complete: 73.9%; Average loss: 2.4343\n",
      "Iteration: 2957; Percent complete: 73.9%; Average loss: 2.4836\n",
      "Iteration: 2958; Percent complete: 74.0%; Average loss: 2.5143\n",
      "Iteration: 2959; Percent complete: 74.0%; Average loss: 2.1490\n",
      "Iteration: 2960; Percent complete: 74.0%; Average loss: 2.4002\n",
      "Iteration: 2961; Percent complete: 74.0%; Average loss: 2.3602\n",
      "Iteration: 2962; Percent complete: 74.1%; Average loss: 2.3563\n",
      "Iteration: 2963; Percent complete: 74.1%; Average loss: 2.5741\n",
      "Iteration: 2964; Percent complete: 74.1%; Average loss: 2.3281\n",
      "Iteration: 2965; Percent complete: 74.1%; Average loss: 2.3575\n",
      "Iteration: 2966; Percent complete: 74.2%; Average loss: 2.3263\n",
      "Iteration: 2967; Percent complete: 74.2%; Average loss: 2.3824\n",
      "Iteration: 2968; Percent complete: 74.2%; Average loss: 2.5082\n",
      "Iteration: 2969; Percent complete: 74.2%; Average loss: 2.0878\n",
      "Iteration: 2970; Percent complete: 74.2%; Average loss: 2.4674\n",
      "Iteration: 2971; Percent complete: 74.3%; Average loss: 2.4026\n",
      "Iteration: 2972; Percent complete: 74.3%; Average loss: 2.2833\n",
      "Iteration: 2973; Percent complete: 74.3%; Average loss: 2.4663\n",
      "Iteration: 2974; Percent complete: 74.4%; Average loss: 2.2278\n",
      "Iteration: 2975; Percent complete: 74.4%; Average loss: 2.5105\n",
      "Iteration: 2976; Percent complete: 74.4%; Average loss: 2.3672\n",
      "Iteration: 2977; Percent complete: 74.4%; Average loss: 2.3924\n",
      "Iteration: 2978; Percent complete: 74.5%; Average loss: 2.2302\n",
      "Iteration: 2979; Percent complete: 74.5%; Average loss: 2.2613\n",
      "Iteration: 2980; Percent complete: 74.5%; Average loss: 2.2982\n",
      "Iteration: 2981; Percent complete: 74.5%; Average loss: 2.2780\n",
      "Iteration: 2982; Percent complete: 74.6%; Average loss: 2.3298\n",
      "Iteration: 2983; Percent complete: 74.6%; Average loss: 2.4311\n",
      "Iteration: 2984; Percent complete: 74.6%; Average loss: 2.2834\n",
      "Iteration: 2985; Percent complete: 74.6%; Average loss: 2.4234\n",
      "Iteration: 2986; Percent complete: 74.7%; Average loss: 2.6447\n",
      "Iteration: 2987; Percent complete: 74.7%; Average loss: 2.3391\n",
      "Iteration: 2988; Percent complete: 74.7%; Average loss: 2.5410\n",
      "Iteration: 2989; Percent complete: 74.7%; Average loss: 2.4772\n",
      "Iteration: 2990; Percent complete: 74.8%; Average loss: 2.3703\n",
      "Iteration: 2991; Percent complete: 74.8%; Average loss: 2.3651\n",
      "Iteration: 2992; Percent complete: 74.8%; Average loss: 2.4510\n",
      "Iteration: 2993; Percent complete: 74.8%; Average loss: 2.3098\n",
      "Iteration: 2994; Percent complete: 74.9%; Average loss: 2.4567\n",
      "Iteration: 2995; Percent complete: 74.9%; Average loss: 2.1375\n",
      "Iteration: 2996; Percent complete: 74.9%; Average loss: 2.3508\n",
      "Iteration: 2997; Percent complete: 74.9%; Average loss: 2.4069\n",
      "Iteration: 2998; Percent complete: 75.0%; Average loss: 2.3588\n",
      "Iteration: 2999; Percent complete: 75.0%; Average loss: 2.5578\n",
      "Iteration: 3000; Percent complete: 75.0%; Average loss: 2.4147\n",
      "Iteration: 3001; Percent complete: 75.0%; Average loss: 2.3318\n",
      "Iteration: 3002; Percent complete: 75.0%; Average loss: 2.6085\n",
      "Iteration: 3003; Percent complete: 75.1%; Average loss: 2.3001\n",
      "Iteration: 3004; Percent complete: 75.1%; Average loss: 2.4633\n",
      "Iteration: 3005; Percent complete: 75.1%; Average loss: 2.4137\n",
      "Iteration: 3006; Percent complete: 75.1%; Average loss: 2.3852\n",
      "Iteration: 3007; Percent complete: 75.2%; Average loss: 2.5581\n",
      "Iteration: 3008; Percent complete: 75.2%; Average loss: 2.3561\n",
      "Iteration: 3009; Percent complete: 75.2%; Average loss: 2.1079\n",
      "Iteration: 3010; Percent complete: 75.2%; Average loss: 2.2198\n",
      "Iteration: 3011; Percent complete: 75.3%; Average loss: 2.4311\n",
      "Iteration: 3012; Percent complete: 75.3%; Average loss: 2.4949\n",
      "Iteration: 3013; Percent complete: 75.3%; Average loss: 2.3993\n",
      "Iteration: 3014; Percent complete: 75.3%; Average loss: 2.1767\n",
      "Iteration: 3015; Percent complete: 75.4%; Average loss: 2.3068\n",
      "Iteration: 3016; Percent complete: 75.4%; Average loss: 2.2386\n",
      "Iteration: 3017; Percent complete: 75.4%; Average loss: 2.2438\n",
      "Iteration: 3018; Percent complete: 75.4%; Average loss: 2.4974\n",
      "Iteration: 3019; Percent complete: 75.5%; Average loss: 2.2411\n",
      "Iteration: 3020; Percent complete: 75.5%; Average loss: 2.3459\n",
      "Iteration: 3021; Percent complete: 75.5%; Average loss: 2.2411\n",
      "Iteration: 3022; Percent complete: 75.5%; Average loss: 2.3733\n",
      "Iteration: 3023; Percent complete: 75.6%; Average loss: 2.4664\n",
      "Iteration: 3024; Percent complete: 75.6%; Average loss: 2.2451\n",
      "Iteration: 3025; Percent complete: 75.6%; Average loss: 2.3637\n",
      "Iteration: 3026; Percent complete: 75.6%; Average loss: 2.5283\n",
      "Iteration: 3027; Percent complete: 75.7%; Average loss: 2.3697\n",
      "Iteration: 3028; Percent complete: 75.7%; Average loss: 2.4745\n",
      "Iteration: 3029; Percent complete: 75.7%; Average loss: 2.5053\n",
      "Iteration: 3030; Percent complete: 75.8%; Average loss: 2.5311\n",
      "Iteration: 3031; Percent complete: 75.8%; Average loss: 2.3098\n",
      "Iteration: 3032; Percent complete: 75.8%; Average loss: 2.4556\n",
      "Iteration: 3033; Percent complete: 75.8%; Average loss: 2.1903\n",
      "Iteration: 3034; Percent complete: 75.8%; Average loss: 2.3582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3035; Percent complete: 75.9%; Average loss: 2.4095\n",
      "Iteration: 3036; Percent complete: 75.9%; Average loss: 2.4238\n",
      "Iteration: 3037; Percent complete: 75.9%; Average loss: 2.5162\n",
      "Iteration: 3038; Percent complete: 75.9%; Average loss: 2.5724\n",
      "Iteration: 3039; Percent complete: 76.0%; Average loss: 2.3386\n",
      "Iteration: 3040; Percent complete: 76.0%; Average loss: 2.4108\n",
      "Iteration: 3041; Percent complete: 76.0%; Average loss: 2.3205\n",
      "Iteration: 3042; Percent complete: 76.0%; Average loss: 2.3724\n",
      "Iteration: 3043; Percent complete: 76.1%; Average loss: 2.4239\n",
      "Iteration: 3044; Percent complete: 76.1%; Average loss: 2.2469\n",
      "Iteration: 3045; Percent complete: 76.1%; Average loss: 2.2079\n",
      "Iteration: 3046; Percent complete: 76.1%; Average loss: 2.2799\n",
      "Iteration: 3047; Percent complete: 76.2%; Average loss: 2.1884\n",
      "Iteration: 3048; Percent complete: 76.2%; Average loss: 2.3691\n",
      "Iteration: 3049; Percent complete: 76.2%; Average loss: 2.2783\n",
      "Iteration: 3050; Percent complete: 76.2%; Average loss: 2.2954\n",
      "Iteration: 3051; Percent complete: 76.3%; Average loss: 2.4121\n",
      "Iteration: 3052; Percent complete: 76.3%; Average loss: 2.2728\n",
      "Iteration: 3053; Percent complete: 76.3%; Average loss: 2.3059\n",
      "Iteration: 3054; Percent complete: 76.3%; Average loss: 2.4256\n",
      "Iteration: 3055; Percent complete: 76.4%; Average loss: 2.2411\n",
      "Iteration: 3056; Percent complete: 76.4%; Average loss: 2.0790\n",
      "Iteration: 3057; Percent complete: 76.4%; Average loss: 2.2907\n",
      "Iteration: 3058; Percent complete: 76.4%; Average loss: 2.6171\n",
      "Iteration: 3059; Percent complete: 76.5%; Average loss: 2.4437\n",
      "Iteration: 3060; Percent complete: 76.5%; Average loss: 2.0519\n",
      "Iteration: 3061; Percent complete: 76.5%; Average loss: 2.3299\n",
      "Iteration: 3062; Percent complete: 76.5%; Average loss: 2.6506\n",
      "Iteration: 3063; Percent complete: 76.6%; Average loss: 2.4772\n",
      "Iteration: 3064; Percent complete: 76.6%; Average loss: 2.4261\n",
      "Iteration: 3065; Percent complete: 76.6%; Average loss: 2.6467\n",
      "Iteration: 3066; Percent complete: 76.6%; Average loss: 2.3333\n",
      "Iteration: 3067; Percent complete: 76.7%; Average loss: 2.2246\n",
      "Iteration: 3068; Percent complete: 76.7%; Average loss: 2.3817\n",
      "Iteration: 3069; Percent complete: 76.7%; Average loss: 2.4277\n",
      "Iteration: 3070; Percent complete: 76.8%; Average loss: 2.5108\n",
      "Iteration: 3071; Percent complete: 76.8%; Average loss: 2.3903\n",
      "Iteration: 3072; Percent complete: 76.8%; Average loss: 2.5691\n",
      "Iteration: 3073; Percent complete: 76.8%; Average loss: 2.3377\n",
      "Iteration: 3074; Percent complete: 76.8%; Average loss: 2.3123\n",
      "Iteration: 3075; Percent complete: 76.9%; Average loss: 2.5509\n",
      "Iteration: 3076; Percent complete: 76.9%; Average loss: 2.5754\n",
      "Iteration: 3077; Percent complete: 76.9%; Average loss: 2.4855\n",
      "Iteration: 3078; Percent complete: 77.0%; Average loss: 2.3483\n",
      "Iteration: 3079; Percent complete: 77.0%; Average loss: 2.2903\n",
      "Iteration: 3080; Percent complete: 77.0%; Average loss: 2.5692\n",
      "Iteration: 3081; Percent complete: 77.0%; Average loss: 2.3090\n",
      "Iteration: 3082; Percent complete: 77.0%; Average loss: 2.3960\n",
      "Iteration: 3083; Percent complete: 77.1%; Average loss: 2.5437\n",
      "Iteration: 3084; Percent complete: 77.1%; Average loss: 2.2112\n",
      "Iteration: 3085; Percent complete: 77.1%; Average loss: 2.2554\n",
      "Iteration: 3086; Percent complete: 77.1%; Average loss: 2.5019\n",
      "Iteration: 3087; Percent complete: 77.2%; Average loss: 2.3035\n",
      "Iteration: 3088; Percent complete: 77.2%; Average loss: 2.1514\n",
      "Iteration: 3089; Percent complete: 77.2%; Average loss: 2.5351\n",
      "Iteration: 3090; Percent complete: 77.2%; Average loss: 2.1563\n",
      "Iteration: 3091; Percent complete: 77.3%; Average loss: 2.1273\n",
      "Iteration: 3092; Percent complete: 77.3%; Average loss: 2.3670\n",
      "Iteration: 3093; Percent complete: 77.3%; Average loss: 2.3215\n",
      "Iteration: 3094; Percent complete: 77.3%; Average loss: 2.5221\n",
      "Iteration: 3095; Percent complete: 77.4%; Average loss: 2.2589\n",
      "Iteration: 3096; Percent complete: 77.4%; Average loss: 2.2965\n",
      "Iteration: 3097; Percent complete: 77.4%; Average loss: 2.3905\n",
      "Iteration: 3098; Percent complete: 77.5%; Average loss: 2.5681\n",
      "Iteration: 3099; Percent complete: 77.5%; Average loss: 2.3906\n",
      "Iteration: 3100; Percent complete: 77.5%; Average loss: 2.3238\n",
      "Iteration: 3101; Percent complete: 77.5%; Average loss: 2.5774\n",
      "Iteration: 3102; Percent complete: 77.5%; Average loss: 2.0422\n",
      "Iteration: 3103; Percent complete: 77.6%; Average loss: 2.2093\n",
      "Iteration: 3104; Percent complete: 77.6%; Average loss: 2.3785\n",
      "Iteration: 3105; Percent complete: 77.6%; Average loss: 2.2493\n",
      "Iteration: 3106; Percent complete: 77.6%; Average loss: 2.4245\n",
      "Iteration: 3107; Percent complete: 77.7%; Average loss: 2.5717\n",
      "Iteration: 3108; Percent complete: 77.7%; Average loss: 2.4164\n",
      "Iteration: 3109; Percent complete: 77.7%; Average loss: 2.3536\n",
      "Iteration: 3110; Percent complete: 77.8%; Average loss: 2.1583\n",
      "Iteration: 3111; Percent complete: 77.8%; Average loss: 2.4076\n",
      "Iteration: 3112; Percent complete: 77.8%; Average loss: 2.2316\n",
      "Iteration: 3113; Percent complete: 77.8%; Average loss: 2.3421\n",
      "Iteration: 3114; Percent complete: 77.8%; Average loss: 2.3252\n",
      "Iteration: 3115; Percent complete: 77.9%; Average loss: 2.4583\n",
      "Iteration: 3116; Percent complete: 77.9%; Average loss: 2.3734\n",
      "Iteration: 3117; Percent complete: 77.9%; Average loss: 2.3900\n",
      "Iteration: 3118; Percent complete: 78.0%; Average loss: 2.3192\n",
      "Iteration: 3119; Percent complete: 78.0%; Average loss: 2.4067\n",
      "Iteration: 3120; Percent complete: 78.0%; Average loss: 2.5131\n",
      "Iteration: 3121; Percent complete: 78.0%; Average loss: 2.2564\n",
      "Iteration: 3122; Percent complete: 78.0%; Average loss: 2.4207\n",
      "Iteration: 3123; Percent complete: 78.1%; Average loss: 2.4349\n",
      "Iteration: 3124; Percent complete: 78.1%; Average loss: 2.3784\n",
      "Iteration: 3125; Percent complete: 78.1%; Average loss: 2.3162\n",
      "Iteration: 3126; Percent complete: 78.1%; Average loss: 2.3219\n",
      "Iteration: 3127; Percent complete: 78.2%; Average loss: 2.4409\n",
      "Iteration: 3128; Percent complete: 78.2%; Average loss: 2.2269\n",
      "Iteration: 3129; Percent complete: 78.2%; Average loss: 2.3112\n",
      "Iteration: 3130; Percent complete: 78.2%; Average loss: 2.4020\n",
      "Iteration: 3131; Percent complete: 78.3%; Average loss: 2.5208\n",
      "Iteration: 3132; Percent complete: 78.3%; Average loss: 2.1766\n",
      "Iteration: 3133; Percent complete: 78.3%; Average loss: 2.4418\n",
      "Iteration: 3134; Percent complete: 78.3%; Average loss: 2.1963\n",
      "Iteration: 3135; Percent complete: 78.4%; Average loss: 2.3374\n",
      "Iteration: 3136; Percent complete: 78.4%; Average loss: 2.5294\n",
      "Iteration: 3137; Percent complete: 78.4%; Average loss: 2.1777\n",
      "Iteration: 3138; Percent complete: 78.5%; Average loss: 2.4624\n",
      "Iteration: 3139; Percent complete: 78.5%; Average loss: 2.4343\n",
      "Iteration: 3140; Percent complete: 78.5%; Average loss: 2.3179\n",
      "Iteration: 3141; Percent complete: 78.5%; Average loss: 2.3323\n",
      "Iteration: 3142; Percent complete: 78.5%; Average loss: 2.3687\n",
      "Iteration: 3143; Percent complete: 78.6%; Average loss: 2.5086\n",
      "Iteration: 3144; Percent complete: 78.6%; Average loss: 2.4637\n",
      "Iteration: 3145; Percent complete: 78.6%; Average loss: 2.2644\n",
      "Iteration: 3146; Percent complete: 78.6%; Average loss: 2.2136\n",
      "Iteration: 3147; Percent complete: 78.7%; Average loss: 2.3844\n",
      "Iteration: 3148; Percent complete: 78.7%; Average loss: 2.2637\n",
      "Iteration: 3149; Percent complete: 78.7%; Average loss: 2.3607\n",
      "Iteration: 3150; Percent complete: 78.8%; Average loss: 2.0272\n",
      "Iteration: 3151; Percent complete: 78.8%; Average loss: 2.6340\n",
      "Iteration: 3152; Percent complete: 78.8%; Average loss: 2.1117\n",
      "Iteration: 3153; Percent complete: 78.8%; Average loss: 2.4826\n",
      "Iteration: 3154; Percent complete: 78.8%; Average loss: 2.4716\n",
      "Iteration: 3155; Percent complete: 78.9%; Average loss: 2.3497\n",
      "Iteration: 3156; Percent complete: 78.9%; Average loss: 2.2727\n",
      "Iteration: 3157; Percent complete: 78.9%; Average loss: 2.6338\n",
      "Iteration: 3158; Percent complete: 79.0%; Average loss: 2.4608\n",
      "Iteration: 3159; Percent complete: 79.0%; Average loss: 2.1394\n",
      "Iteration: 3160; Percent complete: 79.0%; Average loss: 2.1726\n",
      "Iteration: 3161; Percent complete: 79.0%; Average loss: 2.4929\n",
      "Iteration: 3162; Percent complete: 79.0%; Average loss: 2.1813\n",
      "Iteration: 3163; Percent complete: 79.1%; Average loss: 2.5575\n",
      "Iteration: 3164; Percent complete: 79.1%; Average loss: 2.2789\n",
      "Iteration: 3165; Percent complete: 79.1%; Average loss: 2.2189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3166; Percent complete: 79.1%; Average loss: 2.3682\n",
      "Iteration: 3167; Percent complete: 79.2%; Average loss: 2.3336\n",
      "Iteration: 3168; Percent complete: 79.2%; Average loss: 2.2939\n",
      "Iteration: 3169; Percent complete: 79.2%; Average loss: 2.3207\n",
      "Iteration: 3170; Percent complete: 79.2%; Average loss: 2.2215\n",
      "Iteration: 3171; Percent complete: 79.3%; Average loss: 2.5763\n",
      "Iteration: 3172; Percent complete: 79.3%; Average loss: 2.2391\n",
      "Iteration: 3173; Percent complete: 79.3%; Average loss: 2.1355\n",
      "Iteration: 3174; Percent complete: 79.3%; Average loss: 2.4216\n",
      "Iteration: 3175; Percent complete: 79.4%; Average loss: 2.3437\n",
      "Iteration: 3176; Percent complete: 79.4%; Average loss: 2.5292\n",
      "Iteration: 3177; Percent complete: 79.4%; Average loss: 2.3919\n",
      "Iteration: 3178; Percent complete: 79.5%; Average loss: 2.2270\n",
      "Iteration: 3179; Percent complete: 79.5%; Average loss: 2.2934\n",
      "Iteration: 3180; Percent complete: 79.5%; Average loss: 2.3078\n",
      "Iteration: 3181; Percent complete: 79.5%; Average loss: 2.2212\n",
      "Iteration: 3182; Percent complete: 79.5%; Average loss: 2.4718\n",
      "Iteration: 3183; Percent complete: 79.6%; Average loss: 2.4952\n",
      "Iteration: 3184; Percent complete: 79.6%; Average loss: 2.0990\n",
      "Iteration: 3185; Percent complete: 79.6%; Average loss: 2.3952\n",
      "Iteration: 3186; Percent complete: 79.7%; Average loss: 2.1981\n",
      "Iteration: 3187; Percent complete: 79.7%; Average loss: 2.4787\n",
      "Iteration: 3188; Percent complete: 79.7%; Average loss: 2.4962\n",
      "Iteration: 3189; Percent complete: 79.7%; Average loss: 2.5741\n",
      "Iteration: 3190; Percent complete: 79.8%; Average loss: 2.2914\n",
      "Iteration: 3191; Percent complete: 79.8%; Average loss: 2.1547\n",
      "Iteration: 3192; Percent complete: 79.8%; Average loss: 2.5261\n",
      "Iteration: 3193; Percent complete: 79.8%; Average loss: 2.3026\n",
      "Iteration: 3194; Percent complete: 79.8%; Average loss: 2.5464\n",
      "Iteration: 3195; Percent complete: 79.9%; Average loss: 2.3634\n",
      "Iteration: 3196; Percent complete: 79.9%; Average loss: 2.4122\n",
      "Iteration: 3197; Percent complete: 79.9%; Average loss: 2.5288\n",
      "Iteration: 3198; Percent complete: 80.0%; Average loss: 2.1504\n",
      "Iteration: 3199; Percent complete: 80.0%; Average loss: 2.6181\n",
      "Iteration: 3200; Percent complete: 80.0%; Average loss: 2.3122\n",
      "Iteration: 3201; Percent complete: 80.0%; Average loss: 2.4488\n",
      "Iteration: 3202; Percent complete: 80.0%; Average loss: 2.3206\n",
      "Iteration: 3203; Percent complete: 80.1%; Average loss: 2.3010\n",
      "Iteration: 3204; Percent complete: 80.1%; Average loss: 2.5091\n",
      "Iteration: 3205; Percent complete: 80.1%; Average loss: 2.1999\n",
      "Iteration: 3206; Percent complete: 80.2%; Average loss: 2.5553\n",
      "Iteration: 3207; Percent complete: 80.2%; Average loss: 2.3103\n",
      "Iteration: 3208; Percent complete: 80.2%; Average loss: 2.0309\n",
      "Iteration: 3209; Percent complete: 80.2%; Average loss: 2.2298\n",
      "Iteration: 3210; Percent complete: 80.2%; Average loss: 2.3742\n",
      "Iteration: 3211; Percent complete: 80.3%; Average loss: 2.2391\n",
      "Iteration: 3212; Percent complete: 80.3%; Average loss: 2.2223\n",
      "Iteration: 3213; Percent complete: 80.3%; Average loss: 2.5364\n",
      "Iteration: 3214; Percent complete: 80.3%; Average loss: 2.3724\n",
      "Iteration: 3215; Percent complete: 80.4%; Average loss: 2.2640\n",
      "Iteration: 3216; Percent complete: 80.4%; Average loss: 2.1387\n",
      "Iteration: 3217; Percent complete: 80.4%; Average loss: 2.5368\n",
      "Iteration: 3218; Percent complete: 80.5%; Average loss: 2.5808\n",
      "Iteration: 3219; Percent complete: 80.5%; Average loss: 2.4423\n",
      "Iteration: 3220; Percent complete: 80.5%; Average loss: 2.3817\n",
      "Iteration: 3221; Percent complete: 80.5%; Average loss: 2.4157\n",
      "Iteration: 3222; Percent complete: 80.5%; Average loss: 2.3339\n",
      "Iteration: 3223; Percent complete: 80.6%; Average loss: 2.2905\n",
      "Iteration: 3224; Percent complete: 80.6%; Average loss: 2.5648\n",
      "Iteration: 3225; Percent complete: 80.6%; Average loss: 2.3706\n",
      "Iteration: 3226; Percent complete: 80.7%; Average loss: 2.5131\n",
      "Iteration: 3227; Percent complete: 80.7%; Average loss: 2.4534\n",
      "Iteration: 3228; Percent complete: 80.7%; Average loss: 2.3520\n",
      "Iteration: 3229; Percent complete: 80.7%; Average loss: 2.2285\n",
      "Iteration: 3230; Percent complete: 80.8%; Average loss: 2.2868\n",
      "Iteration: 3231; Percent complete: 80.8%; Average loss: 2.4172\n",
      "Iteration: 3232; Percent complete: 80.8%; Average loss: 2.4231\n",
      "Iteration: 3233; Percent complete: 80.8%; Average loss: 2.4212\n",
      "Iteration: 3234; Percent complete: 80.8%; Average loss: 2.4897\n",
      "Iteration: 3235; Percent complete: 80.9%; Average loss: 2.2446\n",
      "Iteration: 3236; Percent complete: 80.9%; Average loss: 2.1339\n",
      "Iteration: 3237; Percent complete: 80.9%; Average loss: 2.3393\n",
      "Iteration: 3238; Percent complete: 81.0%; Average loss: 2.0642\n",
      "Iteration: 3239; Percent complete: 81.0%; Average loss: 2.2153\n",
      "Iteration: 3240; Percent complete: 81.0%; Average loss: 2.2223\n",
      "Iteration: 3241; Percent complete: 81.0%; Average loss: 2.3527\n",
      "Iteration: 3242; Percent complete: 81.0%; Average loss: 2.6813\n",
      "Iteration: 3243; Percent complete: 81.1%; Average loss: 2.4185\n",
      "Iteration: 3244; Percent complete: 81.1%; Average loss: 2.2105\n",
      "Iteration: 3245; Percent complete: 81.1%; Average loss: 2.3444\n",
      "Iteration: 3246; Percent complete: 81.2%; Average loss: 2.4500\n",
      "Iteration: 3247; Percent complete: 81.2%; Average loss: 2.3858\n",
      "Iteration: 3248; Percent complete: 81.2%; Average loss: 2.3524\n",
      "Iteration: 3249; Percent complete: 81.2%; Average loss: 2.3197\n",
      "Iteration: 3250; Percent complete: 81.2%; Average loss: 2.2550\n",
      "Iteration: 3251; Percent complete: 81.3%; Average loss: 2.0033\n",
      "Iteration: 3252; Percent complete: 81.3%; Average loss: 2.4341\n",
      "Iteration: 3253; Percent complete: 81.3%; Average loss: 2.3162\n",
      "Iteration: 3254; Percent complete: 81.3%; Average loss: 2.2443\n",
      "Iteration: 3255; Percent complete: 81.4%; Average loss: 2.3778\n",
      "Iteration: 3256; Percent complete: 81.4%; Average loss: 2.3923\n",
      "Iteration: 3257; Percent complete: 81.4%; Average loss: 2.3946\n",
      "Iteration: 3258; Percent complete: 81.5%; Average loss: 2.1355\n",
      "Iteration: 3259; Percent complete: 81.5%; Average loss: 2.2883\n",
      "Iteration: 3260; Percent complete: 81.5%; Average loss: 2.3176\n",
      "Iteration: 3261; Percent complete: 81.5%; Average loss: 2.2879\n",
      "Iteration: 3262; Percent complete: 81.5%; Average loss: 2.3251\n",
      "Iteration: 3263; Percent complete: 81.6%; Average loss: 2.3795\n",
      "Iteration: 3264; Percent complete: 81.6%; Average loss: 2.5348\n",
      "Iteration: 3265; Percent complete: 81.6%; Average loss: 2.0625\n",
      "Iteration: 3266; Percent complete: 81.7%; Average loss: 2.4439\n",
      "Iteration: 3267; Percent complete: 81.7%; Average loss: 2.3275\n",
      "Iteration: 3268; Percent complete: 81.7%; Average loss: 2.3649\n",
      "Iteration: 3269; Percent complete: 81.7%; Average loss: 2.4564\n",
      "Iteration: 3270; Percent complete: 81.8%; Average loss: 2.3544\n",
      "Iteration: 3271; Percent complete: 81.8%; Average loss: 2.4541\n",
      "Iteration: 3272; Percent complete: 81.8%; Average loss: 2.1542\n",
      "Iteration: 3273; Percent complete: 81.8%; Average loss: 2.4803\n",
      "Iteration: 3274; Percent complete: 81.8%; Average loss: 2.0751\n",
      "Iteration: 3275; Percent complete: 81.9%; Average loss: 2.3472\n",
      "Iteration: 3276; Percent complete: 81.9%; Average loss: 2.1709\n",
      "Iteration: 3277; Percent complete: 81.9%; Average loss: 2.5865\n",
      "Iteration: 3278; Percent complete: 82.0%; Average loss: 2.4513\n",
      "Iteration: 3279; Percent complete: 82.0%; Average loss: 2.1745\n",
      "Iteration: 3280; Percent complete: 82.0%; Average loss: 2.2565\n",
      "Iteration: 3281; Percent complete: 82.0%; Average loss: 2.3115\n",
      "Iteration: 3282; Percent complete: 82.0%; Average loss: 2.2731\n",
      "Iteration: 3283; Percent complete: 82.1%; Average loss: 2.1487\n",
      "Iteration: 3284; Percent complete: 82.1%; Average loss: 2.1661\n",
      "Iteration: 3285; Percent complete: 82.1%; Average loss: 2.3108\n",
      "Iteration: 3286; Percent complete: 82.2%; Average loss: 2.1826\n",
      "Iteration: 3287; Percent complete: 82.2%; Average loss: 2.0873\n",
      "Iteration: 3288; Percent complete: 82.2%; Average loss: 2.2578\n",
      "Iteration: 3289; Percent complete: 82.2%; Average loss: 2.3412\n",
      "Iteration: 3290; Percent complete: 82.2%; Average loss: 2.3081\n",
      "Iteration: 3291; Percent complete: 82.3%; Average loss: 2.4017\n",
      "Iteration: 3292; Percent complete: 82.3%; Average loss: 2.2999\n",
      "Iteration: 3293; Percent complete: 82.3%; Average loss: 2.3505\n",
      "Iteration: 3294; Percent complete: 82.3%; Average loss: 2.5840\n",
      "Iteration: 3295; Percent complete: 82.4%; Average loss: 2.3016\n",
      "Iteration: 3296; Percent complete: 82.4%; Average loss: 2.3873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3297; Percent complete: 82.4%; Average loss: 2.2928\n",
      "Iteration: 3298; Percent complete: 82.5%; Average loss: 2.1248\n",
      "Iteration: 3299; Percent complete: 82.5%; Average loss: 2.2009\n",
      "Iteration: 3300; Percent complete: 82.5%; Average loss: 2.4196\n",
      "Iteration: 3301; Percent complete: 82.5%; Average loss: 2.2128\n",
      "Iteration: 3302; Percent complete: 82.5%; Average loss: 2.4077\n",
      "Iteration: 3303; Percent complete: 82.6%; Average loss: 2.3517\n",
      "Iteration: 3304; Percent complete: 82.6%; Average loss: 2.5449\n",
      "Iteration: 3305; Percent complete: 82.6%; Average loss: 2.2684\n",
      "Iteration: 3306; Percent complete: 82.7%; Average loss: 2.3427\n",
      "Iteration: 3307; Percent complete: 82.7%; Average loss: 2.4162\n",
      "Iteration: 3308; Percent complete: 82.7%; Average loss: 2.2571\n",
      "Iteration: 3309; Percent complete: 82.7%; Average loss: 2.2274\n",
      "Iteration: 3310; Percent complete: 82.8%; Average loss: 2.4206\n",
      "Iteration: 3311; Percent complete: 82.8%; Average loss: 2.3420\n",
      "Iteration: 3312; Percent complete: 82.8%; Average loss: 2.3619\n",
      "Iteration: 3313; Percent complete: 82.8%; Average loss: 2.3116\n",
      "Iteration: 3314; Percent complete: 82.8%; Average loss: 2.2287\n",
      "Iteration: 3315; Percent complete: 82.9%; Average loss: 2.4705\n",
      "Iteration: 3316; Percent complete: 82.9%; Average loss: 2.3008\n",
      "Iteration: 3317; Percent complete: 82.9%; Average loss: 2.3884\n",
      "Iteration: 3318; Percent complete: 83.0%; Average loss: 2.2686\n",
      "Iteration: 3319; Percent complete: 83.0%; Average loss: 2.5587\n",
      "Iteration: 3320; Percent complete: 83.0%; Average loss: 2.1590\n",
      "Iteration: 3321; Percent complete: 83.0%; Average loss: 2.2885\n",
      "Iteration: 3322; Percent complete: 83.0%; Average loss: 2.3580\n",
      "Iteration: 3323; Percent complete: 83.1%; Average loss: 2.3652\n",
      "Iteration: 3324; Percent complete: 83.1%; Average loss: 2.3423\n",
      "Iteration: 3325; Percent complete: 83.1%; Average loss: 2.3723\n",
      "Iteration: 3326; Percent complete: 83.2%; Average loss: 2.3129\n",
      "Iteration: 3327; Percent complete: 83.2%; Average loss: 2.2790\n",
      "Iteration: 3328; Percent complete: 83.2%; Average loss: 2.2427\n",
      "Iteration: 3329; Percent complete: 83.2%; Average loss: 2.2732\n",
      "Iteration: 3330; Percent complete: 83.2%; Average loss: 2.4104\n",
      "Iteration: 3331; Percent complete: 83.3%; Average loss: 2.3827\n",
      "Iteration: 3332; Percent complete: 83.3%; Average loss: 2.3726\n",
      "Iteration: 3333; Percent complete: 83.3%; Average loss: 2.3587\n",
      "Iteration: 3334; Percent complete: 83.4%; Average loss: 2.2936\n",
      "Iteration: 3335; Percent complete: 83.4%; Average loss: 2.2837\n",
      "Iteration: 3336; Percent complete: 83.4%; Average loss: 2.1271\n",
      "Iteration: 3337; Percent complete: 83.4%; Average loss: 2.1791\n",
      "Iteration: 3338; Percent complete: 83.5%; Average loss: 2.5240\n",
      "Iteration: 3339; Percent complete: 83.5%; Average loss: 2.4897\n",
      "Iteration: 3340; Percent complete: 83.5%; Average loss: 2.1900\n",
      "Iteration: 3341; Percent complete: 83.5%; Average loss: 2.2301\n",
      "Iteration: 3342; Percent complete: 83.5%; Average loss: 2.4302\n",
      "Iteration: 3343; Percent complete: 83.6%; Average loss: 2.2846\n",
      "Iteration: 3344; Percent complete: 83.6%; Average loss: 2.2023\n",
      "Iteration: 3345; Percent complete: 83.6%; Average loss: 2.2382\n",
      "Iteration: 3346; Percent complete: 83.7%; Average loss: 2.2472\n",
      "Iteration: 3347; Percent complete: 83.7%; Average loss: 2.2469\n",
      "Iteration: 3348; Percent complete: 83.7%; Average loss: 2.1327\n",
      "Iteration: 3349; Percent complete: 83.7%; Average loss: 2.3151\n",
      "Iteration: 3350; Percent complete: 83.8%; Average loss: 2.1713\n",
      "Iteration: 3351; Percent complete: 83.8%; Average loss: 2.4272\n",
      "Iteration: 3352; Percent complete: 83.8%; Average loss: 2.3722\n",
      "Iteration: 3353; Percent complete: 83.8%; Average loss: 2.3104\n",
      "Iteration: 3354; Percent complete: 83.9%; Average loss: 2.4271\n",
      "Iteration: 3355; Percent complete: 83.9%; Average loss: 2.2773\n",
      "Iteration: 3356; Percent complete: 83.9%; Average loss: 2.3783\n",
      "Iteration: 3357; Percent complete: 83.9%; Average loss: 2.4134\n",
      "Iteration: 3358; Percent complete: 84.0%; Average loss: 2.4072\n",
      "Iteration: 3359; Percent complete: 84.0%; Average loss: 2.1663\n",
      "Iteration: 3360; Percent complete: 84.0%; Average loss: 2.4782\n",
      "Iteration: 3361; Percent complete: 84.0%; Average loss: 2.0764\n",
      "Iteration: 3362; Percent complete: 84.0%; Average loss: 2.1938\n",
      "Iteration: 3363; Percent complete: 84.1%; Average loss: 2.3539\n",
      "Iteration: 3364; Percent complete: 84.1%; Average loss: 2.1141\n",
      "Iteration: 3365; Percent complete: 84.1%; Average loss: 2.2607\n",
      "Iteration: 3366; Percent complete: 84.2%; Average loss: 2.2957\n",
      "Iteration: 3367; Percent complete: 84.2%; Average loss: 2.3780\n",
      "Iteration: 3368; Percent complete: 84.2%; Average loss: 2.1168\n",
      "Iteration: 3369; Percent complete: 84.2%; Average loss: 2.2319\n",
      "Iteration: 3370; Percent complete: 84.2%; Average loss: 2.1697\n",
      "Iteration: 3371; Percent complete: 84.3%; Average loss: 2.0715\n",
      "Iteration: 3372; Percent complete: 84.3%; Average loss: 2.4372\n",
      "Iteration: 3373; Percent complete: 84.3%; Average loss: 2.4443\n",
      "Iteration: 3374; Percent complete: 84.4%; Average loss: 2.2789\n",
      "Iteration: 3375; Percent complete: 84.4%; Average loss: 2.2502\n",
      "Iteration: 3376; Percent complete: 84.4%; Average loss: 2.3719\n",
      "Iteration: 3377; Percent complete: 84.4%; Average loss: 2.2913\n",
      "Iteration: 3378; Percent complete: 84.5%; Average loss: 2.3746\n",
      "Iteration: 3379; Percent complete: 84.5%; Average loss: 2.1791\n",
      "Iteration: 3380; Percent complete: 84.5%; Average loss: 2.4423\n",
      "Iteration: 3381; Percent complete: 84.5%; Average loss: 1.9315\n",
      "Iteration: 3382; Percent complete: 84.5%; Average loss: 2.2456\n",
      "Iteration: 3383; Percent complete: 84.6%; Average loss: 2.0672\n",
      "Iteration: 3384; Percent complete: 84.6%; Average loss: 2.2556\n",
      "Iteration: 3385; Percent complete: 84.6%; Average loss: 2.0773\n",
      "Iteration: 3386; Percent complete: 84.7%; Average loss: 2.3537\n",
      "Iteration: 3387; Percent complete: 84.7%; Average loss: 2.5349\n",
      "Iteration: 3388; Percent complete: 84.7%; Average loss: 2.1515\n",
      "Iteration: 3389; Percent complete: 84.7%; Average loss: 2.4605\n",
      "Iteration: 3390; Percent complete: 84.8%; Average loss: 2.4687\n",
      "Iteration: 3391; Percent complete: 84.8%; Average loss: 2.5420\n",
      "Iteration: 3392; Percent complete: 84.8%; Average loss: 2.4164\n",
      "Iteration: 3393; Percent complete: 84.8%; Average loss: 2.5094\n",
      "Iteration: 3394; Percent complete: 84.9%; Average loss: 2.2731\n",
      "Iteration: 3395; Percent complete: 84.9%; Average loss: 2.2917\n",
      "Iteration: 3396; Percent complete: 84.9%; Average loss: 2.0495\n",
      "Iteration: 3397; Percent complete: 84.9%; Average loss: 2.4121\n",
      "Iteration: 3398; Percent complete: 85.0%; Average loss: 2.1769\n",
      "Iteration: 3399; Percent complete: 85.0%; Average loss: 2.4770\n",
      "Iteration: 3400; Percent complete: 85.0%; Average loss: 2.3083\n",
      "Iteration: 3401; Percent complete: 85.0%; Average loss: 2.2160\n",
      "Iteration: 3402; Percent complete: 85.0%; Average loss: 2.1631\n",
      "Iteration: 3403; Percent complete: 85.1%; Average loss: 2.3164\n",
      "Iteration: 3404; Percent complete: 85.1%; Average loss: 2.2134\n",
      "Iteration: 3405; Percent complete: 85.1%; Average loss: 2.5549\n",
      "Iteration: 3406; Percent complete: 85.2%; Average loss: 2.2524\n",
      "Iteration: 3407; Percent complete: 85.2%; Average loss: 2.2611\n",
      "Iteration: 3408; Percent complete: 85.2%; Average loss: 2.4680\n",
      "Iteration: 3409; Percent complete: 85.2%; Average loss: 2.0971\n",
      "Iteration: 3410; Percent complete: 85.2%; Average loss: 2.1607\n",
      "Iteration: 3411; Percent complete: 85.3%; Average loss: 2.4897\n",
      "Iteration: 3412; Percent complete: 85.3%; Average loss: 2.1960\n",
      "Iteration: 3413; Percent complete: 85.3%; Average loss: 2.3658\n",
      "Iteration: 3414; Percent complete: 85.4%; Average loss: 2.6671\n",
      "Iteration: 3415; Percent complete: 85.4%; Average loss: 2.2505\n",
      "Iteration: 3416; Percent complete: 85.4%; Average loss: 2.0910\n",
      "Iteration: 3417; Percent complete: 85.4%; Average loss: 2.2016\n",
      "Iteration: 3418; Percent complete: 85.5%; Average loss: 2.1065\n",
      "Iteration: 3419; Percent complete: 85.5%; Average loss: 2.3244\n",
      "Iteration: 3420; Percent complete: 85.5%; Average loss: 2.4221\n",
      "Iteration: 3421; Percent complete: 85.5%; Average loss: 2.2200\n",
      "Iteration: 3422; Percent complete: 85.5%; Average loss: 2.2617\n",
      "Iteration: 3423; Percent complete: 85.6%; Average loss: 2.1358\n",
      "Iteration: 3424; Percent complete: 85.6%; Average loss: 2.0328\n",
      "Iteration: 3425; Percent complete: 85.6%; Average loss: 2.3606\n",
      "Iteration: 3426; Percent complete: 85.7%; Average loss: 2.3702\n",
      "Iteration: 3427; Percent complete: 85.7%; Average loss: 2.1722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3428; Percent complete: 85.7%; Average loss: 2.2414\n",
      "Iteration: 3429; Percent complete: 85.7%; Average loss: 2.1524\n",
      "Iteration: 3430; Percent complete: 85.8%; Average loss: 2.3213\n",
      "Iteration: 3431; Percent complete: 85.8%; Average loss: 2.1352\n",
      "Iteration: 3432; Percent complete: 85.8%; Average loss: 2.3867\n",
      "Iteration: 3433; Percent complete: 85.8%; Average loss: 2.4225\n",
      "Iteration: 3434; Percent complete: 85.9%; Average loss: 2.4380\n",
      "Iteration: 3435; Percent complete: 85.9%; Average loss: 2.3294\n",
      "Iteration: 3436; Percent complete: 85.9%; Average loss: 2.3022\n",
      "Iteration: 3437; Percent complete: 85.9%; Average loss: 2.3618\n",
      "Iteration: 3438; Percent complete: 86.0%; Average loss: 2.3122\n",
      "Iteration: 3439; Percent complete: 86.0%; Average loss: 2.3045\n",
      "Iteration: 3440; Percent complete: 86.0%; Average loss: 2.1792\n",
      "Iteration: 3441; Percent complete: 86.0%; Average loss: 2.1593\n",
      "Iteration: 3442; Percent complete: 86.1%; Average loss: 2.1611\n",
      "Iteration: 3443; Percent complete: 86.1%; Average loss: 2.2947\n",
      "Iteration: 3444; Percent complete: 86.1%; Average loss: 1.9938\n",
      "Iteration: 3445; Percent complete: 86.1%; Average loss: 2.3261\n",
      "Iteration: 3446; Percent complete: 86.2%; Average loss: 2.3965\n",
      "Iteration: 3447; Percent complete: 86.2%; Average loss: 2.3955\n",
      "Iteration: 3448; Percent complete: 86.2%; Average loss: 2.4020\n",
      "Iteration: 3449; Percent complete: 86.2%; Average loss: 2.3612\n",
      "Iteration: 3450; Percent complete: 86.2%; Average loss: 2.2861\n",
      "Iteration: 3451; Percent complete: 86.3%; Average loss: 2.3904\n",
      "Iteration: 3452; Percent complete: 86.3%; Average loss: 2.5208\n",
      "Iteration: 3453; Percent complete: 86.3%; Average loss: 2.3519\n",
      "Iteration: 3454; Percent complete: 86.4%; Average loss: 2.2583\n",
      "Iteration: 3455; Percent complete: 86.4%; Average loss: 2.4154\n",
      "Iteration: 3456; Percent complete: 86.4%; Average loss: 2.0540\n",
      "Iteration: 3457; Percent complete: 86.4%; Average loss: 2.3663\n",
      "Iteration: 3458; Percent complete: 86.5%; Average loss: 2.4170\n",
      "Iteration: 3459; Percent complete: 86.5%; Average loss: 2.3662\n",
      "Iteration: 3460; Percent complete: 86.5%; Average loss: 2.1742\n",
      "Iteration: 3461; Percent complete: 86.5%; Average loss: 2.3294\n",
      "Iteration: 3462; Percent complete: 86.6%; Average loss: 2.4238\n",
      "Iteration: 3463; Percent complete: 86.6%; Average loss: 2.3431\n",
      "Iteration: 3464; Percent complete: 86.6%; Average loss: 2.3968\n",
      "Iteration: 3465; Percent complete: 86.6%; Average loss: 2.3794\n",
      "Iteration: 3466; Percent complete: 86.7%; Average loss: 2.4009\n",
      "Iteration: 3467; Percent complete: 86.7%; Average loss: 2.2476\n",
      "Iteration: 3468; Percent complete: 86.7%; Average loss: 2.1492\n",
      "Iteration: 3469; Percent complete: 86.7%; Average loss: 2.3245\n",
      "Iteration: 3470; Percent complete: 86.8%; Average loss: 2.2418\n",
      "Iteration: 3471; Percent complete: 86.8%; Average loss: 2.3636\n",
      "Iteration: 3472; Percent complete: 86.8%; Average loss: 2.3363\n",
      "Iteration: 3473; Percent complete: 86.8%; Average loss: 2.1894\n",
      "Iteration: 3474; Percent complete: 86.9%; Average loss: 2.2725\n",
      "Iteration: 3475; Percent complete: 86.9%; Average loss: 2.2779\n",
      "Iteration: 3476; Percent complete: 86.9%; Average loss: 2.2087\n",
      "Iteration: 3477; Percent complete: 86.9%; Average loss: 2.4282\n",
      "Iteration: 3478; Percent complete: 87.0%; Average loss: 2.1393\n",
      "Iteration: 3479; Percent complete: 87.0%; Average loss: 2.2357\n",
      "Iteration: 3480; Percent complete: 87.0%; Average loss: 2.1064\n",
      "Iteration: 3481; Percent complete: 87.0%; Average loss: 2.2406\n",
      "Iteration: 3482; Percent complete: 87.1%; Average loss: 2.2957\n",
      "Iteration: 3483; Percent complete: 87.1%; Average loss: 2.3813\n",
      "Iteration: 3484; Percent complete: 87.1%; Average loss: 2.5794\n",
      "Iteration: 3485; Percent complete: 87.1%; Average loss: 2.2823\n",
      "Iteration: 3486; Percent complete: 87.2%; Average loss: 2.2777\n",
      "Iteration: 3487; Percent complete: 87.2%; Average loss: 2.1560\n",
      "Iteration: 3488; Percent complete: 87.2%; Average loss: 2.2221\n",
      "Iteration: 3489; Percent complete: 87.2%; Average loss: 2.1475\n",
      "Iteration: 3490; Percent complete: 87.2%; Average loss: 2.3710\n",
      "Iteration: 3491; Percent complete: 87.3%; Average loss: 2.2966\n",
      "Iteration: 3492; Percent complete: 87.3%; Average loss: 2.2224\n",
      "Iteration: 3493; Percent complete: 87.3%; Average loss: 2.3171\n",
      "Iteration: 3494; Percent complete: 87.4%; Average loss: 2.2897\n",
      "Iteration: 3495; Percent complete: 87.4%; Average loss: 2.1894\n",
      "Iteration: 3496; Percent complete: 87.4%; Average loss: 2.3042\n",
      "Iteration: 3497; Percent complete: 87.4%; Average loss: 2.3845\n",
      "Iteration: 3498; Percent complete: 87.5%; Average loss: 2.4048\n",
      "Iteration: 3499; Percent complete: 87.5%; Average loss: 2.3148\n",
      "Iteration: 3500; Percent complete: 87.5%; Average loss: 2.3588\n",
      "Iteration: 3501; Percent complete: 87.5%; Average loss: 2.1065\n",
      "Iteration: 3502; Percent complete: 87.5%; Average loss: 2.2466\n",
      "Iteration: 3503; Percent complete: 87.6%; Average loss: 2.3488\n",
      "Iteration: 3504; Percent complete: 87.6%; Average loss: 2.3865\n",
      "Iteration: 3505; Percent complete: 87.6%; Average loss: 2.1805\n",
      "Iteration: 3506; Percent complete: 87.6%; Average loss: 2.1836\n",
      "Iteration: 3507; Percent complete: 87.7%; Average loss: 2.2532\n",
      "Iteration: 3508; Percent complete: 87.7%; Average loss: 2.2435\n",
      "Iteration: 3509; Percent complete: 87.7%; Average loss: 2.2746\n",
      "Iteration: 3510; Percent complete: 87.8%; Average loss: 2.1923\n",
      "Iteration: 3511; Percent complete: 87.8%; Average loss: 2.2944\n",
      "Iteration: 3512; Percent complete: 87.8%; Average loss: 2.2053\n",
      "Iteration: 3513; Percent complete: 87.8%; Average loss: 2.2338\n",
      "Iteration: 3514; Percent complete: 87.8%; Average loss: 2.5088\n",
      "Iteration: 3515; Percent complete: 87.9%; Average loss: 2.1528\n",
      "Iteration: 3516; Percent complete: 87.9%; Average loss: 2.2312\n",
      "Iteration: 3517; Percent complete: 87.9%; Average loss: 2.0131\n",
      "Iteration: 3518; Percent complete: 87.9%; Average loss: 2.2761\n",
      "Iteration: 3519; Percent complete: 88.0%; Average loss: 2.3922\n",
      "Iteration: 3520; Percent complete: 88.0%; Average loss: 2.1315\n",
      "Iteration: 3521; Percent complete: 88.0%; Average loss: 2.2615\n",
      "Iteration: 3522; Percent complete: 88.0%; Average loss: 2.3116\n",
      "Iteration: 3523; Percent complete: 88.1%; Average loss: 2.1162\n",
      "Iteration: 3524; Percent complete: 88.1%; Average loss: 2.0741\n",
      "Iteration: 3525; Percent complete: 88.1%; Average loss: 2.3004\n",
      "Iteration: 3526; Percent complete: 88.1%; Average loss: 2.2061\n",
      "Iteration: 3527; Percent complete: 88.2%; Average loss: 2.0773\n",
      "Iteration: 3528; Percent complete: 88.2%; Average loss: 1.9903\n",
      "Iteration: 3529; Percent complete: 88.2%; Average loss: 2.0000\n",
      "Iteration: 3530; Percent complete: 88.2%; Average loss: 2.1691\n",
      "Iteration: 3531; Percent complete: 88.3%; Average loss: 2.2471\n",
      "Iteration: 3532; Percent complete: 88.3%; Average loss: 2.2220\n",
      "Iteration: 3533; Percent complete: 88.3%; Average loss: 2.2562\n",
      "Iteration: 3534; Percent complete: 88.3%; Average loss: 2.1850\n",
      "Iteration: 3535; Percent complete: 88.4%; Average loss: 2.1575\n",
      "Iteration: 3536; Percent complete: 88.4%; Average loss: 2.1504\n",
      "Iteration: 3537; Percent complete: 88.4%; Average loss: 2.4715\n",
      "Iteration: 3538; Percent complete: 88.4%; Average loss: 2.3326\n",
      "Iteration: 3539; Percent complete: 88.5%; Average loss: 2.4584\n",
      "Iteration: 3540; Percent complete: 88.5%; Average loss: 2.2398\n",
      "Iteration: 3541; Percent complete: 88.5%; Average loss: 2.2459\n",
      "Iteration: 3542; Percent complete: 88.5%; Average loss: 2.1554\n",
      "Iteration: 3543; Percent complete: 88.6%; Average loss: 2.0917\n",
      "Iteration: 3544; Percent complete: 88.6%; Average loss: 2.2513\n",
      "Iteration: 3545; Percent complete: 88.6%; Average loss: 2.3137\n",
      "Iteration: 3546; Percent complete: 88.6%; Average loss: 2.2283\n",
      "Iteration: 3547; Percent complete: 88.7%; Average loss: 2.0782\n",
      "Iteration: 3548; Percent complete: 88.7%; Average loss: 2.1238\n",
      "Iteration: 3549; Percent complete: 88.7%; Average loss: 2.4643\n",
      "Iteration: 3550; Percent complete: 88.8%; Average loss: 2.2463\n",
      "Iteration: 3551; Percent complete: 88.8%; Average loss: 2.1172\n",
      "Iteration: 3552; Percent complete: 88.8%; Average loss: 2.1244\n",
      "Iteration: 3553; Percent complete: 88.8%; Average loss: 2.3200\n",
      "Iteration: 3554; Percent complete: 88.8%; Average loss: 2.3378\n",
      "Iteration: 3555; Percent complete: 88.9%; Average loss: 2.4456\n",
      "Iteration: 3556; Percent complete: 88.9%; Average loss: 2.0785\n",
      "Iteration: 3557; Percent complete: 88.9%; Average loss: 2.3603\n",
      "Iteration: 3558; Percent complete: 88.9%; Average loss: 2.0601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3559; Percent complete: 89.0%; Average loss: 2.1991\n",
      "Iteration: 3560; Percent complete: 89.0%; Average loss: 2.3868\n",
      "Iteration: 3561; Percent complete: 89.0%; Average loss: 2.2613\n",
      "Iteration: 3562; Percent complete: 89.0%; Average loss: 2.1725\n",
      "Iteration: 3563; Percent complete: 89.1%; Average loss: 2.1583\n",
      "Iteration: 3564; Percent complete: 89.1%; Average loss: 2.1248\n",
      "Iteration: 3565; Percent complete: 89.1%; Average loss: 2.3328\n",
      "Iteration: 3566; Percent complete: 89.1%; Average loss: 2.2688\n",
      "Iteration: 3567; Percent complete: 89.2%; Average loss: 2.3447\n",
      "Iteration: 3568; Percent complete: 89.2%; Average loss: 2.1629\n",
      "Iteration: 3569; Percent complete: 89.2%; Average loss: 2.3799\n",
      "Iteration: 3570; Percent complete: 89.2%; Average loss: 2.1816\n",
      "Iteration: 3571; Percent complete: 89.3%; Average loss: 2.3387\n",
      "Iteration: 3572; Percent complete: 89.3%; Average loss: 2.2473\n",
      "Iteration: 3573; Percent complete: 89.3%; Average loss: 2.1285\n",
      "Iteration: 3574; Percent complete: 89.3%; Average loss: 2.2253\n",
      "Iteration: 3575; Percent complete: 89.4%; Average loss: 2.2354\n",
      "Iteration: 3576; Percent complete: 89.4%; Average loss: 2.2844\n",
      "Iteration: 3577; Percent complete: 89.4%; Average loss: 2.2515\n",
      "Iteration: 3578; Percent complete: 89.5%; Average loss: 2.3963\n",
      "Iteration: 3579; Percent complete: 89.5%; Average loss: 2.3125\n",
      "Iteration: 3580; Percent complete: 89.5%; Average loss: 2.2808\n",
      "Iteration: 3581; Percent complete: 89.5%; Average loss: 2.2168\n",
      "Iteration: 3582; Percent complete: 89.5%; Average loss: 2.4245\n",
      "Iteration: 3583; Percent complete: 89.6%; Average loss: 2.2081\n",
      "Iteration: 3584; Percent complete: 89.6%; Average loss: 2.2161\n",
      "Iteration: 3585; Percent complete: 89.6%; Average loss: 2.2033\n",
      "Iteration: 3586; Percent complete: 89.6%; Average loss: 2.0376\n",
      "Iteration: 3587; Percent complete: 89.7%; Average loss: 2.1145\n",
      "Iteration: 3588; Percent complete: 89.7%; Average loss: 2.4036\n",
      "Iteration: 3589; Percent complete: 89.7%; Average loss: 2.1541\n",
      "Iteration: 3590; Percent complete: 89.8%; Average loss: 2.2247\n",
      "Iteration: 3591; Percent complete: 89.8%; Average loss: 2.1142\n",
      "Iteration: 3592; Percent complete: 89.8%; Average loss: 2.3003\n",
      "Iteration: 3593; Percent complete: 89.8%; Average loss: 2.3958\n",
      "Iteration: 3594; Percent complete: 89.8%; Average loss: 2.2033\n",
      "Iteration: 3595; Percent complete: 89.9%; Average loss: 2.1148\n",
      "Iteration: 3596; Percent complete: 89.9%; Average loss: 2.0238\n",
      "Iteration: 3597; Percent complete: 89.9%; Average loss: 2.2414\n",
      "Iteration: 3598; Percent complete: 90.0%; Average loss: 2.2620\n",
      "Iteration: 3599; Percent complete: 90.0%; Average loss: 2.3140\n",
      "Iteration: 3600; Percent complete: 90.0%; Average loss: 2.2424\n",
      "Iteration: 3601; Percent complete: 90.0%; Average loss: 2.2397\n",
      "Iteration: 3602; Percent complete: 90.0%; Average loss: 2.3850\n",
      "Iteration: 3603; Percent complete: 90.1%; Average loss: 2.2806\n",
      "Iteration: 3604; Percent complete: 90.1%; Average loss: 2.2991\n",
      "Iteration: 3605; Percent complete: 90.1%; Average loss: 2.1286\n",
      "Iteration: 3606; Percent complete: 90.1%; Average loss: 2.2848\n",
      "Iteration: 3607; Percent complete: 90.2%; Average loss: 2.3407\n",
      "Iteration: 3608; Percent complete: 90.2%; Average loss: 2.2918\n",
      "Iteration: 3609; Percent complete: 90.2%; Average loss: 1.9845\n",
      "Iteration: 3610; Percent complete: 90.2%; Average loss: 2.1592\n",
      "Iteration: 3611; Percent complete: 90.3%; Average loss: 2.0643\n",
      "Iteration: 3612; Percent complete: 90.3%; Average loss: 2.3392\n",
      "Iteration: 3613; Percent complete: 90.3%; Average loss: 2.4030\n",
      "Iteration: 3614; Percent complete: 90.3%; Average loss: 2.2334\n",
      "Iteration: 3615; Percent complete: 90.4%; Average loss: 2.2918\n",
      "Iteration: 3616; Percent complete: 90.4%; Average loss: 2.4726\n",
      "Iteration: 3617; Percent complete: 90.4%; Average loss: 2.4881\n",
      "Iteration: 3618; Percent complete: 90.5%; Average loss: 2.1320\n",
      "Iteration: 3619; Percent complete: 90.5%; Average loss: 2.3811\n",
      "Iteration: 3620; Percent complete: 90.5%; Average loss: 2.1955\n",
      "Iteration: 3621; Percent complete: 90.5%; Average loss: 2.1030\n",
      "Iteration: 3622; Percent complete: 90.5%; Average loss: 2.3546\n",
      "Iteration: 3623; Percent complete: 90.6%; Average loss: 2.2266\n",
      "Iteration: 3624; Percent complete: 90.6%; Average loss: 2.3240\n",
      "Iteration: 3625; Percent complete: 90.6%; Average loss: 2.2338\n",
      "Iteration: 3626; Percent complete: 90.6%; Average loss: 2.1724\n",
      "Iteration: 3627; Percent complete: 90.7%; Average loss: 2.2785\n",
      "Iteration: 3628; Percent complete: 90.7%; Average loss: 2.2657\n",
      "Iteration: 3629; Percent complete: 90.7%; Average loss: 2.2724\n",
      "Iteration: 3630; Percent complete: 90.8%; Average loss: 2.2447\n",
      "Iteration: 3631; Percent complete: 90.8%; Average loss: 2.1472\n",
      "Iteration: 3632; Percent complete: 90.8%; Average loss: 2.2057\n",
      "Iteration: 3633; Percent complete: 90.8%; Average loss: 2.2559\n",
      "Iteration: 3634; Percent complete: 90.8%; Average loss: 2.2812\n",
      "Iteration: 3635; Percent complete: 90.9%; Average loss: 2.2779\n",
      "Iteration: 3636; Percent complete: 90.9%; Average loss: 2.2893\n",
      "Iteration: 3637; Percent complete: 90.9%; Average loss: 2.3614\n",
      "Iteration: 3638; Percent complete: 91.0%; Average loss: 2.2085\n",
      "Iteration: 3639; Percent complete: 91.0%; Average loss: 2.4063\n",
      "Iteration: 3640; Percent complete: 91.0%; Average loss: 2.3269\n",
      "Iteration: 3641; Percent complete: 91.0%; Average loss: 2.3540\n",
      "Iteration: 3642; Percent complete: 91.0%; Average loss: 2.1384\n",
      "Iteration: 3643; Percent complete: 91.1%; Average loss: 2.3446\n",
      "Iteration: 3644; Percent complete: 91.1%; Average loss: 2.2073\n",
      "Iteration: 3645; Percent complete: 91.1%; Average loss: 2.2918\n",
      "Iteration: 3646; Percent complete: 91.1%; Average loss: 2.2347\n",
      "Iteration: 3647; Percent complete: 91.2%; Average loss: 1.9261\n",
      "Iteration: 3648; Percent complete: 91.2%; Average loss: 2.2885\n",
      "Iteration: 3649; Percent complete: 91.2%; Average loss: 2.3082\n",
      "Iteration: 3650; Percent complete: 91.2%; Average loss: 2.1802\n",
      "Iteration: 3651; Percent complete: 91.3%; Average loss: 2.3490\n",
      "Iteration: 3652; Percent complete: 91.3%; Average loss: 2.1952\n",
      "Iteration: 3653; Percent complete: 91.3%; Average loss: 2.0949\n",
      "Iteration: 3654; Percent complete: 91.3%; Average loss: 2.2009\n",
      "Iteration: 3655; Percent complete: 91.4%; Average loss: 2.1775\n",
      "Iteration: 3656; Percent complete: 91.4%; Average loss: 2.2287\n",
      "Iteration: 3657; Percent complete: 91.4%; Average loss: 2.0769\n",
      "Iteration: 3658; Percent complete: 91.5%; Average loss: 2.0994\n",
      "Iteration: 3659; Percent complete: 91.5%; Average loss: 2.1754\n",
      "Iteration: 3660; Percent complete: 91.5%; Average loss: 2.3681\n",
      "Iteration: 3661; Percent complete: 91.5%; Average loss: 2.4552\n",
      "Iteration: 3662; Percent complete: 91.5%; Average loss: 2.3079\n",
      "Iteration: 3663; Percent complete: 91.6%; Average loss: 2.1447\n",
      "Iteration: 3664; Percent complete: 91.6%; Average loss: 2.4575\n",
      "Iteration: 3665; Percent complete: 91.6%; Average loss: 2.2053\n",
      "Iteration: 3666; Percent complete: 91.6%; Average loss: 2.2493\n",
      "Iteration: 3667; Percent complete: 91.7%; Average loss: 2.2709\n",
      "Iteration: 3668; Percent complete: 91.7%; Average loss: 2.1317\n",
      "Iteration: 3669; Percent complete: 91.7%; Average loss: 2.2930\n",
      "Iteration: 3670; Percent complete: 91.8%; Average loss: 2.2584\n",
      "Iteration: 3671; Percent complete: 91.8%; Average loss: 2.0131\n",
      "Iteration: 3672; Percent complete: 91.8%; Average loss: 2.3218\n",
      "Iteration: 3673; Percent complete: 91.8%; Average loss: 2.0454\n",
      "Iteration: 3674; Percent complete: 91.8%; Average loss: 2.3364\n",
      "Iteration: 3675; Percent complete: 91.9%; Average loss: 2.1710\n",
      "Iteration: 3676; Percent complete: 91.9%; Average loss: 2.1374\n",
      "Iteration: 3677; Percent complete: 91.9%; Average loss: 2.1833\n",
      "Iteration: 3678; Percent complete: 92.0%; Average loss: 2.2160\n",
      "Iteration: 3679; Percent complete: 92.0%; Average loss: 2.1908\n",
      "Iteration: 3680; Percent complete: 92.0%; Average loss: 2.1873\n",
      "Iteration: 3681; Percent complete: 92.0%; Average loss: 2.2820\n",
      "Iteration: 3682; Percent complete: 92.0%; Average loss: 2.1917\n",
      "Iteration: 3683; Percent complete: 92.1%; Average loss: 2.2673\n",
      "Iteration: 3684; Percent complete: 92.1%; Average loss: 2.1609\n",
      "Iteration: 3685; Percent complete: 92.1%; Average loss: 2.4586\n",
      "Iteration: 3686; Percent complete: 92.2%; Average loss: 2.1157\n",
      "Iteration: 3687; Percent complete: 92.2%; Average loss: 2.1874\n",
      "Iteration: 3688; Percent complete: 92.2%; Average loss: 2.1857\n",
      "Iteration: 3689; Percent complete: 92.2%; Average loss: 2.2845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3690; Percent complete: 92.2%; Average loss: 2.3145\n",
      "Iteration: 3691; Percent complete: 92.3%; Average loss: 2.1711\n",
      "Iteration: 3692; Percent complete: 92.3%; Average loss: 1.9841\n",
      "Iteration: 3693; Percent complete: 92.3%; Average loss: 2.1939\n",
      "Iteration: 3694; Percent complete: 92.3%; Average loss: 2.3371\n",
      "Iteration: 3695; Percent complete: 92.4%; Average loss: 2.5802\n",
      "Iteration: 3696; Percent complete: 92.4%; Average loss: 2.2222\n",
      "Iteration: 3697; Percent complete: 92.4%; Average loss: 2.3568\n",
      "Iteration: 3698; Percent complete: 92.5%; Average loss: 2.2976\n",
      "Iteration: 3699; Percent complete: 92.5%; Average loss: 2.0232\n",
      "Iteration: 3700; Percent complete: 92.5%; Average loss: 2.2164\n",
      "Iteration: 3701; Percent complete: 92.5%; Average loss: 2.2540\n",
      "Iteration: 3702; Percent complete: 92.5%; Average loss: 2.2515\n",
      "Iteration: 3703; Percent complete: 92.6%; Average loss: 2.0955\n",
      "Iteration: 3704; Percent complete: 92.6%; Average loss: 2.2004\n",
      "Iteration: 3705; Percent complete: 92.6%; Average loss: 2.2713\n",
      "Iteration: 3706; Percent complete: 92.7%; Average loss: 2.1038\n",
      "Iteration: 3707; Percent complete: 92.7%; Average loss: 2.3943\n",
      "Iteration: 3708; Percent complete: 92.7%; Average loss: 2.2056\n",
      "Iteration: 3709; Percent complete: 92.7%; Average loss: 2.0865\n",
      "Iteration: 3710; Percent complete: 92.8%; Average loss: 2.4668\n",
      "Iteration: 3711; Percent complete: 92.8%; Average loss: 2.1417\n",
      "Iteration: 3712; Percent complete: 92.8%; Average loss: 2.1813\n",
      "Iteration: 3713; Percent complete: 92.8%; Average loss: 2.1682\n",
      "Iteration: 3714; Percent complete: 92.8%; Average loss: 2.1421\n",
      "Iteration: 3715; Percent complete: 92.9%; Average loss: 2.1808\n",
      "Iteration: 3716; Percent complete: 92.9%; Average loss: 2.0384\n",
      "Iteration: 3717; Percent complete: 92.9%; Average loss: 1.8613\n",
      "Iteration: 3718; Percent complete: 93.0%; Average loss: 2.1915\n",
      "Iteration: 3719; Percent complete: 93.0%; Average loss: 2.2159\n",
      "Iteration: 3720; Percent complete: 93.0%; Average loss: 2.2464\n",
      "Iteration: 3721; Percent complete: 93.0%; Average loss: 2.2803\n",
      "Iteration: 3722; Percent complete: 93.0%; Average loss: 2.3005\n",
      "Iteration: 3723; Percent complete: 93.1%; Average loss: 2.3081\n",
      "Iteration: 3724; Percent complete: 93.1%; Average loss: 2.2507\n",
      "Iteration: 3725; Percent complete: 93.1%; Average loss: 2.1312\n",
      "Iteration: 3726; Percent complete: 93.2%; Average loss: 2.0347\n",
      "Iteration: 3727; Percent complete: 93.2%; Average loss: 2.1373\n",
      "Iteration: 3728; Percent complete: 93.2%; Average loss: 2.0849\n",
      "Iteration: 3729; Percent complete: 93.2%; Average loss: 2.2271\n",
      "Iteration: 3730; Percent complete: 93.2%; Average loss: 2.0292\n",
      "Iteration: 3731; Percent complete: 93.3%; Average loss: 2.1905\n",
      "Iteration: 3732; Percent complete: 93.3%; Average loss: 2.0579\n",
      "Iteration: 3733; Percent complete: 93.3%; Average loss: 2.2224\n",
      "Iteration: 3734; Percent complete: 93.3%; Average loss: 2.3427\n",
      "Iteration: 3735; Percent complete: 93.4%; Average loss: 2.1706\n",
      "Iteration: 3736; Percent complete: 93.4%; Average loss: 2.1851\n",
      "Iteration: 3737; Percent complete: 93.4%; Average loss: 2.2631\n",
      "Iteration: 3738; Percent complete: 93.5%; Average loss: 2.2182\n",
      "Iteration: 3739; Percent complete: 93.5%; Average loss: 2.2836\n",
      "Iteration: 3740; Percent complete: 93.5%; Average loss: 2.2401\n",
      "Iteration: 3741; Percent complete: 93.5%; Average loss: 2.3125\n",
      "Iteration: 3742; Percent complete: 93.5%; Average loss: 2.0865\n",
      "Iteration: 3743; Percent complete: 93.6%; Average loss: 2.0932\n",
      "Iteration: 3744; Percent complete: 93.6%; Average loss: 2.2912\n",
      "Iteration: 3745; Percent complete: 93.6%; Average loss: 2.2575\n",
      "Iteration: 3746; Percent complete: 93.7%; Average loss: 2.0750\n",
      "Iteration: 3747; Percent complete: 93.7%; Average loss: 2.1111\n",
      "Iteration: 3748; Percent complete: 93.7%; Average loss: 2.1496\n",
      "Iteration: 3749; Percent complete: 93.7%; Average loss: 2.2706\n",
      "Iteration: 3750; Percent complete: 93.8%; Average loss: 2.1800\n",
      "Iteration: 3751; Percent complete: 93.8%; Average loss: 2.1528\n",
      "Iteration: 3752; Percent complete: 93.8%; Average loss: 2.2019\n",
      "Iteration: 3753; Percent complete: 93.8%; Average loss: 2.2719\n",
      "Iteration: 3754; Percent complete: 93.8%; Average loss: 2.2788\n",
      "Iteration: 3755; Percent complete: 93.9%; Average loss: 2.1366\n",
      "Iteration: 3756; Percent complete: 93.9%; Average loss: 2.1354\n",
      "Iteration: 3757; Percent complete: 93.9%; Average loss: 2.3865\n",
      "Iteration: 3758; Percent complete: 94.0%; Average loss: 2.1471\n",
      "Iteration: 3759; Percent complete: 94.0%; Average loss: 2.1903\n",
      "Iteration: 3760; Percent complete: 94.0%; Average loss: 2.4276\n",
      "Iteration: 3761; Percent complete: 94.0%; Average loss: 2.2857\n",
      "Iteration: 3762; Percent complete: 94.0%; Average loss: 2.2099\n",
      "Iteration: 3763; Percent complete: 94.1%; Average loss: 2.3106\n",
      "Iteration: 3764; Percent complete: 94.1%; Average loss: 2.2395\n",
      "Iteration: 3765; Percent complete: 94.1%; Average loss: 2.2103\n",
      "Iteration: 3766; Percent complete: 94.2%; Average loss: 2.0387\n",
      "Iteration: 3767; Percent complete: 94.2%; Average loss: 2.1540\n",
      "Iteration: 3768; Percent complete: 94.2%; Average loss: 2.0350\n",
      "Iteration: 3769; Percent complete: 94.2%; Average loss: 2.5321\n",
      "Iteration: 3770; Percent complete: 94.2%; Average loss: 2.2116\n",
      "Iteration: 3771; Percent complete: 94.3%; Average loss: 2.2214\n",
      "Iteration: 3772; Percent complete: 94.3%; Average loss: 2.3264\n",
      "Iteration: 3773; Percent complete: 94.3%; Average loss: 2.1564\n",
      "Iteration: 3774; Percent complete: 94.3%; Average loss: 2.3424\n",
      "Iteration: 3775; Percent complete: 94.4%; Average loss: 2.3435\n",
      "Iteration: 3776; Percent complete: 94.4%; Average loss: 2.2214\n",
      "Iteration: 3777; Percent complete: 94.4%; Average loss: 2.1412\n",
      "Iteration: 3778; Percent complete: 94.5%; Average loss: 2.3316\n",
      "Iteration: 3779; Percent complete: 94.5%; Average loss: 2.1711\n",
      "Iteration: 3780; Percent complete: 94.5%; Average loss: 2.1260\n",
      "Iteration: 3781; Percent complete: 94.5%; Average loss: 2.2559\n",
      "Iteration: 3782; Percent complete: 94.5%; Average loss: 2.0905\n",
      "Iteration: 3783; Percent complete: 94.6%; Average loss: 2.2443\n",
      "Iteration: 3784; Percent complete: 94.6%; Average loss: 2.1381\n",
      "Iteration: 3785; Percent complete: 94.6%; Average loss: 2.1831\n",
      "Iteration: 3786; Percent complete: 94.7%; Average loss: 2.0815\n",
      "Iteration: 3787; Percent complete: 94.7%; Average loss: 2.1623\n",
      "Iteration: 3788; Percent complete: 94.7%; Average loss: 2.0275\n",
      "Iteration: 3789; Percent complete: 94.7%; Average loss: 2.2885\n",
      "Iteration: 3790; Percent complete: 94.8%; Average loss: 1.9567\n",
      "Iteration: 3791; Percent complete: 94.8%; Average loss: 2.3096\n",
      "Iteration: 3792; Percent complete: 94.8%; Average loss: 2.1169\n",
      "Iteration: 3793; Percent complete: 94.8%; Average loss: 2.2281\n",
      "Iteration: 3794; Percent complete: 94.8%; Average loss: 2.0256\n",
      "Iteration: 3795; Percent complete: 94.9%; Average loss: 2.4069\n",
      "Iteration: 3796; Percent complete: 94.9%; Average loss: 2.0737\n",
      "Iteration: 3797; Percent complete: 94.9%; Average loss: 2.1178\n",
      "Iteration: 3798; Percent complete: 95.0%; Average loss: 2.0353\n",
      "Iteration: 3799; Percent complete: 95.0%; Average loss: 2.1433\n",
      "Iteration: 3800; Percent complete: 95.0%; Average loss: 2.3210\n",
      "Iteration: 3801; Percent complete: 95.0%; Average loss: 2.2129\n",
      "Iteration: 3802; Percent complete: 95.0%; Average loss: 2.2256\n",
      "Iteration: 3803; Percent complete: 95.1%; Average loss: 2.1499\n",
      "Iteration: 3804; Percent complete: 95.1%; Average loss: 2.2569\n",
      "Iteration: 3805; Percent complete: 95.1%; Average loss: 2.0223\n",
      "Iteration: 3806; Percent complete: 95.2%; Average loss: 2.0416\n",
      "Iteration: 3807; Percent complete: 95.2%; Average loss: 2.0346\n",
      "Iteration: 3808; Percent complete: 95.2%; Average loss: 1.9603\n",
      "Iteration: 3809; Percent complete: 95.2%; Average loss: 2.1568\n",
      "Iteration: 3810; Percent complete: 95.2%; Average loss: 2.2851\n",
      "Iteration: 3811; Percent complete: 95.3%; Average loss: 2.1383\n",
      "Iteration: 3812; Percent complete: 95.3%; Average loss: 1.9998\n",
      "Iteration: 3813; Percent complete: 95.3%; Average loss: 2.0987\n",
      "Iteration: 3814; Percent complete: 95.3%; Average loss: 2.0687\n",
      "Iteration: 3815; Percent complete: 95.4%; Average loss: 2.1194\n",
      "Iteration: 3816; Percent complete: 95.4%; Average loss: 2.0387\n",
      "Iteration: 3817; Percent complete: 95.4%; Average loss: 2.3052\n",
      "Iteration: 3818; Percent complete: 95.5%; Average loss: 1.9595\n",
      "Iteration: 3819; Percent complete: 95.5%; Average loss: 2.3021\n",
      "Iteration: 3820; Percent complete: 95.5%; Average loss: 2.1797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3821; Percent complete: 95.5%; Average loss: 2.2645\n",
      "Iteration: 3822; Percent complete: 95.5%; Average loss: 2.0010\n",
      "Iteration: 3823; Percent complete: 95.6%; Average loss: 2.2654\n",
      "Iteration: 3824; Percent complete: 95.6%; Average loss: 2.1211\n",
      "Iteration: 3825; Percent complete: 95.6%; Average loss: 2.1202\n",
      "Iteration: 3826; Percent complete: 95.7%; Average loss: 2.2830\n",
      "Iteration: 3827; Percent complete: 95.7%; Average loss: 2.0870\n",
      "Iteration: 3828; Percent complete: 95.7%; Average loss: 2.1725\n",
      "Iteration: 3829; Percent complete: 95.7%; Average loss: 2.1127\n",
      "Iteration: 3830; Percent complete: 95.8%; Average loss: 1.8756\n",
      "Iteration: 3831; Percent complete: 95.8%; Average loss: 2.0835\n",
      "Iteration: 3832; Percent complete: 95.8%; Average loss: 2.2059\n",
      "Iteration: 3833; Percent complete: 95.8%; Average loss: 2.1514\n",
      "Iteration: 3834; Percent complete: 95.9%; Average loss: 2.2645\n",
      "Iteration: 3835; Percent complete: 95.9%; Average loss: 2.1595\n",
      "Iteration: 3836; Percent complete: 95.9%; Average loss: 2.2652\n",
      "Iteration: 3837; Percent complete: 95.9%; Average loss: 2.2296\n",
      "Iteration: 3838; Percent complete: 96.0%; Average loss: 2.1767\n",
      "Iteration: 3839; Percent complete: 96.0%; Average loss: 2.2155\n",
      "Iteration: 3840; Percent complete: 96.0%; Average loss: 2.1165\n",
      "Iteration: 3841; Percent complete: 96.0%; Average loss: 2.0941\n",
      "Iteration: 3842; Percent complete: 96.0%; Average loss: 2.3011\n",
      "Iteration: 3843; Percent complete: 96.1%; Average loss: 2.2039\n",
      "Iteration: 3844; Percent complete: 96.1%; Average loss: 2.0853\n",
      "Iteration: 3845; Percent complete: 96.1%; Average loss: 2.1730\n",
      "Iteration: 3846; Percent complete: 96.2%; Average loss: 2.3301\n",
      "Iteration: 3847; Percent complete: 96.2%; Average loss: 2.1309\n",
      "Iteration: 3848; Percent complete: 96.2%; Average loss: 2.3017\n",
      "Iteration: 3849; Percent complete: 96.2%; Average loss: 1.9707\n",
      "Iteration: 3850; Percent complete: 96.2%; Average loss: 2.2255\n",
      "Iteration: 3851; Percent complete: 96.3%; Average loss: 2.0688\n",
      "Iteration: 3852; Percent complete: 96.3%; Average loss: 1.9867\n",
      "Iteration: 3853; Percent complete: 96.3%; Average loss: 2.0434\n",
      "Iteration: 3854; Percent complete: 96.4%; Average loss: 2.1823\n",
      "Iteration: 3855; Percent complete: 96.4%; Average loss: 2.0834\n",
      "Iteration: 3856; Percent complete: 96.4%; Average loss: 2.3528\n",
      "Iteration: 3857; Percent complete: 96.4%; Average loss: 2.2937\n",
      "Iteration: 3858; Percent complete: 96.5%; Average loss: 2.3270\n",
      "Iteration: 3859; Percent complete: 96.5%; Average loss: 2.1744\n",
      "Iteration: 3860; Percent complete: 96.5%; Average loss: 2.1349\n",
      "Iteration: 3861; Percent complete: 96.5%; Average loss: 2.0254\n",
      "Iteration: 3862; Percent complete: 96.5%; Average loss: 2.2165\n",
      "Iteration: 3863; Percent complete: 96.6%; Average loss: 2.2466\n",
      "Iteration: 3864; Percent complete: 96.6%; Average loss: 2.1600\n",
      "Iteration: 3865; Percent complete: 96.6%; Average loss: 2.1876\n",
      "Iteration: 3866; Percent complete: 96.7%; Average loss: 2.0790\n",
      "Iteration: 3867; Percent complete: 96.7%; Average loss: 2.1367\n",
      "Iteration: 3868; Percent complete: 96.7%; Average loss: 2.0456\n",
      "Iteration: 3869; Percent complete: 96.7%; Average loss: 2.0436\n",
      "Iteration: 3870; Percent complete: 96.8%; Average loss: 2.1560\n",
      "Iteration: 3871; Percent complete: 96.8%; Average loss: 2.2079\n",
      "Iteration: 3872; Percent complete: 96.8%; Average loss: 2.1669\n",
      "Iteration: 3873; Percent complete: 96.8%; Average loss: 2.1296\n",
      "Iteration: 3874; Percent complete: 96.9%; Average loss: 2.1083\n",
      "Iteration: 3875; Percent complete: 96.9%; Average loss: 1.9967\n",
      "Iteration: 3876; Percent complete: 96.9%; Average loss: 2.1398\n",
      "Iteration: 3877; Percent complete: 96.9%; Average loss: 2.1280\n",
      "Iteration: 3878; Percent complete: 97.0%; Average loss: 2.3045\n",
      "Iteration: 3879; Percent complete: 97.0%; Average loss: 2.2323\n",
      "Iteration: 3880; Percent complete: 97.0%; Average loss: 2.2030\n",
      "Iteration: 3881; Percent complete: 97.0%; Average loss: 2.2063\n",
      "Iteration: 3882; Percent complete: 97.0%; Average loss: 2.4255\n",
      "Iteration: 3883; Percent complete: 97.1%; Average loss: 2.1104\n",
      "Iteration: 3884; Percent complete: 97.1%; Average loss: 2.1677\n",
      "Iteration: 3885; Percent complete: 97.1%; Average loss: 2.0718\n",
      "Iteration: 3886; Percent complete: 97.2%; Average loss: 2.1704\n",
      "Iteration: 3887; Percent complete: 97.2%; Average loss: 2.1447\n",
      "Iteration: 3888; Percent complete: 97.2%; Average loss: 2.1370\n",
      "Iteration: 3889; Percent complete: 97.2%; Average loss: 2.2054\n",
      "Iteration: 3890; Percent complete: 97.2%; Average loss: 2.3168\n",
      "Iteration: 3891; Percent complete: 97.3%; Average loss: 2.1081\n",
      "Iteration: 3892; Percent complete: 97.3%; Average loss: 2.2643\n",
      "Iteration: 3893; Percent complete: 97.3%; Average loss: 2.1246\n",
      "Iteration: 3894; Percent complete: 97.4%; Average loss: 2.0754\n",
      "Iteration: 3895; Percent complete: 97.4%; Average loss: 2.2235\n",
      "Iteration: 3896; Percent complete: 97.4%; Average loss: 2.1129\n",
      "Iteration: 3897; Percent complete: 97.4%; Average loss: 1.9216\n",
      "Iteration: 3898; Percent complete: 97.5%; Average loss: 2.2425\n",
      "Iteration: 3899; Percent complete: 97.5%; Average loss: 1.8809\n",
      "Iteration: 3900; Percent complete: 97.5%; Average loss: 2.4768\n",
      "Iteration: 3901; Percent complete: 97.5%; Average loss: 2.1309\n",
      "Iteration: 3902; Percent complete: 97.5%; Average loss: 2.2340\n",
      "Iteration: 3903; Percent complete: 97.6%; Average loss: 2.2089\n",
      "Iteration: 3904; Percent complete: 97.6%; Average loss: 2.0458\n",
      "Iteration: 3905; Percent complete: 97.6%; Average loss: 2.1672\n",
      "Iteration: 3906; Percent complete: 97.7%; Average loss: 2.0732\n",
      "Iteration: 3907; Percent complete: 97.7%; Average loss: 2.1716\n",
      "Iteration: 3908; Percent complete: 97.7%; Average loss: 2.1668\n",
      "Iteration: 3909; Percent complete: 97.7%; Average loss: 2.1517\n",
      "Iteration: 3910; Percent complete: 97.8%; Average loss: 2.1357\n",
      "Iteration: 3911; Percent complete: 97.8%; Average loss: 2.3144\n",
      "Iteration: 3912; Percent complete: 97.8%; Average loss: 2.1953\n",
      "Iteration: 3913; Percent complete: 97.8%; Average loss: 2.1672\n",
      "Iteration: 3914; Percent complete: 97.9%; Average loss: 2.0253\n",
      "Iteration: 3915; Percent complete: 97.9%; Average loss: 2.1396\n",
      "Iteration: 3916; Percent complete: 97.9%; Average loss: 1.9549\n",
      "Iteration: 3917; Percent complete: 97.9%; Average loss: 2.4775\n",
      "Iteration: 3918; Percent complete: 98.0%; Average loss: 2.2651\n",
      "Iteration: 3919; Percent complete: 98.0%; Average loss: 2.2767\n",
      "Iteration: 3920; Percent complete: 98.0%; Average loss: 2.0179\n",
      "Iteration: 3921; Percent complete: 98.0%; Average loss: 2.3382\n",
      "Iteration: 3922; Percent complete: 98.0%; Average loss: 2.3248\n",
      "Iteration: 3923; Percent complete: 98.1%; Average loss: 2.1743\n",
      "Iteration: 3924; Percent complete: 98.1%; Average loss: 2.0825\n",
      "Iteration: 3925; Percent complete: 98.1%; Average loss: 2.2383\n",
      "Iteration: 3926; Percent complete: 98.2%; Average loss: 2.1760\n",
      "Iteration: 3927; Percent complete: 98.2%; Average loss: 2.2521\n",
      "Iteration: 3928; Percent complete: 98.2%; Average loss: 2.2355\n",
      "Iteration: 3929; Percent complete: 98.2%; Average loss: 2.2628\n",
      "Iteration: 3930; Percent complete: 98.2%; Average loss: 2.2565\n",
      "Iteration: 3931; Percent complete: 98.3%; Average loss: 2.3010\n",
      "Iteration: 3932; Percent complete: 98.3%; Average loss: 2.2845\n",
      "Iteration: 3933; Percent complete: 98.3%; Average loss: 2.2873\n",
      "Iteration: 3934; Percent complete: 98.4%; Average loss: 2.2696\n",
      "Iteration: 3935; Percent complete: 98.4%; Average loss: 2.2622\n",
      "Iteration: 3936; Percent complete: 98.4%; Average loss: 2.1609\n",
      "Iteration: 3937; Percent complete: 98.4%; Average loss: 2.3430\n",
      "Iteration: 3938; Percent complete: 98.5%; Average loss: 2.0073\n",
      "Iteration: 3939; Percent complete: 98.5%; Average loss: 2.2913\n",
      "Iteration: 3940; Percent complete: 98.5%; Average loss: 2.2618\n",
      "Iteration: 3941; Percent complete: 98.5%; Average loss: 2.1183\n",
      "Iteration: 3942; Percent complete: 98.6%; Average loss: 2.1568\n",
      "Iteration: 3943; Percent complete: 98.6%; Average loss: 2.0996\n",
      "Iteration: 3944; Percent complete: 98.6%; Average loss: 2.1383\n",
      "Iteration: 3945; Percent complete: 98.6%; Average loss: 2.0804\n",
      "Iteration: 3946; Percent complete: 98.7%; Average loss: 2.0651\n",
      "Iteration: 3947; Percent complete: 98.7%; Average loss: 2.0734\n",
      "Iteration: 3948; Percent complete: 98.7%; Average loss: 2.2015\n",
      "Iteration: 3949; Percent complete: 98.7%; Average loss: 2.1653\n",
      "Iteration: 3950; Percent complete: 98.8%; Average loss: 2.2435\n",
      "Iteration: 3951; Percent complete: 98.8%; Average loss: 2.3389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3952; Percent complete: 98.8%; Average loss: 2.2334\n",
      "Iteration: 3953; Percent complete: 98.8%; Average loss: 2.0570\n",
      "Iteration: 3954; Percent complete: 98.9%; Average loss: 2.0885\n",
      "Iteration: 3955; Percent complete: 98.9%; Average loss: 2.2621\n",
      "Iteration: 3956; Percent complete: 98.9%; Average loss: 2.0722\n",
      "Iteration: 3957; Percent complete: 98.9%; Average loss: 2.2298\n",
      "Iteration: 3958; Percent complete: 99.0%; Average loss: 2.1677\n",
      "Iteration: 3959; Percent complete: 99.0%; Average loss: 2.0923\n",
      "Iteration: 3960; Percent complete: 99.0%; Average loss: 2.0396\n",
      "Iteration: 3961; Percent complete: 99.0%; Average loss: 2.1201\n",
      "Iteration: 3962; Percent complete: 99.1%; Average loss: 2.2592\n",
      "Iteration: 3963; Percent complete: 99.1%; Average loss: 2.4131\n",
      "Iteration: 3964; Percent complete: 99.1%; Average loss: 2.2232\n",
      "Iteration: 3965; Percent complete: 99.1%; Average loss: 2.1667\n",
      "Iteration: 3966; Percent complete: 99.2%; Average loss: 2.0066\n",
      "Iteration: 3967; Percent complete: 99.2%; Average loss: 2.1612\n",
      "Iteration: 3968; Percent complete: 99.2%; Average loss: 2.1849\n",
      "Iteration: 3969; Percent complete: 99.2%; Average loss: 2.0803\n",
      "Iteration: 3970; Percent complete: 99.2%; Average loss: 2.2196\n",
      "Iteration: 3971; Percent complete: 99.3%; Average loss: 2.2620\n",
      "Iteration: 3972; Percent complete: 99.3%; Average loss: 2.1734\n",
      "Iteration: 3973; Percent complete: 99.3%; Average loss: 2.2652\n",
      "Iteration: 3974; Percent complete: 99.4%; Average loss: 2.0669\n",
      "Iteration: 3975; Percent complete: 99.4%; Average loss: 2.0148\n",
      "Iteration: 3976; Percent complete: 99.4%; Average loss: 2.1167\n",
      "Iteration: 3977; Percent complete: 99.4%; Average loss: 2.1068\n",
      "Iteration: 3978; Percent complete: 99.5%; Average loss: 2.0120\n",
      "Iteration: 3979; Percent complete: 99.5%; Average loss: 2.1494\n",
      "Iteration: 3980; Percent complete: 99.5%; Average loss: 2.3231\n",
      "Iteration: 3981; Percent complete: 99.5%; Average loss: 2.2528\n",
      "Iteration: 3982; Percent complete: 99.6%; Average loss: 1.9743\n",
      "Iteration: 3983; Percent complete: 99.6%; Average loss: 2.1595\n",
      "Iteration: 3984; Percent complete: 99.6%; Average loss: 2.1699\n",
      "Iteration: 3985; Percent complete: 99.6%; Average loss: 2.2931\n",
      "Iteration: 3986; Percent complete: 99.7%; Average loss: 1.8141\n",
      "Iteration: 3987; Percent complete: 99.7%; Average loss: 2.2333\n",
      "Iteration: 3988; Percent complete: 99.7%; Average loss: 2.1798\n",
      "Iteration: 3989; Percent complete: 99.7%; Average loss: 2.3314\n",
      "Iteration: 3990; Percent complete: 99.8%; Average loss: 2.0668\n",
      "Iteration: 3991; Percent complete: 99.8%; Average loss: 2.1543\n",
      "Iteration: 3992; Percent complete: 99.8%; Average loss: 2.1733\n",
      "Iteration: 3993; Percent complete: 99.8%; Average loss: 2.0873\n",
      "Iteration: 3994; Percent complete: 99.9%; Average loss: 2.1991\n",
      "Iteration: 3995; Percent complete: 99.9%; Average loss: 2.1143\n",
      "Iteration: 3996; Percent complete: 99.9%; Average loss: 2.1262\n",
      "Iteration: 3997; Percent complete: 99.9%; Average loss: 1.9784\n",
      "Iteration: 3998; Percent complete: 100.0%; Average loss: 2.1328\n",
      "Iteration: 3999; Percent complete: 100.0%; Average loss: 2.0285\n",
      "Iteration: 4000; Percent complete: 100.0%; Average loss: 2.2019\n"
     ]
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 4000\n",
    "print_every = 1\n",
    "save_every = 500\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Hello babe\n",
      "Bot: hello .\n",
      "> What's your name?\n",
      "Bot: i m sorry .\n",
      "> Why are you sorry?\n",
      "Bot: because i m here .\n",
      "> Here for what?\n",
      "Bot: for what ?\n",
      "> what for?\n",
      "Bot: i don t know .\n",
      "> what do you know?\n",
      "Bot: i know .\n",
      "> know what?\n",
      "Bot: what ?\n",
      "> what?\n",
      "Bot: i m not hungry .\n",
      "> I'll make you an offer you cannot refuse\n",
      "Bot: i love you .\n",
      "> Why do you love me?\n",
      "Bot: because i love you .\n",
      "> What is philosophy?\n",
      "Bot: i don t know .\n",
      "> Courage is what I seek\n",
      "Bot: you re a good man .\n",
      "> What about you?\n",
      "Bot: i don t know .\n",
      "> Are you courageous?\n",
      "Error: Encountered unknown word.\n",
      "> Are you brave?\n",
      "Bot: yes .\n",
      "> Are you happy?\n",
      "Bot: i m fine .\n",
      "> Are you hungry?\n",
      "Bot: yes .\n",
      "> What would you like to eat?\n",
      "Bot: i don t know .\n",
      "> How about Chinese food?\n",
      "Bot: i m not .\n",
      "> What kind of food would you like to eat?\n",
      "Bot: i don t know .\n",
      "> Which nationality are you?\n",
      "Error: Encountered unknown word.\n",
      "> Which country are you from?\n",
      "Bot: yeah .\n",
      "> The football fell to the ground\n",
      "Bot: i m not asking you .\n",
      "> Where is the football?\n",
      "Bot: what ?\n",
      "> Where is the football\n",
      "Bot: what ?\n",
      "> The football is where?\n",
      "Bot: the other one .\n",
      "> Father to a murdered son\n",
      "Bot: yes .\n",
      "> Husband to murdered wife\n",
      "Bot: i m not hungry .\n",
      "> True warrior\n",
      "Bot: i m not hungry .\n",
      "> \n",
      "Bot: i m not hungry .\n",
      "> \n",
      "Bot: i m not hungry .\n",
      "> \n",
      "Bot: i m not hungry .\n",
      "> \n",
      "Bot: i m not hungry .\n",
      "> \n",
      "Bot: i m not hungry .\n",
      "> \n",
      "Bot: i m not hungry .\n",
      "> \n",
      "Bot: i m not hungry .\n",
      "> q\n"
     ]
    }
   ],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "evaluateInput(encoder, decoder, searcher, voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
