{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2, 1],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[2,2,1],[4,5,6]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n"
     ]
    }
   ],
   "source": [
    "print(a.shape[0],a.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.FloatTensor([[2,1,4],[3,5,4],[1,2,0],[4,3,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.tensor([2,2,1], dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([[2,1,4],[3,5,4],[1,2,0],[4,3,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [1],\n",
      "        [4],\n",
      "        [3],\n",
      "        [5],\n",
      "        [4],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [4],\n",
      "        [3],\n",
      "        [2]])\n",
      "tensor([2, 1, 4, 3, 5, 4, 1, 2, 0, 4, 3, 2])\n",
      "tensor([[2, 1, 4, 3],\n",
      "        [5, 4, 1, 2],\n",
      "        [0, 4, 3, 2]])\n",
      "tensor([[2, 1, 4, 3],\n",
      "        [5, 4, 1, 2],\n",
      "        [0, 4, 3, 2]])\n"
     ]
    }
   ],
   "source": [
    "#Reshape b\n",
    "#Note: If one of the dimensions is -1, its size can be inferred\n",
    "print(b.view(-1,1))\n",
    "print(b.view(12))\n",
    "print(b.view(-1,4))\n",
    "print(b.view(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "tensor([[[-1., -0.,  1.,  0.],\n",
      "         [-1.,  1.,  1.,  1.],\n",
      "         [-1.,  0.,  2., -1.]],\n",
      "\n",
      "        [[-1.,  0.,  1., -0.],\n",
      "         [ 1.,  0., -1., -1.],\n",
      "         [ 0., -1.,  0.,  1.]]])\n",
      "tensor([[-1., -0.,  1.,  0., -1.,  1.,  1.,  1., -1.,  0.,  2., -1.],\n",
      "        [-1.,  0.,  1., -0.,  1.,  0., -1., -1.,  0., -1.,  0.,  1.]])\n",
      "tensor([[-1., -0.,  1.,  0., -1.,  1.,  1.,  1., -1.,  0.,  2., -1.],\n",
      "        [-1.,  0.,  1., -0.,  1.,  0., -1., -1.,  0., -1.,  0.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "three_dim = torch.randn(2, 3, 4)\n",
    "print('\\n')\n",
    "print(three_dim.round())\n",
    "print(three_dim.view(2, 12).round())  # Reshape to 2 rows, 12 columns\n",
    "print(three_dim.view(2, -1).round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1729, 0.3580, 0.8855, 0.5387],\n",
      "        [0.1704, 0.9571, 0.6880, 0.3009],\n",
      "        [0.4551, 0.0679, 0.1765, 0.1045],\n",
      "        [0.0989, 0.5369, 0.5712, 0.2202]])\n"
     ]
    }
   ],
   "source": [
    "r = torch.rand(4,4)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1454, -1.0034,  0.7409,  1.2808],\n",
      "        [ 0.5383,  0.0885, -1.1803, -0.2797],\n",
      "        [ 1.7608, -1.6727, -0.3208,  0.0216],\n",
      "        [ 0.2249,  0.9275, -0.8639, -1.7227]])\n",
      "torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (30) : unknown error at ..\\aten\\src\\THC\\THCGeneral.cpp:74",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-1a066b32ed6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Move the tensor to the GPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (30) : unknown error at ..\\aten\\src\\THC\\THCGeneral.cpp:74"
     ]
    }
   ],
   "source": [
    "r2 = torch.randn(4,4)\n",
    "print(r2)\n",
    "print(r2.dtype)\n",
    "\n",
    "#Move the tensor to the GPU\n",
    "r2 = r2.cuda()\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Provide Easy switching between CPU and GPU\n",
    "CUDA = torch.cuda.is_available()\n",
    "print(CUDA)\n",
    "if CUDA:\n",
    "    add_result = add_result.cuda()\n",
    "    print(add_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 1]\n",
      "tensor([2, 3, 4, 1]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "#You can also convert a list to a tensor\n",
    "a = [2,3,4,1]\n",
    "print(a)\n",
    "to_list = torch.tensor(a)\n",
    "print(to_list, to_list.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4749, -0.0992,  0.2559,  0.4163,  0.8625],\n",
      "        [-0.0740, -0.3441,  0.0237,  0.4128, -0.4807]])\n",
      "tensor([[ 0.7257, -1.0996,  0.9211,  1.1918,  0.9330],\n",
      "        [ 1.0694,  1.0862, -0.0717, -1.9877,  1.0121],\n",
      "        [ 0.6396, -0.2935,  1.7021,  1.5975, -0.7414]])\n",
      "\n",
      "\n",
      "tensor([[ 1.4749, -0.0992,  0.2559,  0.4163,  0.8625],\n",
      "        [-0.0740, -0.3441,  0.0237,  0.4128, -0.4807],\n",
      "        [ 0.7257, -1.0996,  0.9211,  1.1918,  0.9330],\n",
      "        [ 1.0694,  1.0862, -0.0717, -1.9877,  1.0121],\n",
      "        [ 0.6396, -0.2935,  1.7021,  1.5975, -0.7414]])\n",
      "\n",
      "\n",
      "tensor([[-0.6709, -1.0505,  0.5973],\n",
      "        [-0.1674, -1.0133,  1.7314]])\n",
      "tensor([[ 0.5354, -0.5791,  1.7262,  0.0236,  0.4145],\n",
      "        [-0.4081,  0.8494,  1.4980, -0.1216, -1.3631]])\n",
      "\n",
      "\n",
      "tensor([[-0.6709, -1.0505,  0.5973,  0.5354, -0.5791,  1.7262,  0.0236,  0.4145],\n",
      "        [-0.1674, -1.0133,  1.7314, -0.4081,  0.8494,  1.4980, -0.1216, -1.3631]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tensor Concatenation \n",
    "first_1 = torch.randn(2, 5)\n",
    "print(first_1)\n",
    "second_1 = torch.randn(3, 5)\n",
    "print(second_1)\n",
    "#Concatenate along the 0 dimension (concatenate rows)\n",
    "con_1 = torch.cat([first_1, second_1],0)\n",
    "print('\\n')\n",
    "print(con_1)\n",
    "print('\\n')\n",
    "first_2 = torch.randn(2, 3)\n",
    "print(first_2)\n",
    "second_2 = torch.randn(2, 5)\n",
    "print(second_2)\n",
    "# Concatenate along the 1 dimension (concatenate columns)\n",
    "con_2 = torch.cat([first_2, second_2], 1)\n",
    "print('\\n')\n",
    "print(con_2)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "tensor([[1, 2, 3, 4]])\n",
      "torch.Size([1, 4])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "torch.Size([4, 1])\n",
      "\n",
      "\n",
      "tensor([[[0.6561, 0.7074, 0.7983, 0.4529],\n",
      "         [0.3775, 0.9105, 0.3349, 0.1615],\n",
      "         [0.4886, 0.5808, 0.5535, 0.0999]],\n",
      "\n",
      "        [[0.4217, 0.7812, 0.5267, 0.6731],\n",
      "         [0.1528, 0.8140, 0.7739, 0.9010],\n",
      "         [0.1075, 0.0743, 0.3369, 0.3360]]])\n",
      "\n",
      "\n",
      "tensor([[0.7983, 0.3349, 0.5535],\n",
      "        [0.5267, 0.7739, 0.3369]])\n",
      "torch.Size([2, 3])\n",
      "\n",
      "\n",
      "tensor([[[0.7983],\n",
      "         [0.3349],\n",
      "         [0.5535]],\n",
      "\n",
      "        [[0.5267],\n",
      "         [0.7739],\n",
      "         [0.3369]]])\n",
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "#Adds a dimension of 1 along a specified index\n",
    "tensor_1 = torch.tensor([1, 2, 3, 4])\n",
    "print(tensor_1.shape)\n",
    "tensor_a = torch.unsqueeze(tensor_1, 0)\n",
    "print(tensor_a)\n",
    "print(tensor_a.shape)\n",
    "\n",
    "tensor_b = torch.unsqueeze(tensor_1,1)\n",
    "print(tensor_b)\n",
    "print(tensor_b.shape)\n",
    "print('\\n')\n",
    "\n",
    "tensor_2 = torch.rand(2,3,4)\n",
    "print(tensor_2)\n",
    "print('\\n')\n",
    "tensor_c = tensor_2[:,:,2]\n",
    "print(tensor_c)\n",
    "print(tensor_c.shape)\n",
    "print('\\n')\n",
    "tensor_d = torch.unsqueeze(tensor_c,2)\n",
    "print(tensor_d)\n",
    "print(tensor_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], grad_fn=<ThAddBackward>)\n",
      "<ThAddBackward object at 0x0000029389E033C8>\n",
      "tensor(21., grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x0000029392997860>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Remember, If requires_grad=True, the Tensor object keeps track of how it was created.\n",
    "x = torch.tensor([1., 2., 3], requires_grad=True)\n",
    "y = torch.tensor([4., 5., 6], requires_grad=True)\n",
    "#Notice that both x and y have their required_grad set to true, therefore we an compute gradients with respect to them\n",
    "z = x + y\n",
    "print(z)\n",
    "# z knows that is was created as a result of addition of x and y. It knows that it wasn't read in from a file\n",
    "print(z.grad_fn)\n",
    "#And if we go further on this\n",
    "s = z.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Now if we backpropagate on s, we can find the gradients of s with respect to x\n",
    "s.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "None\n",
      "<ThAddBackward object at 0x00000293929B9C88>\n",
      "True\n",
      "None\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# By default, Tensors have `requires_grad=False`\n",
    "x = torch.randn(2, 2)\n",
    "y = torch.randn(2, 2)\n",
    "print(x.requires_grad, y.requires_grad)\n",
    "z = x + y\n",
    "# So you can't backprop through z\n",
    "print(z.grad_fn)\n",
    "#Another way to set the requires_grad = True is\n",
    "x.requires_grad_()\n",
    "y.requires_grad_()\n",
    "# z contains enough information to compute gradients, as we saw above\n",
    "z = x + y\n",
    "print(z.grad_fn)\n",
    "# If any input to an operation has ``requires_grad=True``, so will the output\n",
    "print(z.requires_grad)\n",
    "# Now z has the computation history that relates itself to x and y\n",
    "\n",
    "new_z = z.detach()\n",
    "print(new_z.grad_fn)\n",
    "# z.detach() returns a tensor that shares the same storage as ``z``, but with the computation history forgotten. \n",
    "#It doesn't know anything about how it was computed.In other words, we have broken the Tensor away from its past history\n",
    "\n",
    "#You can also stop autograd from tracking history on Tensors. This concept is useful when applying Transfer Learning \n",
    "print(x.requires_grad)\n",
    "print((x+10).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x+10).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
